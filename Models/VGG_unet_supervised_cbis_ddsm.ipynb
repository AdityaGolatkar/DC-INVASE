{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems:\n",
    "## 1)Loss function : Dice + cross entropy\n",
    "## 2)We dont need accurate segmentation instead we could just work with a bounding box metric\n",
    "## 3)For the model we used vgg backbone with decoder\n",
    "## 4)We add a distance based weighted loss term\n",
    "## 5)Made new mask which have a larger area now\n",
    "## 6)Also its important to consider the breast mask and make sure our region of focus is inside the breast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import augmentations\n",
    "from augmentations import *\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## Dataloader\n",
    "\n",
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = '../Data/mask_orient_cropped/'\n",
    "        self.dist_mask_dir = '../Data/distance_mask_orient_cropped/'\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        #get the image\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        #get the mask\n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'].replace('.j','_mask.j'))\n",
    "        mask = io.imread(mask_name)\n",
    "        \n",
    "        #get the distance mask\n",
    "        dist_mask_name = os.path.join(self.dist_mask_dir,self.data_frame.iloc[idx]['name'].replace('.j','_mask.j'))\n",
    "        dist_mask = io.imread(dist_mask_name)\n",
    "\n",
    "        #add the distance mask as the final channel of the \n",
    "        mask = np.array([mask,mask,dist_mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)     \n",
    "\n",
    "        if self.transform:\n",
    "            image,mask = self.transform(image,mask)\n",
    "                \n",
    "        mask_final = mask[0,:,:]\n",
    "        mask_final[mask_final<0.5] = 0\n",
    "        mask_final[mask_final>0.5] = 1\n",
    "        \n",
    "        dist_mask = mask[2,:,:]\n",
    "        \n",
    "        return {'image':image, 'mask':mask_final, 'dist_mask':dist_mask, 'name':self.data_frame.iloc[idx]['name']}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': Compose([\n",
    "            RandomHorizontallyFlip(0.5),\n",
    "            RandomVerticallyFlip(0.5),\n",
    "            RandomTranslate((0.1,0.1)),\n",
    "            RandomRotate(15),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': Compose([\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': Compose([\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)        \n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        if x == 'train':\n",
    "            bs = batch_size\n",
    "            sh = True\n",
    "        elif x == 'valid':\n",
    "            bs = batch_size\n",
    "            sh = False\n",
    "        else:\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=bs,shuffle=sh, num_workers=8)    \n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "\n",
    "# a,_,_,_ = get_dataloader('../Data/CBIS-DDSM_classification_orient_cropped/','../CSV/gain_train.csv',[0,0,0],[1,1,1],1)\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "\n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[0][i]) for i in [12,22,32,42]]\n",
    "        self.up1 = UnetBlock(512,512,256)\n",
    "        self.up2 = UnetBlock(256,512,256)\n",
    "        self.up3 = UnetBlock(256,256,256)\n",
    "        self.up4 = UnetBlock(256,128,256)\n",
    "        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        return x\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "\n",
    "def build_model():\n",
    "    v = models.vgg16_bn(pretrained=True)\n",
    "    v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "    m = Unet34(v1)\n",
    "    return m\n",
    "\n",
    "def get_IoU(pred, targs):\n",
    "    return 2*(pred*targs).sum() / ((pred+targs).sum())# - (pred*targs).sum())\n",
    "\n",
    "def new_metric(preds,targs,device,patch_size=64):\n",
    "    \n",
    "    mask = targs\n",
    "    b,c,h,w = preds.size()\n",
    "    \n",
    "#     conv_filter = torch.ones((1, 1, 5, 5))/25\n",
    "#     conv_filter = conv_filter.to(device)\n",
    "#     filtered_preds = F.conv2d(preds, conv_filter, padding=2)\n",
    "#     max_loc = torch.argmax(filtered_preds)\n",
    "#     h_loc = int(max_loc%h)\n",
    "#     w_loc = int(max_loc/h)\n",
    "    temp = preds\n",
    "    temp = temp.detach().cpu().numpy()\n",
    "    temp = temp.squeeze()\n",
    "    temp[temp>0] = 1\n",
    "    temp[temp<0] = 0\n",
    "    #import pdb;pdb.set_trace()\n",
    "    hs,ws = np.where(temp==1)\n",
    "    try:\n",
    "        h_loc = int(hs.mean())\n",
    "        w_loc = int(ws.mean())\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    h_up = max(0,h_loc-patch_size//2)\n",
    "    h_bottom = min(h,h_loc+patch_size//2)\n",
    "    \n",
    "    w_left = max(0,w_loc-patch_size//2)\n",
    "    w_right = min(w,w_loc+patch_size//2)\n",
    "    \n",
    "    if h_up == 0:\n",
    "        h_bottom = min(patch_size,h)\n",
    "    elif h_bottom == h:\n",
    "        h_up = max(0,-patch_size+h)\n",
    "        \n",
    "    if w_left == 0:\n",
    "        w_right = min(patch_size,w)\n",
    "    elif w_right == w:\n",
    "        w_left = max(0,-patch_size+w)\n",
    "    \n",
    "    mask_loc = mask[0,h_up:h_bottom,w_left:w_right]\n",
    "    return 1.0*mask_loc.sum()/(mask.sum()+1)\n",
    "    \n",
    "    \n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        smooth = 1\n",
    "        num = targets.size(0)\n",
    "        probs = F.sigmoid(1*(logits))\n",
    "        m1 = probs.view(num, -1)\n",
    "        m2 = targets.view(num, -1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score\n",
    "    \n",
    "class DistanceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DistanceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "    \n",
    "        num = targets.size(0)\n",
    "        probs = F.sigmoid(logits)\n",
    "        m1 = probs.view(num, -1)\n",
    "        m2 = targets.view(num, -1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score = intersection.sum()/m2.sum()\n",
    "        return score\n",
    "    \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        input = input.view(-1)\n",
    "        target = target.view(-1)\n",
    "        target_a = target*self.alpha\n",
    "        target_1_a = (1-target)*(1-self.alpha)\n",
    "        \n",
    "        pt = F.sigmoid(input)\n",
    "    \n",
    "        loss = target_a*((1-pt)**self.gamma)*torch.log(pt+1e-8) + target_1_a*((pt)**self.gamma)*torch.log(1-pt+1e-8) \n",
    "        loss = -loss.mean()\n",
    "        \n",
    "        return loss   \n",
    "    \n",
    "class VGG_unet_bc():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialization\n",
    "        self.data_dir = '../Data/CBIS-DDSM_classification_orient_cropped/'\n",
    "        self.train_csv = '../CSV/mass_segmentation_train.csv'\n",
    "        self.num_epochs = 20\n",
    "        self.batch_size = 1\n",
    "        self.img_mean = [0.253, 0.238, 0.234]\n",
    "        self.img_std = [0.272, 0.268, 0.262]\n",
    "        self.exp_name = 'Weights/VGG_unet_cbis_ddsm_distloss'\n",
    "        \n",
    "        #Define the three models\n",
    "        self.model = build_model()\n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.model = self.model.cuda()\n",
    "        #self.model.load_state_dict(torch.load(self.exp_name+'.pt'))\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(),lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        \n",
    "        #self.lr_scheduler = CosineAnnealingLR(self.optimizer,T_max=10,eta_min=1e-4)\n",
    "    \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        best_epoch_acc = 0.0\n",
    "        best_epoch_iou = 0.0\n",
    "        best_epoch_metric = 0.0\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':\n",
    "                    \n",
    "                    #Set the models to training mode\n",
    "                    #self.lr_scheduler.step()\n",
    "                    self.model.train()\n",
    "                \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    self.model.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_loss = 0.0\n",
    "                running_dice_loss = 0.0\n",
    "                running_dist_loss = 0.0\n",
    "                \n",
    "                #Metrics : predictor auc and selector iou\n",
    "                running_iou = 0\n",
    "                running_new_metric = 0\n",
    "                \n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    mask = sampled_batch['mask']\n",
    "                    dist_mask = sampled_batch['dist_mask']\n",
    "                   \n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    mask = mask.to(self.device)\n",
    "                    dist_mask = dist_mask.to(self.device)\n",
    "                    \n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer.zero_grad()\n",
    "                \n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        \n",
    "                        outputs = self.model(inputs)\n",
    "                        \n",
    "                        out4loss = outputs.view(-1)\n",
    "                        mask4loss = mask.view(-1)\n",
    "                        dm4loss = dist_mask.view(-1)\n",
    "                        \n",
    "                        z_c = float((mask==0).sum())\n",
    "                        o_c = float((mask==1).sum())\n",
    "                        alpha = z_c/(z_c+o_c)\n",
    "                        #ce_loss = nn.BCEWithLogitsLoss()(out4loss,new_mask4loss)\n",
    "                        ce_loss = FocalLoss(2,alpha)(outputs,mask)\n",
    "                        dice_loss = SoftDiceLoss()(outputs,mask)\n",
    "                        dist_loss = DistanceLoss()(outputs,dist_mask)\n",
    "                        loss = ce_loss + 2*dice_loss + dist_loss\n",
    "                        \n",
    "                        #print((F.sigmoid(out4loss)*dm4loss).sum(),(outputs>0).sum(),maskdm4loss.sum())\n",
    "                        #import pdb;pdb.set_trace()\n",
    "                        \n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            loss.backward()\n",
    "                            self.optimizer.step()\n",
    "                                    \n",
    "                    out4iou = out4loss\n",
    "                    out4iou[out4loss>0] = 1\n",
    "                    out4iou[out4loss<0] = 0\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_dice_loss += dice_loss.item() * inputs.size(0)\n",
    "                    running_dist_loss += dist_loss.item() * inputs.size(0)\n",
    "                    running_iou += get_IoU(out4loss,mask4loss) * inputs.size(0)\n",
    "                    running_new_metric += new_metric(outputs,mask,self.device,64) * inputs.size(0)\n",
    "                    #print(running_new_metric)\n",
    "                    #print(running_iou)\n",
    "                    \n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "                epoch_loss = running_loss / self.dataset_sizes[phase]\n",
    "                epoch_dice_loss = running_dice_loss / self.dataset_sizes[phase]\n",
    "                epoch_dist_loss = running_dist_loss / self.dataset_sizes[phase]\n",
    "                epoch_iou = running_iou / self.dataset_sizes[phase]\n",
    "                epoch_new_metric = running_new_metric / self.dataset_sizes[phase]\n",
    "                \n",
    "                print('{} Loss: {:.4f} Dice_Loss: {:.4f} Dist_Loss: {:.4f} IoU: {:.4f} New Metric: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_dice_loss, epoch_dist_loss, epoch_iou, epoch_new_metric))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and epoch_new_metric > best_epoch_metric:\n",
    "                    best_epoch_metric = epoch_new_metric\n",
    "                    torch.save(self.model.state_dict(),self.exp_name+'.pt')\n",
    "                    \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best new metric: {:4f}'.format(best_epoch_metric))\n",
    "\n",
    "        torch.save(self.model.state_dict(),self.exp_name+'_final.pt')\n",
    "        \n",
    "        print('Training completed finally !!!!!')\n",
    "        \n",
    "        \n",
    "    def test_model(self):\n",
    "                \n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'.pt'))\n",
    "        self.model.eval()\n",
    "        \n",
    "        mIoU = 0\n",
    "        running_iou = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        image_list = []\n",
    "        mask_list = []\n",
    "        pred_list = []\n",
    "        i=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                images = data['image'].to(self.device)\n",
    "                mask = data['mask'].to(self.device)\n",
    "                dist_mask = data['dist_mask']\n",
    "                \n",
    "                preds = self.model(images)\n",
    "                \n",
    "                out4metric = preds.view(-1)\n",
    "                mask4metric = mask.view(-1)\n",
    "                \n",
    "                prediction = preds[:]\n",
    "                \n",
    "                #import pdb;pdb.set_trace()\n",
    "                sorted_pixels = sorted(prediction.cpu().numpy().reshape(-1))\n",
    "                \n",
    "                \n",
    "                thresh = float(sorted_pixels[int(0.99*len(sorted_pixels))])\n",
    "                \n",
    "                print(i)\n",
    "                i+=1\n",
    "                prediction[prediction>thresh] = 1\n",
    "                prediction[prediction<=thresh] = 0\n",
    "                \n",
    "                running_iou += get_IoU(prediction.view(-1),mask4metric) * images.size(0)                \n",
    "                \n",
    "                base_path = '../Experiments/cbis_ddsm_sup/'\n",
    "                name = data['name'][0]\n",
    "\n",
    "                pr = name.replace('.j','_supervised_out_1_percent.j')\n",
    "                \n",
    "                preds = preds - preds.min()\n",
    "                preds = preds/preds.max()\n",
    "                \n",
    "                cv2.imwrite(base_path+pr,prediction.cpu().numpy().squeeze()*255)\n",
    "                #cv2.imwrite(base_path+pr.replace('.j','_probs.j'),preds.cpu().numpy().squeeze()*255)\n",
    "                \n",
    "                \n",
    "        mIoU = running_iou/self.dataset_sizes[mode]\n",
    "        print('mean IoU:',mIoU)\n",
    "\n",
    "#                 image_list.append(images.squeeze().cpu().numpy().transpose((1,2,0)))\n",
    "#                 mask_list.append(mask.transpose((1,2,0)).squeeze())\n",
    "#                 pred_list.append(preds.squeeze().cpu().numpy())\n",
    "\n",
    "#         return image_list,mask_list,pred_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = VGG_unet_bc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1ccd987843477eb2b114f685332c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=924), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0872 Dice_Loss: 0.9613 Dist_Loss: 0.2241 IoU: 0.1582 New Metric: 0.3035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a04719adf484af3adfc7d4c87343380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=307), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.0192 Dice_Loss: 0.9590 Dist_Loss: 0.0923 IoU: 0.1734 New Metric: 0.2804\n",
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04983b7cc18d40ec8bcd51ad07a39880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=924), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0136 Dice_Loss: 0.9511 Dist_Loss: 0.0667 IoU: 0.1994 New Metric: 0.3772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6110c968aae4ebd81d2b7be62776efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=307), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.0086 Dice_Loss: 0.9722 Dist_Loss: 0.0429 IoU: 0.0658 New Metric: 0.2121\n",
      "Epoch 2/19\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0084610ba04c99aa9be46f3719d996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=924), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-104:\n",
      "Process Process-103:\n",
      "Process Process-101:\n",
      "Process Process-97:\n",
      "Process Process-99:\n",
      "Process Process-98:\n",
      "Process Process-100:\n",
      "Process Process-102:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6b5c273340fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-c60cb421338e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                     \u001b[0mout4iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout4loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mout4iou\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout4loss\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                     \u001b[0mout4iou\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout4loss\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                     \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "u.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "mean IoU: tensor(0.2132, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "u.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.imread('../Experiments/cbis_ddsm/Mass-Test_P_00056_LEFT_MLO_supervised_out.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.imread('../Experiments/cbis_ddsm/Mass-Test_P_00056_LEFT_MLO_supervised_new_mask.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'../Data/masks_orient/Mass-Training_P_00913'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = u.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c[1]\n",
    "d[d>0] = 255\n",
    "d[d<=0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_IoU(d/255,b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_ = dci.get_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dci.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dci.test_model_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md,dl = dci.return_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(dl).next()\n",
    "\n",
    "m = denorm_img(a['mask'],[0.223, 0.231, 0.243],[0.266, 0.270, 0.274]).squeeze()\n",
    "bm = denorm_img(a['bmask'],[0.223, 0.231, 0.243],[0.266, 0.270, 0.274]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "p = F.sigmoid(md(a['image'].to(device))).detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m = p*bm\n",
    "p_m[p_m > p_m.mean() + p_m.std()] = 1\n",
    "p_m[p_m < p_m.mean() + p_m.std()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m_t = torch.Tensor(p_m)\n",
    "print(nn.L1Loss()(torch.Tensor(p_m),torch.zeros(p_m_t.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p*bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
