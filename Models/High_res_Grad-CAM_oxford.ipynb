{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "  \n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import augmentations\n",
    "from augmentations import *\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "## Dataloader\n",
    "\n",
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = self.root_dir.replace('images','masks')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'])\n",
    "        mask = io.imread(mask_name)\n",
    "        mask = np.array([mask,mask,mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']       \n",
    "\n",
    "        if self.transform:\n",
    "            image,mask = self.transform(image,mask)\n",
    "        \n",
    "        mask_final = mask[0,:,:]\n",
    "        mask_final[mask_final<0.5] = 0\n",
    "        mask_final[mask_final>0.5] = 1\n",
    "        \n",
    "        return {'image':image, 'category':label, 'mask':mask_final, 'name':self.data_frame.iloc[idx]['name']}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': Compose([\n",
    "            Resize(image_size),\n",
    "            RandomHorizontallyFlip(0.5),\n",
    "            RandomVerticallyFlip(0.5),\n",
    "            RandomTranslate((0.2,0.2)),\n",
    "            RandomRotate(15),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': Compose([\n",
    "            Resize(image_size),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': Compose([\n",
    "            Resize(image_size),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)        \n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        if x == 'test':\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        elif x == 'valid':\n",
    "            bs = batch_size\n",
    "            sh = False\n",
    "        else:\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=bs,shuffle=sh, num_workers=8)    \n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "\n",
    "## Selector network (VGG-UNet)\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return F.dropout2d(self.bn(F.relu(cat_p)),p=0.5) #Using dropout after non-linearity and before the \n",
    "\n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[0][i]) for i in [12,22,32,42]]\n",
    "        self.up1 = UnetBlock(512,512,256)\n",
    "        self.up2 = UnetBlock(256,512,256)\n",
    "        self.up3 = UnetBlock(256,256,256)\n",
    "        self.up4 = UnetBlock(256,128,256)\n",
    "        self.up5 = nn.ConvTranspose2d(256,16, 2, stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x1 = self.up1(x, self.sfs[3].features)\n",
    "        x2 = self.up2(x1, self.sfs[2].features)\n",
    "        x3 = self.up3(x2, self.sfs[1].features)\n",
    "        x4 = self.up4(x3, self.sfs[0].features)\n",
    "        x5 = self.up5(x4)\n",
    "        return x5\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "            \n",
    "class mdl(nn.Module):\n",
    "    def __init__(self,base_model):\n",
    "        super().__init__()\n",
    "        self.base = base_model \n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(16,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# def build_model():\n",
    "#     v = models.vgg16_bn(pretrained=False)\n",
    "#     v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "#     m = Unet34(v1)\n",
    "#     model_final = mdl(m)\n",
    "#     return model_final\n",
    "\n",
    "def build_model():\n",
    "\n",
    "    class mdl(nn.Module):\n",
    "        def __init__(self,base_model):\n",
    "            super().__init__()\n",
    "            self.base = base_model \n",
    "            self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.fc1 = nn.Linear(512,2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x_base = self.base(x)\n",
    "            x = self.gap(x_base)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            return x,x_base \n",
    "\n",
    "    v = models.vgg16_bn(pretrained=True)\n",
    "    v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "    model = mdl(v1[-1][:-1])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# a = build_selector()\n",
    "# summary(a.cuda(),(3,224,224))\n",
    "\n",
    "    \n",
    "def get_IoU(pred, targs, device):\n",
    "\n",
    "    targs = torch.Tensor(targs).to(device)\n",
    "    return (pred*targs).sum() / ((pred+targs).sum() - (pred*targs).sum())\n",
    "\n",
    "\n",
    "class grad_cam():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialization\n",
    "        self.data_dir = '../Data/oxford_pets/sparse_images/'\n",
    "        self.train_csv = '../CSV/oxford_pet_train.csv'\n",
    "        self.num_epochs = 25\n",
    "        self.input_shape = (224,224)\n",
    "        self.batch_size = 1\n",
    "        self.img_mean = [0.485, 0.456, 0.406]#[0,0,0]\n",
    "        self.img_std = [0.229, 0.224, 0.225]#[1,1,1]\n",
    "        \n",
    "        self.exp_name = 'Weights/high_res_grad_cam_vgg_16_oxford'\n",
    "        \n",
    "        #Define the three models\n",
    "        self.model = build_model()\n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.input_shape,self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "        #Get the optimizer\n",
    "        self.optimizer = optim.Adam(self.model.parameters(),lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        #self.optimizer = optim.SGD(self.model.parameters(), lr = 0.01, momentum=0.9)\n",
    "        \n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        best_epoch_acc = 0.0\n",
    "        best_epoch_f1 = 0.0\n",
    "        \n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'valid']:\n",
    "                \n",
    "                labels_list = []\n",
    "                preds_list = []\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    \n",
    "                    #Set the models to training mode\n",
    "                    self.model.train()\n",
    "                \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    self.model.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                #Metrics : predictor auc and selector iou\n",
    "                running_acc = 0\n",
    "                running_f1 = 0\n",
    "                \n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    labels = sampled_batch['category']\n",
    "\n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    labels = labels.long().to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer.zero_grad()\n",
    "                \n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                                            \n",
    "                        outputs,_ = self.model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            loss.backward()\n",
    "                            self.optimizer.step()\n",
    "                                    \n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_acc += torch.sum(preds == labels.data)\n",
    "                    #running_f1 += f1_score(labels.data,preds)*inputs.size(0)\n",
    "                    #import pdb;pdb.set_trace()\n",
    "                    labels_list += [labels.data.view(-1)]\n",
    "                    preds_list += [preds.view(-1)]\n",
    "\n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "                labels_list = torch.cat(labels_list)\n",
    "                preds_list = torch.cat(preds_list)\n",
    "                \n",
    "                epoch_loss = running_loss / self.dataset_sizes[phase]\n",
    "                epoch_acc = running_acc.double() / self.dataset_sizes[phase]\n",
    "                epoch_f1 = f1_score(labels_list,preds_list)\n",
    "\n",
    "                print('{} Sel_Loss: {:.4f} Acc: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc,  epoch_f1))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and epoch_f1 > best_epoch_f1:\n",
    "                    best_epoch_f1 = epoch_f1\n",
    "                    torch.save(self.model.state_dict(),self.exp_name+'.pt')\n",
    "                    \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best F1: {:4f}'.format(best_epoch_f1))\n",
    "\n",
    "        torch.save(self.model.state_dict(),self.exp_name+'_final.pt')\n",
    "        \n",
    "        print('Training completed finally !!!!!')\n",
    "\n",
    "        \n",
    "    def test_model_auc(self):\n",
    "                \n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'.pt'))\n",
    "        self.model.eval()\n",
    "        \n",
    "        acc = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        predictions = []\n",
    "        ground_truth = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pbar = tqdm(total=self.dataset_sizes[mode])\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                inputs = data['image']\n",
    "                labels = data['category']\n",
    "                \n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                output = self.model(inputs)\n",
    "                _,out = torch.max(output,1)\n",
    "                \n",
    "                predictions.append(output.cpu().numpy())\n",
    "                ground_truth.append(labels.cpu().numpy())\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                acc += torch.sum(out==labels.data)\n",
    "                pbar.update(inputs.shape[0])\n",
    "            pbar.close()\n",
    "                \n",
    "        pred = predictions[0]\n",
    "        for i in range(len(predictions)-1):\n",
    "            pred = np.concatenate((pred,predictions[i+1]),axis=0)\n",
    "            \n",
    "        gt = ground_truth[0]\n",
    "        for i in range(len(ground_truth)-1):\n",
    "            gt = np.concatenate((gt,ground_truth[i+1]),axis=0)\n",
    "            \n",
    "        #import pdb;pdb.set_trace()\n",
    "        auc = roc_auc_score(gt,pred[:,1],average='weighted')\n",
    "        \n",
    "        print(\"AUC:\", auc)\n",
    "        print(\"ACC:\", acc.double()/total)\n",
    "        \n",
    "\n",
    "    def get_cam(self):\n",
    "                \n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'.pt'))\n",
    "        self.model.eval()\n",
    "        \n",
    "        acc = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        cm = []\n",
    "        m = []\n",
    "        bm = []\n",
    "        \n",
    "        params = list(self.model.parameters())                        \n",
    "        weight_softmax = torch.squeeze(params[-2].data)\n",
    "        \n",
    "        iou = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pbar = tqdm(total=self.dataset_sizes[mode])\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                inputs = data['image']\n",
    "                labels = data['category']\n",
    "                \n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                input_write = inputs.cpu().numpy().squeeze().transpose((1,2,0))\n",
    "                \n",
    "                output = self.model(inputs)\n",
    "                _,out = torch.max(output,1)      \n",
    "\n",
    "                #Get the CAM which will the prob map\n",
    "                cam = torch.matmul(weight_softmax[out[0]],feat[0].reshape(feat[0].shape[0],feat[0].shape[1]*feat[0].shape[2]))\n",
    "                cam = F.relu(cam.reshape(feat[0].shape[1], feat[0].shape[2]))\n",
    "                cam_img = F.interpolate(cam.unsqueeze(dim=0).unsqueeze(dim=0),(self.input_shape[0],self.input_shape[1]),mode='bilinear')             \n",
    "                cam_img = cam_img - cam_img.min()\n",
    "                cam_img = cam_img/cam_img.max()\n",
    "                \n",
    "                base_path = '../Experiments/Oxford_pets/'\n",
    "                name = data['name'][0]\n",
    "                \n",
    "                heatmap = cam_img.cpu().numpy().squeeze()\n",
    "                heatmap[heatmap>heatmap.mean()+heatmap.std()] = 1\n",
    "                heatmap[heatmap<=heatmap.mean()+heatmap.std()] = 0\n",
    "                heatmap = np.expand_dims(heatmap,axis=3)\n",
    "                \n",
    "                #heatmap = cv2.applyColorMap(np.uint8(255*cam_img.cpu().numpy().squeeze()), cv2.COLORMAP_JET)\n",
    "                #heatmap = np.float32(heatmap) / 255\n",
    "                #cam_f = heatmap + np.float32(inputs.cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "                \n",
    "                cam_f = heatmap*(input_write)\n",
    "                #import pdb;pdb.set_trace()\n",
    "                cam_f = cam_f / np.max(cam_f)\n",
    "                \n",
    "                \n",
    "                pr = name.replace('.j','_cam.j')\n",
    "                cv2.imwrite(base_path+pr,cam_f*255)\n",
    "                \n",
    "                #cv2.imwrite(base_path+name,input_write*255)\n",
    "                      \n",
    "                pbar.update(inputs.shape[0])\n",
    "                \n",
    "            pbar.close()                \n",
    "        \n",
    "    def return_model(self):\n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.model.eval()\n",
    "        mode = 'test'\n",
    "        return self.model,self.dataloaders[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "  \n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = self.root_dir.replace('images','masks')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'])\n",
    "        mask = io.imread(mask_name)\n",
    "        mask = np.array([mask,mask,mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']       \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "    \n",
    "        return {'image':image, 'category':label, 'mask':mask, 'name':self.data_frame.iloc[idx]['name']}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomAffine(translate=(0,0.2),degrees=15,shear=15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        if x == 'train':\n",
    "            bs = batch_size\n",
    "            sh = True\n",
    "        elif x == 'valid':\n",
    "            bs = batch_size\n",
    "            sh = False\n",
    "        else:\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=bs,shuffle=sh, num_workers=8)    \n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "\n",
    "# def build_model():\n",
    "\n",
    "#     class mdl(nn.Module):\n",
    "#         def __init__(self,base_model):\n",
    "#             super().__init__()\n",
    "#             self.base = base_model \n",
    "#             self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "#             self.fc1 = nn.Linear(512,2)\n",
    "\n",
    "#         def forward(self, x):\n",
    "#             x_base = self.base(x)\n",
    "#             x = self.gap(x_base)\n",
    "#             x = x.view(x.size(0), -1)\n",
    "#             x = self.fc1(x)\n",
    "#             return x,x_base \n",
    "\n",
    "#     v = models.vgg16_bn(pretrained=True)\n",
    "#     v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "#     model = mdl(v1[-1][:-1])\n",
    "    \n",
    "#     return model\n",
    "def build_base():\n",
    "    class unetConv2(nn.Module):\n",
    "        def __init__(self, in_size, out_size, is_batchnorm):\n",
    "            super(unetConv2, self).__init__()\n",
    "\n",
    "            if is_batchnorm:\n",
    "                self.conv1 = nn.Sequential(nn.Conv2d(in_size, out_size, 3, 1, 1),\n",
    "                                           nn.BatchNorm2d(out_size),\n",
    "                                           nn.ReLU(),)\n",
    "                self.conv2 = nn.Sequential(nn.Conv2d(out_size, out_size, 3, 1, 1),\n",
    "                                           nn.BatchNorm2d(out_size),\n",
    "                                           nn.ReLU(),)\n",
    "            else:\n",
    "                self.conv1 = nn.Sequential(nn.Conv2d(in_size, out_size, 3, 1, 1),\n",
    "                                           nn.ReLU(),)\n",
    "                self.conv2 = nn.Sequential(nn.Conv2d(out_size, out_size, 3, 1, 1),\n",
    "                                           nn.ReLU(),)\n",
    "        def forward(self, inputs):\n",
    "            outputs = self.conv1(inputs)\n",
    "            outputs = self.conv2(outputs)\n",
    "            return outputs\n",
    "\n",
    "    class unetUp(nn.Module):\n",
    "        def __init__(self, in_size, out_size, is_deconv):\n",
    "            super(unetUp, self).__init__()\n",
    "            self.conv = unetConv2(in_size, out_size, False)\n",
    "            if is_deconv:\n",
    "                self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "            else:\n",
    "                self.up = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "\n",
    "        def forward(self, inputs1, inputs2):\n",
    "            outputs2 = self.up(inputs2)\n",
    "            offset = outputs2.size()[2] - inputs1.size()[2]\n",
    "            padding = 2 * [offset // 2, offset // 2]\n",
    "            outputs1 = F.pad(inputs1, padding)\n",
    "            return self.conv(torch.cat([outputs1, outputs2], 1))\n",
    "\n",
    "    class unet(nn.Module):\n",
    "\n",
    "        def __init__(self, feature_scale=4, n_classes=1, is_deconv=True, in_channels=3, is_batchnorm=True):\n",
    "            super(unet, self).__init__()\n",
    "            self.is_deconv = is_deconv\n",
    "            self.in_channels = in_channels\n",
    "            self.is_batchnorm = is_batchnorm\n",
    "            self.feature_scale = feature_scale\n",
    "\n",
    "            filters = [32, 64, 128, 256, 512]\n",
    "            filters = [int(x / self.feature_scale) for x in filters]\n",
    "\n",
    "            #downsampling\n",
    "            self.conv1 = unetConv2(self.in_channels, filters[0], self.is_batchnorm)\n",
    "            self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "            self.conv2 = unetConv2(filters[0], filters[1], self.is_batchnorm)\n",
    "            self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "            self.conv3 = unetConv2(filters[1], filters[2], self.is_batchnorm)\n",
    "            self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "            self.conv4 = unetConv2(filters[2], filters[3], self.is_batchnorm)\n",
    "            self.maxpool4 = nn.MaxPool2d(kernel_size=2)\n",
    "                    \n",
    "            self.center = unetConv2(filters[3], filters[4], self.is_batchnorm)\n",
    "\n",
    "            # upsampling\n",
    "            self.up_concat4 = unetUp(filters[4], filters[3], self.is_deconv)\n",
    "            self.up_concat3 = unetUp(filters[3], filters[2], self.is_deconv)\n",
    "            self.up_concat2 = unetUp(filters[2], filters[1], self.is_deconv)\n",
    "            self.up_concat1 = unetUp(filters[1], filters[0], self.is_deconv)\n",
    "\n",
    "            # final conv (without any concat)\n",
    "            self.final = nn.Conv2d(filters[0], n_classes, 1)\n",
    "\n",
    "        def forward(self, inputs):\n",
    "            conv1 = self.conv1(inputs)\n",
    "            maxpool1 = self.maxpool1(conv1)\n",
    "\n",
    "            conv2 = self.conv2(maxpool1)\n",
    "            maxpool2 = self.maxpool2(conv2)\n",
    "\n",
    "            conv3 = self.conv3(maxpool2)\n",
    "            maxpool3 = self.maxpool3(conv3)\n",
    "\n",
    "            conv4 = self.conv4(maxpool3)\n",
    "            maxpool4 = self.maxpool4(conv4)\n",
    "\n",
    "            center = self.center(maxpool4)\n",
    "            up4 = self.up_concat4(conv4, center)\n",
    "            up3 = self.up_concat3(conv3, up4)\n",
    "            up2 = self.up_concat2(conv2, up3)\n",
    "            up1 = self.up_concat1(conv1, up2)\n",
    "\n",
    "            return up1\n",
    "        \n",
    "    model = unet()\n",
    "    return model\n",
    "\n",
    "            \n",
    "class mdl(nn.Module):\n",
    "    def __init__(self,base_model):\n",
    "        super().__init__()\n",
    "        self.base = base_model \n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(8,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_base = self.base(x)\n",
    "        x = self.gap(x_base)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x,x_base\n",
    "\n",
    "def build_model():\n",
    "    m = build_base()\n",
    "    model_final = mdl(m)\n",
    "    return model_final\n",
    "    \n",
    "def get_IoU(pred, targs, device):\n",
    "\n",
    "    targs = torch.Tensor(targs).to(device)\n",
    "    return (pred*targs).sum() / ((pred+targs).sum() - (pred*targs).sum())\n",
    "\n",
    "def denorm_img(img_ten,img_mean,img_std):\n",
    "\n",
    "    bz,nc,h,w = img_ten.shape\n",
    "    output = []\n",
    "    img_num = img_ten.numpy()\n",
    "    \n",
    "    for i in range(bz):\n",
    "        \n",
    "        img = img_ten[i].numpy().squeeze()\n",
    "        \n",
    "        img[0,:,:] = img[0,:,:]*img_std[0]\n",
    "        img[1,:,:] = img[1,:,:]*img_std[1]\n",
    "        img[2,:,:] = img[2,:,:]*img_std[2]\n",
    "\n",
    "        img[0,:,:] = img[0,:,:] + img_mean[0]\n",
    "        img[1,:,:] = img[1,:,:] + img_mean[1]\n",
    "        img[2,:,:] = img[2,:,:] + img_mean[2]\n",
    "        \n",
    "        img = img.mean(axis=0)\n",
    "        img[img>=0.2*img.max()] = 1\n",
    "        img[img<0.2*img.max()] = 0\n",
    "        \n",
    "        output.append(img)\n",
    "    \n",
    "    output = np.array(output)\n",
    "    return output\n",
    "    \n",
    "class grad_cam():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialization\n",
    "        self.data_dir = '../Data/oxford_pets/sparse_images/'\n",
    "        self.train_csv = '../CSV/oxford_pet_train.csv'\n",
    "        self.num_epochs = 25\n",
    "        self.input_shape = (224,224)\n",
    "        self.batch_size = 4\n",
    "        self.img_mean = [0,0,0]\n",
    "        self.img_std = [1, 1, 1]\n",
    "        \n",
    "        self.exp_name = 'Weights/high_res_grad_cam_vgg_16_oxford'\n",
    "        \n",
    "        #Define the three models\n",
    "        self.model = build_model()\n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.input_shape,self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "        #Get the optimizer\n",
    "        self.optimizer = optim.Adam(self.model.parameters(),lr=0.005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        best_epoch_acc = 0.0\n",
    "        best_epoch_f1 = 0.0\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'valid']:\n",
    "                labels_list = []\n",
    "                preds_list = []\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    \n",
    "                    #Set the models to training mode\n",
    "                    self.model.train()\n",
    "                \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    self.model.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                #Metrics : predictor auc and selector iou\n",
    "                running_acc = 0\n",
    "                running_f1 = 0\n",
    "                \n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    labels = sampled_batch['category']\n",
    "\n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    labels = labels.long().to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer.zero_grad()\n",
    "                \n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                                            \n",
    "                        outputs,_ = self.model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            loss.backward()\n",
    "                            self.optimizer.step()\n",
    "                                    \n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_acc += torch.sum(preds == labels.data)\n",
    "                    #running_f1 += f1_score(labels.data,preds)*inputs.size(0)\n",
    "                    labels_list += [labels.data.view(-1)]\n",
    "                    preds_list += [preds.view(-1)]\n",
    "\n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "                labels_list = torch.cat(labels_list)\n",
    "                preds_list = torch.cat(preds_list)\n",
    "                \n",
    "                epoch_loss = running_loss / self.dataset_sizes[phase]\n",
    "                epoch_acc = running_acc.double() / self.dataset_sizes[phase]\n",
    "                epoch_f1 = f1_score(labels_list,preds_list)\n",
    "\n",
    "                print('{} Sel_Loss: {:.4f} Acc: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc,  epoch_f1))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and epoch_f1 > best_epoch_f1:\n",
    "                    best_epoch_f1 = epoch_f1\n",
    "                    torch.save(self.model.state_dict(),self.exp_name+'.pt')\n",
    "                    \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best F1: {:4f}'.format(best_epoch_f1))\n",
    "\n",
    "        torch.save(self.model.state_dict(),self.exp_name+'_final.pt')\n",
    "        \n",
    "        print('Training completed finally !!!!!')\n",
    "\n",
    "        \n",
    "    def test_model_auc(self):\n",
    "                \n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'.pt'))\n",
    "        self.model.eval()\n",
    "        \n",
    "        acc = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        predictions = []\n",
    "        ground_truth = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pbar = tqdm(total=self.dataset_sizes[mode])\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                inputs = data['image']\n",
    "                labels = data['category']\n",
    "                \n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                output,_ = self.model(inputs)\n",
    "                _,out = torch.max(output,1)\n",
    "                \n",
    "                predictions.append(output.cpu().numpy())\n",
    "                ground_truth.append(labels.cpu().numpy())\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                acc += torch.sum(out==labels.data)\n",
    "                pbar.update(inputs.shape[0])\n",
    "            pbar.close()\n",
    "                \n",
    "        pred = predictions[0]\n",
    "        for i in range(len(predictions)-1):\n",
    "            pred = np.concatenate((pred,predictions[i+1]),axis=0)\n",
    "            \n",
    "        gt = ground_truth[0]\n",
    "        for i in range(len(ground_truth)-1):\n",
    "            gt = np.concatenate((gt,ground_truth[i+1]),axis=0)\n",
    "            \n",
    "        #import pdb;pdb.set_trace()\n",
    "        auc = roc_auc_score(gt,pred[:,1],average='weighted')\n",
    "        \n",
    "        print(\"AUC:\", auc)\n",
    "        print(\"ACC:\", acc.double()/total)\n",
    "        \n",
    "\n",
    "    def get_cam(self):\n",
    "                \n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'.pt'))\n",
    "        self.model.eval()\n",
    "        \n",
    "        acc = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        cm = []\n",
    "        m = []\n",
    "        bm = []\n",
    "        \n",
    "        params = list(self.model.parameters())                        \n",
    "        weight_softmax = torch.squeeze(params[-2].data)\n",
    "        \n",
    "        iou = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pbar = tqdm(total=self.dataset_sizes[mode])\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                inputs = data['image']\n",
    "                labels = data['category']\n",
    "                \n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                input_write = inputs.cpu().numpy().squeeze().transpose((1,2,0))\n",
    "                \n",
    "                output,feat = self.model(inputs)\n",
    "                _,out = torch.max(output,1)      \n",
    "\n",
    "                #Get the CAM which will the prob map\n",
    "                cam = torch.matmul(weight_softmax[out[0]],feat[0].reshape(feat[0].shape[0],feat[0].shape[1]*feat[0].shape[2]))\n",
    "                cam = F.relu(cam.reshape(feat[0].shape[1], feat[0].shape[2]))\n",
    "                cam_img = F.interpolate(cam.unsqueeze(dim=0).unsqueeze(dim=0),(self.input_shape[0],self.input_shape[1]),mode='bilinear')             \n",
    "                cam_img = cam_img - cam_img.min()\n",
    "                cam_img = cam_img/cam_img.max()\n",
    "                \n",
    "                base_path = '../Experiments/Oxford_pets/'\n",
    "                name = data['name'][0]\n",
    "                \n",
    "                heatmap = cam_img.cpu().numpy().squeeze()\n",
    "                heatmap[heatmap>heatmap.mean()+heatmap.std()] = 1\n",
    "                heatmap[heatmap<=heatmap.mean()+heatmap.std()] = 0\n",
    "                heatmap = np.expand_dims(heatmap,axis=3)\n",
    "                \n",
    "                #heatmap = cv2.applyColorMap(np.uint8(255*cam_img.cpu().numpy().squeeze()), cv2.COLORMAP_JET)\n",
    "                #heatmap = np.float32(heatmap) / 255\n",
    "                #cam_f = heatmap + np.float32(inputs.cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "                \n",
    "                cam_f = heatmap*(input_write)\n",
    "                #import pdb;pdb.set_trace()\n",
    "                cam_f = cam_f / np.max(cam_f)\n",
    "                \n",
    "                \n",
    "                pr = name.replace('.j','_cam.j')\n",
    "                cv2.imwrite(base_path+pr,cam_f*255)\n",
    "                \n",
    "                #cv2.imwrite(base_path+name,input_write*255)\n",
    "                      \n",
    "                pbar.update(inputs.shape[0])\n",
    "                \n",
    "            pbar.close()                \n",
    "        \n",
    "    def return_model(self):\n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.model.eval()\n",
    "        mode = 'test'\n",
    "        return self.model,self.dataloaders[mode]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = grad_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715b525ae1a64df7ab4dd68c555ba438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6883 Acc: 0.5338 F1: 0.4537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f78a411d9741f28304dc532ec13e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.8663 Acc: 0.5070 F1: 0.6693\n",
      "Epoch 1/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfa0f0d1c27422788472ffe6cecfb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6668 Acc: 0.5893 F1: 0.4948\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad4fe1c9df84134ac9c21a7045bb15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6557 Acc: 0.5950 F1: 0.4122\n",
      "Epoch 2/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4c60b399904f4cb5fd0bc71497d381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6640 Acc: 0.5938 F1: 0.4925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5ba4a253c44cac864b5d4fc7e697ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6618 Acc: 0.5780 F1: 0.4155\n",
      "Epoch 3/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af0c374369249728d8cf71e08136267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6650 Acc: 0.5748 F1: 0.4572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d364e5e56e3a4da48ead85c8ca8951e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6628 Acc: 0.5880 F1: 0.5560\n",
      "Epoch 4/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bd9128452d46fd95a32587bcdce508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6593 Acc: 0.5998 F1: 0.4785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3297a4854860444cae486172534afed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6580 Acc: 0.6180 F1: 0.4753\n",
      "Epoch 5/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa5c55ad9c1484cb23450becebbfec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6606 Acc: 0.5918 F1: 0.4855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313fc8b3985745c6bfba042071c02b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6472 Acc: 0.6170 F1: 0.5663\n",
      "Epoch 6/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115e3becf4f74ddf9acbc2df02deeff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6574 Acc: 0.6048 F1: 0.5006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fa9b9b3ede43f5842b4a433186a2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6488 Acc: 0.6180 F1: 0.4893\n",
      "Epoch 7/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7147f3f9e5b430b8a87f7056f92e204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6547 Acc: 0.6078 F1: 0.5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75243886d8a5499cab392594a0addc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6526 Acc: 0.6300 F1: 0.5363\n",
      "Epoch 8/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820194fc57d3468a8a9706d8febc2aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6571 Acc: 0.6108 F1: 0.5174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148ae19fca0b4a918b974631c1ce9621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6487 Acc: 0.6090 F1: 0.4292\n",
      "Epoch 9/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1c32a6f1114aa08908ead8d3973bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6574 Acc: 0.5998 F1: 0.4872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff9eba74cc54040a75da68b19eca9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6459 Acc: 0.6300 F1: 0.5220\n",
      "Epoch 10/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b605bbf230a4b9a9191c59a956d536c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6593 Acc: 0.6023 F1: 0.4920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05981119c78e40fd99c89443dca86acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6503 Acc: 0.6100 F1: 0.5486\n",
      "Epoch 11/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9386f0e16945d0b269d6a07b279ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6554 Acc: 0.6063 F1: 0.4945\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0ea50bc20342d7910e98b00e5450a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6546 Acc: 0.6200 F1: 0.6082\n",
      "Epoch 12/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e5fd07f02047f1b68e10792217cf0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6520 Acc: 0.6008 F1: 0.5146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b818c9748d949f7a20f7b18227b2aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6494 Acc: 0.6330 F1: 0.5349\n",
      "Epoch 13/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8745471b75444d9091741bf4fb179d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Sel_Loss: 0.6561 Acc: 0.6008 F1: 0.4764\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35e4eae380849ee96cd0151ad2769e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Sel_Loss: 0.6439 Acc: 0.6250 F1: 0.5198\n",
      "Epoch 14/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c6f767add94ddaad34bda2d7892749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-559:\n",
      "Process Process-560:\n",
      "Process Process-555:\n",
      "Process Process-554:\n",
      "Process Process-556:\n",
      "Process Process-553:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-558:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-557:\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"<ipython-input-17-3d972eb2ae66>\", line 67, in __getitem__\n",
      "    mask = Image.fromarray(mask)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 2446, in fromarray\n",
      "    obj = obj.tobytes()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ae7f2418b36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-3d972eb2ae66>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                     \u001b[0mrunning_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;31m#running_f1 += f1_score(labels.data,preds)*inputs.size(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.get_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cv2.imread('../Experiments/Oxford_pets/cat_Abyssinian_105_cam.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.test_model_auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.get_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.test_model_auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m,b,c = gc.get_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cv2.imread('../Experiments/Sanity_Check/dog.10337_cam.jpg')\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('../Experiments/Sanity_Check')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
