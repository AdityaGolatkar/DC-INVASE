{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import augmentations\n",
    "from augmentations import *\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import dataloaders\n",
    "from dataloaders import *\n",
    "\n",
    "## Dataloader\n",
    "## Dataloader\n",
    "\n",
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = self.root_dir.replace('images','masks')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'])\n",
    "        mask = io.imread(mask_name)\n",
    "        mask = np.array([mask,mask,mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']       \n",
    "\n",
    "        if self.transform:\n",
    "            image,mask = self.transform(image,mask)\n",
    "        \n",
    "        mask_final = mask[0,:,:]\n",
    "        mask_final[mask_final<0.5] = 0\n",
    "        mask_final[mask_final>0.5] = 1\n",
    "        \n",
    "        return {'image':image, 'category':label, 'mask':mask_final, 'name':self.data_frame.iloc[idx]['name']}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': Compose([\n",
    "            Resize(image_size),\n",
    "            RandomHorizontallyFlip(0.5),\n",
    "            RandomVerticallyFlip(0.5),\n",
    "            RandomTranslate((0.2,0.2)),\n",
    "            RandomRotate(15),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': Compose([\n",
    "            Resize(image_size),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': Compose([\n",
    "            Resize(image_size),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)        \n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        if x == 'train':\n",
    "            bs = batch_size\n",
    "            sh = True\n",
    "        elif x == 'valid':\n",
    "            bs = batch_size\n",
    "            sh = False\n",
    "        else:\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=bs,shuffle=sh, num_workers=8)    \n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "\n",
    "\n",
    "## Predictor-Discriminator-Baseline\n",
    "def build_pdb():\n",
    "\n",
    "    class mdl(nn.Module):\n",
    "        def __init__(self,base_model):\n",
    "            super().__init__()\n",
    "            self.base = base_model \n",
    "            self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.fc1 = nn.Linear(512,2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x_base = self.base(x)\n",
    "            x = self.gap(x_base)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            return x,x_base \n",
    "\n",
    "    v = models.vgg16_bn(pretrained=True)\n",
    "    v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "\n",
    "    #r = models.resnet101(pretrained=True)\n",
    "    #r1 = nn.Sequential(*list(r.children())[:-2])\n",
    "    \n",
    "    model = mdl(v1[-1][:-1])\n",
    "    model.load_state_dict(torch.load('./Weights/grad_cam_vgg_16_oxford.pt'))\n",
    "        \n",
    "    return model\n",
    "\n",
    "# IoU\n",
    "def get_IoU(pred, targs):\n",
    "    return (pred*targs).sum() / ((pred+targs).sum() - (pred*targs).sum())\n",
    "    \n",
    "## Sampler\n",
    "\n",
    "def sampler(gen_prob):\n",
    "\n",
    "    # Sampling\n",
    "    samples = np.random.binomial(1, gen_prob, gen_prob.shape)\n",
    "\n",
    "    return samples\n",
    "\n",
    "def test_samples(gen_prob):\n",
    "    out = torch.zeros(gen_prob.shape)\n",
    "    out[gen_prob>0.5] = 1\n",
    "    return out\n",
    "\n",
    "## Mask generation\n",
    "\n",
    "class get_prob_mask(torch.nn.Module):\n",
    "    def __init__(self,img_size,patch_size):\n",
    "        super(get_prob_mask, self).__init__()\n",
    "        self.i_h = img_size[0]\n",
    "        self.i_w = img_size[1]\n",
    "        self.p_h = patch_size[0]\n",
    "        self.p_w = patch_size[1]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        b,c,h,w = x.size()\n",
    "        mask = torch.zeros((b,c,self.i_h,self.i_w))\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                mask[0][0][i*self.p_h:(i+1)*self.p_h,j*self.p_w:(j+1)*self.p_w] = x[0][0][i,j]\n",
    "                #import pdb;pdb.set_trace()\n",
    "        return mask\n",
    "    \n",
    "\n",
    "## DC-INVASE class\n",
    "\n",
    "class dc_invase():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialization\n",
    "        self.data_dir =  '../Data/oxford_pets/sparse_images/'\n",
    "        self.train_csv = '../CSV/oxford_pet_train.csv'\n",
    "        self.num_epochs = 10\n",
    "        self.input_shape = (256,256)\n",
    "        self.patch_shape = (16,16)\n",
    "        self.batch_size = 1\n",
    "        self.img_mean = [0,0,0]#[0.485, 0.456, 0.406]\n",
    "        self.img_std = [1,1,1]#[0.229, 0.224, 0.225]\n",
    "        self.alpha = 1\n",
    "        self.beta = 0.005#0.05 for 64x64\n",
    "        self.exp_name = './Weights/dci_patchwise_16x16_oxford_share_cam'\n",
    "        \n",
    "        #Define the four models\n",
    "        self.baseline = build_pdb()\n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.baseline = self.baseline.cuda()\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.input_shape,self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "        #Define optimizers one for each model\n",
    "        self.optimizer_base = optim.Adam(self.baseline.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5, amsgrad=False)\n",
    "        \n",
    "        #Define the interpolation function\n",
    "        self.prob_mask = get_prob_mask(self.input_shape,self.patch_shape)\n",
    "             \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        best_iou = 0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':                \n",
    "                    #Set the models to training mode\n",
    "                    self.baseline.train()\n",
    "                \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    self.baseline.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_sel_loss = 0.0\n",
    "                running_base_loss = 0.0\n",
    "                running_pred_loss = 0.0\n",
    "                running_dis_loss = 0.0\n",
    "                running_final_base = 0.0\n",
    "                running_spa = 0.0\n",
    "              \n",
    "                #Metrics : accuracy\n",
    "                running_pred_acc = 0\n",
    "                running_dis_acc = 0\n",
    "                running_base_acc = 0\n",
    "                running_iou = 0\n",
    "\n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    labels = sampled_batch['category']\n",
    "                    mask = sampled_batch['mask']\n",
    "                    \n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    labels = labels.long().to(self.device)\n",
    "                    mask = mask.to(self.device)\n",
    "                    \n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer_base.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        \n",
    "                        #import pdb;pdb.set_trace()\n",
    "                        \n",
    "                        #Generate predictor output probabilities\n",
    "                        base_out,feat = self.baseline(inputs)\n",
    "                        base_prob = F.softmax(base_out)\n",
    "                        _, base_preds = torch.max(base_out, 1)\n",
    "                        \n",
    "                        #=>Baseline Cross entropy\n",
    "                        base_ce_loss = F.cross_entropy(base_out,labels)\n",
    "                        \n",
    "                        #Get the parameters list\n",
    "                        params = list(self.baseline.parameters())\n",
    "\n",
    "                        #Final layer weights\n",
    "                        weight_softmax = torch.squeeze(params[-2].data)\n",
    "                        \n",
    "                        c,h,w = feat[0].shape\n",
    "                        \n",
    "                        #Get the CAM which will the prob map\n",
    "                        cam = torch.matmul(weight_softmax[labels[0]],feat[0].reshape(c,h*w))\n",
    "                        sel_prob = (cam.reshape(h,w)).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "                        sel_prob = sel_prob - sel_prob.min()\n",
    "                        sel_prob = sel_prob/sel_prob.max()\n",
    "                        #print(sel_prob)\n",
    "                                                                       \n",
    "                        pred_ce_loss = 0\n",
    "                        dis_loss = 0\n",
    "                        sel_loss = 0\n",
    "                        sparsity = 0\n",
    "                        iou = 0\n",
    "                        \n",
    "                        no_of_samples = 1\n",
    "                        for sampling_ind in range(no_of_samples):\n",
    "                        \n",
    "                            #Sample using the selector distribution.\n",
    "                            bin_samples = sampler(sel_prob.data.cpu().numpy())\n",
    "                            \n",
    "                            #print(bin_samples,phase)\n",
    "                            \n",
    "                            bin_samples = torch.Tensor(bin_samples).to(self.device)\n",
    "                            \n",
    "                            #Interpolate the selector output\n",
    "                            bin_mask = self.prob_mask(bin_samples).to(self.device)\n",
    "                            #print(bin_samples)\n",
    "                            \n",
    "                            #Compute the sparsity and iou\n",
    "                            sparsity+=torch.mean(bin_samples)\n",
    "                            #print(sparsity)\n",
    "                            iou+=get_IoU(bin_mask,mask)\n",
    "\n",
    "                            #Compute the Complementary selection probability\n",
    "                            comp_bin_mask = 1 - bin_mask\n",
    "\n",
    "                            #Generate X_S the selection probability masked image\n",
    "                            x_s = inputs*bin_mask\n",
    "\n",
    "                            #Generate X_S_bar the complementary selection probability masked image\n",
    "                            x_s_bar = inputs*comp_bin_mask\n",
    "\n",
    "                            #Generate predictor output probabilities using the baseline cnn\n",
    "                            pred_out,_ = self.baseline(x_s)\n",
    "                            pred_prob = F.softmax(pred_out)\n",
    "                            _, pred_preds = torch.max(pred_out, 1)\n",
    "\n",
    "                            #Generate discriminator probabilities using the baseline cnn\n",
    "                            dis_out,_ = self.baseline(x_s_bar)\n",
    "                            dis_prob = F.softmax(dis_out)\n",
    "                            _, dis_preds = torch.max(dis_out, 1)\n",
    "                            #dis_metric += torch.mean(torch.abs(dis_prob-0.5)) \n",
    "                            #print(torch.mean(torch.abs(dis_prob-0.5)))\n",
    "                            \n",
    "                            #Predictor Cross entropy\n",
    "                            pred_ce_loss += F.cross_entropy(pred_out,labels)\n",
    "\n",
    "                            #Discriminator loss = probability of the actual label\n",
    "                            dis_loss += dis_prob[0][labels[0]]\n",
    "                            #print(pred_out,dis_out,labels)\n",
    "\n",
    "                            with torch.no_grad():\n",
    "                                dis_ce_loss = F.cross_entropy(dis_out,labels)\n",
    "\n",
    "                                #first KL divergence term\n",
    "                                kl_1 = -base_ce_loss + pred_ce_loss\n",
    "\n",
    "                                #second KL divergence term\n",
    "                                kl_2 = -base_ce_loss + dis_ce_loss\n",
    "\n",
    "                                #the difference in the two KL divergence terms\n",
    "                                kl_diff = kl_1 - self.alpha*kl_2\n",
    "\n",
    "                            #Selector function loss\n",
    "                            #l1_loss = torch.mean(sel_prob)                        \n",
    "\n",
    "                            distribution_loss = torch.mean(bin_samples*torch.log(sel_prob + 1e-8) + (1-bin_samples)*torch.log(1 - sel_prob + 1e-8))\n",
    "\n",
    "                            sel_loss += distribution_loss*kl_diff #+ self.beta*l1_loss\n",
    "                            #print(distribution_loss*kl_diff,self.beta*l1_loss)\n",
    "                            \n",
    "                        pred_ce_loss /= no_of_samples\n",
    "                        dis_loss /= no_of_samples\n",
    "                        sel_loss /= no_of_samples\n",
    "                        sparsity /= no_of_samples\n",
    "                        iou /= no_of_samples\n",
    "                        \n",
    "                        final_baseline_loss = base_ce_loss + pred_ce_loss + dis_loss + sel_loss\n",
    "                        \n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            #The gradients of pred_ce_loss should not update the params of disc or sel\n",
    "                            final_baseline_loss.backward()\n",
    "                            self.optimizer_base.step()\n",
    "                                    \n",
    "                    # statistics\n",
    "                    running_sel_loss += sel_loss.item() * inputs.size(0)\n",
    "                    running_pred_loss += pred_ce_loss.item() * inputs.size(0)\n",
    "                    running_dis_loss += dis_loss.item() * inputs.size(0)\n",
    "                    running_base_loss += base_ce_loss.item() * inputs.size(0)\n",
    "                    running_final_base += final_baseline_loss.item() * inputs.size(0)\n",
    "                    running_spa += sparsity *inputs.size(0)\n",
    "                \n",
    "                    running_pred_acc += torch.sum(pred_preds == labels.data)\n",
    "                    running_dis_acc += torch.sum(dis_preds == (1-labels.data))\n",
    "                    running_base_acc += torch.sum(base_preds == labels.data)\n",
    "                    running_iou += iou * inputs.size(0)\n",
    "                    \n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "                epoch_base_loss = running_base_loss / self.dataset_sizes[phase]\n",
    "                epoch_final_base = running_final_base / self.dataset_sizes[phase]\n",
    "                epoch_sel_loss = running_sel_loss / self.dataset_sizes[phase]\n",
    "                epoch_pred_loss = running_pred_loss / self.dataset_sizes[phase]\n",
    "                epoch_dis_loss = running_dis_loss / self.dataset_sizes[phase]\n",
    "                epoch_spa = running_spa / self.dataset_sizes[phase]\n",
    "                \n",
    "                epoch_base_acc = running_base_acc.double()/ self.dataset_sizes[phase]\n",
    "                epoch_pred_acc = running_pred_acc.double() / self.dataset_sizes[phase]\n",
    "                epoch_dis_acc = running_dis_acc.double() / self.dataset_sizes[phase]\n",
    "                epoch_iou = running_iou / self.dataset_sizes[phase]\n",
    "                \n",
    "                print('{} Final_Base: {:.4f} Base_Loss: {:.4f} Sel_Loss: {:.4f} Pred_Loss: {:.4f} Dis_Loss: {:.4f} Spa: {:.4f} BAC: {:.4f} PAC: {:.4f} DAC: {:.4f} IoU: {:.4f}'.format(\n",
    "                    phase, epoch_final_base, epoch_base_loss, epoch_sel_loss, epoch_pred_loss, epoch_dis_loss, epoch_spa, epoch_base_acc, epoch_pred_acc, epoch_dis_acc,epoch_iou))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and epoch_iou > best_iou:\n",
    "                    \n",
    "                    best_iou = epoch_iou\n",
    "                    torch.save(self.baseline.state_dict(),self.exp_name+'_base.pt')\n",
    "                    #import pdb;pdb.set_trace()\n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best iou: {:4f}'.format(best_iou))\n",
    "\n",
    "        torch.save(self.baseline.state_dict(),self.exp_name+'_base_final.pt')\n",
    "        torch.save(self.selector.state_dict(),self.exp_name+'_sel_final.pt')\n",
    "\n",
    "        print('Training completed finally !!!!!')\n",
    "        \n",
    "    def get_cam(self):\n",
    "                \n",
    "        #self.selector.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.baseline.load_state_dict(torch.load(self.exp_name+'_base.pt'))\n",
    "        self.baseline.eval()\n",
    "        \n",
    "        acc = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        cm = []\n",
    "        m = []\n",
    "        bm = []\n",
    "        \n",
    "        iou = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pbar = tqdm(total=self.dataset_sizes[mode])\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                inputs = data['image']\n",
    "                labels = data['category']\n",
    "\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device) \n",
    "                \n",
    "                #sel_prob = self.selector(inputs)\n",
    "                #sel_prob = sel_prob - sel_prob.min()\n",
    "                #sel_prob = sel_prob/sel_prob.max()\n",
    "\n",
    "                #Generate predictor output probabilities\n",
    "                base_out,feat = self.baseline(inputs)\n",
    "                base_prob = F.softmax(base_out)\n",
    "                _, base_preds = torch.max(base_out, 1)\n",
    "\n",
    "                #=>Baseline Cross entropy\n",
    "                base_ce_loss = F.cross_entropy(base_out,labels)\n",
    "\n",
    "                #Get the parameters list\n",
    "                params = list(self.baseline.parameters())\n",
    "\n",
    "                #Final layer weights\n",
    "                weight_softmax = torch.squeeze(params[-2].data)\n",
    "\n",
    "                c,h,w = feat[0].shape\n",
    "\n",
    "                #Get the CAM which will the prob map\n",
    "                cam = torch.matmul(weight_softmax[labels[0]],feat[0].reshape(c,h*w))\n",
    "                sel_prob = (cam.reshape(h,w)).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "                sel_prob = sel_prob - sel_prob.min()\n",
    "                sel_prob = sel_prob/sel_prob.max()\n",
    "\n",
    "                #Threshold using 0.5\n",
    "                #bin_samples = test_samples(sel_prob.data)\n",
    "                \n",
    "                #Sample using the distribution induced\n",
    "                bin_samples = sampler(sel_prob.data.cpu().numpy())\n",
    "                bin_samples = torch.Tensor(bin_samples).to(self.device)\n",
    "                bin_mask = self.prob_mask(bin_samples).to(self.device) \n",
    "\n",
    "                base_path = '../Experiments/Oxford_pets/'\n",
    "                name = data['name'][0]\n",
    "\n",
    "                #heatmap = cv2.applyColorMap(np.uint8(255*bin_mask.cpu().numpy().squeeze()), cv2.COLORMAP_JET)\n",
    "                heatmap = bin_mask.cpu().numpy().squeeze()\n",
    "                heatmap = np.expand_dims(heatmap,axis=2)\n",
    "                #heatmap = np.float32(heatmap) / 255\n",
    "                cam_f = heatmap*np.float32(inputs.cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "                cam_f = cam_f / np.max(cam_f)\n",
    "                #cam_f = heatmap\n",
    "                pr = name.replace('.j','_bin_16x16_samp_share_cam.j')\n",
    "                cv2.imwrite(base_path+pr,cam_f*255)\n",
    "\n",
    "                \n",
    "                pbar.update(inputs.shape[0])\n",
    "                \n",
    "            pbar.close()\n",
    "        \n",
    "\n",
    "    def return_model(self):\n",
    "        self.selector.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.selector.eval()\n",
    "        return self.selector,self.dataloaders['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dc = dc_invase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9f0b551bed497bae60789e6ed36ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dc.get_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9893ac6cdd461a94e50cd382be7f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Final_Base: 1.4542 Base_Loss: 0.3849 Sel_Loss: 0.2832 Pred_Loss: 0.3234 Dis_Loss: 0.4626 Spa: 0.2703 BAC: 0.8279 PAC: 0.8454 DAC: 0.5228 IoU: 0.1926\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bfebb6e45f4bf191a38b3cd45692d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid Final_Base: 3.1288 Base_Loss: 1.4676 Sel_Loss: 0.5632 Pred_Loss: 0.5908 Dis_Loss: 0.5073 Spa: 0.2651 BAC: 0.7400 PAC: 0.7120 DAC: 0.4840 IoU: 0.1926\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20992f6a49a54eb58ad6d03d2cf8fcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Final_Base: 1.3399 Base_Loss: 0.2857 Sel_Loss: 0.3703 Pred_Loss: 0.2340 Dis_Loss: 0.4500 Spa: 0.2359 BAC: 0.8719 PAC: 0.8949 DAC: 0.5578 IoU: 0.1935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c0acd31dcb4328a1f49481262f7566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid Final_Base: 1.2705 Base_Loss: 0.3095 Sel_Loss: 0.1244 Pred_Loss: 0.3519 Dis_Loss: 0.4846 Spa: 0.1921 BAC: 0.8890 PAC: 0.7410 DAC: 0.5010 IoU: 0.2135\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbeed355c944b7fb22f630666022f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Final_Base: 1.3690 Base_Loss: 0.2672 Sel_Loss: 0.5131 Pred_Loss: 0.1833 Dis_Loss: 0.4054 Spa: 0.2392 BAC: 0.8844 PAC: 0.9270 DAC: 0.6203 IoU: 0.2022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab2776027dc42a4a8e31b85c9697cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid Final_Base: 1.6714 Base_Loss: 0.6149 Sel_Loss: 0.2666 Pred_Loss: 0.3309 Dis_Loss: 0.4591 Spa: 0.2521 BAC: 0.8570 PAC: 0.7870 DAC: 0.5750 IoU: 0.2436\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38143506d19402381012f5b8419c7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Final_Base: 1.3834 Base_Loss: 0.2133 Sel_Loss: 0.6751 Pred_Loss: 0.1469 Dis_Loss: 0.3480 Spa: 0.2379 BAC: 0.9125 PAC: 0.9405 DAC: 0.6898 IoU: 0.2094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb87079d1344111828289b59401640b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid Final_Base: 1.7898 Base_Loss: 0.3530 Sel_Loss: 0.3429 Pred_Loss: 0.6793 Dis_Loss: 0.4147 Spa: 0.2518 BAC: 0.8930 PAC: 0.7820 DAC: 0.6080 IoU: 0.2369\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efb0523624e4f4caa4f65918078905b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Final_Base: 1.3501 Base_Loss: 0.1992 Sel_Loss: 0.7251 Pred_Loss: 0.1379 Dis_Loss: 0.2879 Spa: 0.2136 BAC: 0.9230 PAC: 0.9450 DAC: 0.7489 IoU: 0.2050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834aff348c074d28b7a3ceb442376583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid Final_Base: 1.3671 Base_Loss: 0.2710 Sel_Loss: 0.0465 Pred_Loss: 0.5650 Dis_Loss: 0.4845 Spa: 0.2089 BAC: 0.8640 PAC: 0.6050 DAC: 0.5440 IoU: 0.1909\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c797acf0e3414c9acbd6623b16c0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Final_Base: 1.3539 Base_Loss: 0.1629 Sel_Loss: 0.8561 Pred_Loss: 0.1337 Dis_Loss: 0.2011 Spa: 0.1948 BAC: 0.9325 PAC: 0.9420 DAC: 0.8319 IoU: 0.1967\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006ad160cedc41fa89fa4cb3ae244c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid Final_Base: 5.5615 Base_Loss: 0.2214 Sel_Loss: -0.9067 Pred_Loss: 5.7845 Dis_Loss: 0.4624 Spa: 0.2099 BAC: 0.9020 PAC: 0.5000 DAC: 0.5290 IoU: 0.2001\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a08cd6747ad4e4a80eacb5202981196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Final_Base: 1.4569 Base_Loss: 0.1495 Sel_Loss: 1.0484 Pred_Loss: 0.1134 Dis_Loss: 0.1455 Spa: 0.1928 BAC: 0.9355 PAC: 0.9520 DAC: 0.8829 IoU: 0.1935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7aea4a269642c8922eb9e07fcaf592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid Final_Base: 1.5691 Base_Loss: 0.3051 Sel_Loss: 0.2536 Pred_Loss: 0.6090 Dis_Loss: 0.4014 Spa: 0.1974 BAC: 0.8720 PAC: 0.7600 DAC: 0.6720 IoU: 0.1745\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58865afb143409fb107c8e85ef2aa4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Final_Base: 1.4690 Base_Loss: 0.1313 Sel_Loss: 1.1284 Pred_Loss: 0.1203 Dis_Loss: 0.0890 Spa: 0.1705 BAC: 0.9500 PAC: 0.9595 DAC: 0.9335 IoU: 0.1763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1f15bc3ced45c6ad8e4487ca41a2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid Final_Base: 1.2785 Base_Loss: 0.2154 Sel_Loss: 0.3065 Pred_Loss: 0.3369 Dis_Loss: 0.4196 Spa: 0.1957 BAC: 0.9180 PAC: 0.8180 DAC: 0.6750 IoU: 0.1932\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77739ff0869c49c59499784ddab46432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Final_Base: 1.6836 Base_Loss: 0.1174 Sel_Loss: 1.3945 Pred_Loss: 0.0929 Dis_Loss: 0.0787 Spa: 0.1795 BAC: 0.9480 PAC: 0.9605 DAC: 0.9400 IoU: 0.1787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e328269bb65047a195ce3250e54f0714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid Final_Base: 1.6332 Base_Loss: 0.2937 Sel_Loss: 0.4097 Pred_Loss: 0.5397 Dis_Loss: 0.3901 Spa: 0.1835 BAC: 0.9070 PAC: 0.7560 DAC: 0.7270 IoU: 0.1947\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897ea569c9a74d198161fed7988dde42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Final_Base: 1.7717 Base_Loss: 0.1064 Sel_Loss: 1.5051 Pred_Loss: 0.0955 Dis_Loss: 0.0647 Spa: 0.1677 BAC: 0.9570 PAC: 0.9655 DAC: 0.9485 IoU: 0.1721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9060dd5fc6964cb1b4e66d2dc2d4ed2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "valid Final_Base: 2.6094 Base_Loss: 0.2614 Sel_Loss: 0.6885 Pred_Loss: 1.2977 Dis_Loss: 0.3619 Spa: 0.1749 BAC: 0.9000 PAC: 0.6660 DAC: 0.7000 IoU: 0.1650\n",
      "Training complete in 29m 22s\n",
      "Best iou: 0.243601\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dc_invase' object has no attribute 'selector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4e103abb286a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-eebdd1b61112>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_base_final.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_sel_final.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training completed finally !!!!!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dc_invase' object has no attribute 'selector'"
     ]
    }
   ],
   "source": [
    "dc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
