{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "#PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "#Others\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = self.root_dir.replace('CBIS-DDSM_classification','masks')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']\n",
    "\n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'].replace('.j','_mask.j'))\n",
    "        mask = io.imread(mask_name)\n",
    "        mask = np.array([mask,mask,mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask) \n",
    "      \n",
    "        return {'image':image,'category':label,'mask':mask, 'name':img_name}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(image_size),#row to column ratio should be 1.69\n",
    "            #transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomVerticalFlip(0.5),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "\n",
    "        if x!= 'test':\n",
    "            dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,shuffle=True, num_workers=4)\n",
    "        else:\n",
    "            dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,shuffle=False, num_workers=4)\n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm_img(img_ten,img_mean,img_std):\n",
    "\n",
    "    bz,nc,h,w = img_ten.shape\n",
    "    output = []\n",
    "    img_num = img_ten.numpy()\n",
    "    #img_num = img_ten\n",
    "    \n",
    "    for i in range(bz):\n",
    "        \n",
    "        #import pdb;pdb.set_trace()\n",
    "        img = img_ten[i].numpy().squeeze()\n",
    "        #img = img_ten[i].squeeze()\n",
    "        \n",
    "        img[0,:,:] = img[0,:,:]*img_std[0]\n",
    "        img[1,:,:] = img[1,:,:]*img_std[1]\n",
    "        img[2,:,:] = img[2,:,:]*img_std[2]\n",
    "\n",
    "        img[0,:,:] = img[0,:,:] + img_mean[0]\n",
    "        img[1,:,:] = img[1,:,:] + img_mean[1]\n",
    "        img[2,:,:] = img[2,:,:] + img_mean[2]\n",
    "        \n",
    "        output.append(img)\n",
    "    \n",
    "    output = np.array(output)\n",
    "        \n",
    "    return output\n",
    "\n",
    "def dice(pred, targs):\n",
    "    targs = (targs>0)#.float()\n",
    "    pred = (pred>0)#.float()\n",
    "    return 2. * (pred*targs).sum() / (pred+targs).sum()\n",
    "\n",
    "#ir2 = pretrainedmodels.__dict__['inceptionresnetv2'](num_classes=1000, pretrained='imagenet')\n",
    "#ir1 = nn.Sequential(*list(ir2.children())[:-1])\n",
    "#summary(ir1.cuda(),(3,540,320))\n",
    "\n",
    "#vggnet = models.vgg11_bn(pretrained=True)\n",
    "#vgg_conv = nn.Sequential(*list(vggnet.children())[0][:-1])\n",
    "\n",
    "class vgg_gain(nn.Module):\n",
    "    def __init__(self,vgg_base):\n",
    "        super().__init__()\n",
    "        self.vgg_base = vgg_base\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))#nn.AvgPool2d((14,14),stride=1)\n",
    "        self.fc = nn.Linear(512,2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vgg_base(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "#v = vgg_gain(vgg_conv)\n",
    "#v.vgg_base[28]\n",
    "\n",
    "class SaveFeatures:\n",
    "    def __init__(self, m):\n",
    "        self.handle = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, m, inp, outp):\n",
    "        self.features = outp\n",
    "    def remove(self):\n",
    "        self.handle.remove()\n",
    "\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx, output_shape):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = output_shape\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for i in range(bz):\n",
    "        #import pdb;pdb.set_trace()\n",
    "        idx = class_idx[0][i]\n",
    "        cam = weight_softmax[idx].dot(feature_conv[i].reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        #cam = cam - np.min(cam)\n",
    "        #cam_img = cam / np.max(cam)\n",
    "        #print('cam img shape',cam_img.shape)\n",
    "        cam_img = cv2.resize(cam,(size_upsample[0],size_upsample[1]))\n",
    "        cam_img[cam_img<0] = 0\n",
    "        output_cam.append(cam_img)\n",
    "    output_cam = np.array(output_cam)\n",
    "    \n",
    "    final_output_cam = np.zeros((bz,3,size_upsample[1],size_upsample[0]))\n",
    "    final_output_cam[:,0,:,:] = output_cam\n",
    "    final_output_cam[:,1,:,:] = output_cam\n",
    "    final_output_cam[:,2,:,:] = output_cam\n",
    "    \n",
    "    return final_output_cam\n",
    "\n",
    "def mining_loss(mining_output,labels):\n",
    "    mining_output = mining_output\n",
    "    min_loss = 0\n",
    "    #import pdb;pdb.set_trace()\n",
    "    for i in range(mining_output.shape[0]):\n",
    "        min_loss+=mining_output[i][labels[i]]\n",
    "    \n",
    "    min_loss = min_loss/mining_output.shape[0]\n",
    "    return min_loss\n",
    "\n",
    "def gain_train_model(model, dataloaders, dataset_sizes, device, stream_loss, optimizer, scheduler, img_mean, img_std, num_epochs=25, sigma=0, w=1, alpha=1):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1),flush=True)\n",
    "        print('-' * 10,flush=True)\n",
    "        \n",
    "        #import pdb;pdb.set_trace()\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_dice = 0\n",
    "\n",
    "            #tqdm bar\n",
    "            pbar = tqdm(total=dataset_sizes[phase])            \n",
    "            # Iterate over data.\n",
    "            for sampled_batch in dataloaders[phase]:\n",
    "                \n",
    "                inputs = sampled_batch['image']\n",
    "                labels = sampled_batch['category']\n",
    "                mask = sampled_batch['mask']\n",
    "                \n",
    "                inputs = inputs.float().to(device)\n",
    "                labels = labels.long().to(device)\n",
    "                #print('labels shape',labels.shape)\n",
    "                #print(mask.shape)\n",
    "                mask = denorm_img(mask,img_mean,img_std).squeeze()\n",
    "                #print('mask shape',mask.shape)\n",
    "                mask[mask>0.1] = 1\n",
    "                mask[mask<0.1] = 0\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    #CAM computation need to take place in eval mode\n",
    "#                     if phase == 'train':\n",
    "#                         print('yaay')\n",
    "#                         model.eval()\n",
    "                    \n",
    "                    #Save features for the forward pass\n",
    "                    sfs = SaveFeatures(model.vgg_base[27])\n",
    "                    outputs = torch.exp(model(inputs))\n",
    "                    #print('outputs shape',outputs.shape)\n",
    "                    sfs.remove()\n",
    "                    \n",
    "                    #print(sfs.features.requires_grad)\n",
    "                    #Get the features obtained after forward pass\n",
    "                    features = sfs.features.detach().cpu().numpy()\n",
    "                    #print('Features shape',features.shape)\n",
    "                    \n",
    "                    #This will get the prediction for the sample\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    #Get the weights of the model\n",
    "                    params = list(model.parameters())\n",
    "                    weight_softmax = np.squeeze(params[-2].data.cpu().numpy())\n",
    "                    \n",
    "                    #Get the CAM\n",
    "                    cam_orig = np.array(returnCAM(features,weight_softmax,[preds],(inputs.size(-1),inputs.size(-2))))\n",
    "                    #print('cam orig shape',cam_orig.shape)\n",
    "                    \n",
    "                    #Convert cam to tensor\n",
    "                    cam = torch.from_numpy(cam_orig).float().to(device)\n",
    "                    #print('cam shape',cam.shape)\n",
    "                    #import pdb\n",
    "                    #pdb.set_trace()\n",
    "                    \n",
    "                    #T(A) as defined in the paper\n",
    "                    t_cam = F.sigmoid(w*(cam - sigma))\n",
    "                    #print('t cam shape',t_cam.shape)\n",
    "                    #print('inputs shape',inputs.shape)\n",
    "                    \n",
    "                    #Mining input\n",
    "                    mining_input = inputs - t_cam*inputs\n",
    "                    #print('mining_input shape',mining_input.shape)\n",
    "                    \n",
    "                    #Compute the mining output\n",
    "                    mining_output = torch.exp(model(mining_input))\n",
    "                    \n",
    "#                     #Convert to training mode\n",
    "#                     if phase == 'train':\n",
    "#                         model.train()\n",
    "                    \n",
    "                    #Compute the stream loss\n",
    "                    loss_stream = stream_loss(outputs, labels)\n",
    "                    \n",
    "                    #print('labels shape',labels.shape)\n",
    "                    #Compute the mining loss\n",
    "                    loss_mining = mining_loss(mining_output,labels)\n",
    "                    \n",
    "                    #import pdb;pdb.set_trace()\n",
    "\n",
    "                    #Total loss is the sum of the two loss\n",
    "                    loss = loss_stream + alpha*loss_mining\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                running_dice += dice(cam_orig,mask)\n",
    "                \n",
    "                pbar.update(inputs.shape[0])\n",
    "            pbar.close()\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            epoch_dice = running_dice / dataset_sizes[phase]\n",
    "                                        \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Dice: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_dice))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(),'gain_vgg_'+str(epoch_acc)+'_acc.pt')\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    #model.save_state_dict('vgg_gain.pt')\n",
    "    return model\n",
    "\n",
    "data_dir = '../Data/CBIS-DDSM_classification_1/'\n",
    "train_csv = '../CSV/gain_train.csv'\n",
    "#image_size = (640,384)\n",
    "image_size = (320,192)\n",
    "num_classes = 2\n",
    "num_epochs = 50\n",
    "sigma = 0\n",
    "w = 1\n",
    "alpha = 1\n",
    "img_mean = [0.223, 0.231, 0.243]\n",
    "img_std = [0.266, 0.270, 0.274]\n",
    "\n",
    "dataloaders,dataset_sizes,dataset,device = get_classification_dataloader(data_dir,train_csv,image_size,img_mean,img_std,12)\n",
    "\n",
    "#i = iter(dataloaders['train']).next()\n",
    "# d = denorm_img(i['image'],img_mean,img_std)\n",
    "# plt.imshow(d.transpose((1,2,0)))\n",
    "\n",
    "vggnet = models.vgg11_bn(pretrained=True)\n",
    "vgg_conv = nn.Sequential(*list(vggnet.children())[0][:-1])\n",
    "v1 = vgg_gain(vgg_conv).to(device)\n",
    "\n",
    "params = v1.parameters()\n",
    "stream_loss = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "#optimizer_ft = optim.SGD(params, lr=0.01, momentum=0.9)\n",
    "optimizer_ft = optim.Adam(params, lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "lr_sched = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "model_ft = gain_train_model(v1, dataloaders, dataset_sizes, device, stream_loss, optimizer_ft, lr_sched, img_mean, img_std, num_epochs, sigma, w, alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
