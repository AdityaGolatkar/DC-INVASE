{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "  \n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = self.root_dir.replace('CBIS-DDSM_classification','masks')\n",
    "        self.bmask_dir = self.root_dir.replace('CBIS-DDSM_classification','breast_mask')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']\n",
    "\n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'].replace('.j','_mask.j'))\n",
    "        mask = io.imread(mask_name)\n",
    "        mask = np.array([mask,mask,mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)\n",
    "        \n",
    "        bmask_name = os.path.join(self.bmask_dir,self.data_frame.iloc[idx]['name'].replace('.j','_bmask.j'))\n",
    "        bmask = io.imread(bmask_name)\n",
    "        bmask = np.array([bmask,bmask,bmask]).transpose((1,2,0))\n",
    "        bmask = Image.fromarray(bmask)\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask) \n",
    "            bmask = self.transform(bmask)\n",
    "    \n",
    "        return {'image':image,'category':label,'mask':mask, 'bmask':bmask, 'name':self.data_frame.iloc[idx]['name']}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(image_size),#row to column ratio should be 1.69\n",
    "            #transforms.RandomHorizontalFlip(0.5),\n",
    "            #transforms.CenterCrop((image_size[1],image_size[1])),\n",
    "            transforms.RandomVerticalFlip(0.5),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.RandomAffine(translate=(0,0.2),degrees=15,shear=15),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            #transforms.CenterCrop((image_size[1],image_size[1])),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            #transforms.CenterCrop((image_size[1],image_size[1])),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        if x == 'test':\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        else:\n",
    "            bs = batch_size\n",
    "            sh = True\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=bs,shuffle=sh, num_workers=8)    \n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "\n",
    "def build_model():\n",
    "\n",
    "    class mdl(nn.Module):\n",
    "        def __init__(self,base_model):\n",
    "            super().__init__()\n",
    "            self.base = base_model \n",
    "            self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.fc1 = nn.Linear(512,2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x_base = self.base(x)\n",
    "            x = self.gap(x_base)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            return x,x_base \n",
    "\n",
    "    v = models.vgg16_bn(pretrained=True)\n",
    "    v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "\n",
    "    #r = models.resnet101(pretrained=True)\n",
    "    #r1 = nn.Sequential(*list(r.children())[:-2])\n",
    "    model = mdl(v1[-1][:-1])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def denorm_img(img_ten,img_mean,img_std):\n",
    "\n",
    "    bz,nc,h,w = img_ten.shape\n",
    "    output = []\n",
    "    img_num = img_ten.numpy()\n",
    "    \n",
    "    for i in range(bz):\n",
    "        \n",
    "        img = img_ten[i].numpy().squeeze()\n",
    "        \n",
    "        img[0,:,:] = img[0,:,:]*img_std[0]\n",
    "        img[1,:,:] = img[1,:,:]*img_std[1]\n",
    "        img[2,:,:] = img[2,:,:]*img_std[2]\n",
    "\n",
    "        img[0,:,:] = img[0,:,:] + img_mean[0]\n",
    "        img[1,:,:] = img[1,:,:] + img_mean[1]\n",
    "        img[2,:,:] = img[2,:,:] + img_mean[2]\n",
    "        \n",
    "        img = img.mean(axis=0)\n",
    "        img[img>=0.2*img.max()] = 1\n",
    "        img[img<0.2*img.max()] = 0\n",
    "        \n",
    "        output.append(img)\n",
    "    \n",
    "    output = np.array(output)\n",
    "    return output\n",
    "    \n",
    "def get_IoU(pred, targs, device):\n",
    "\n",
    "    targs = torch.Tensor(targs).to(device)\n",
    "    \n",
    "    #targs = torch.Tensor((targs>0)).to(device)#.float()\n",
    "    #pred = (pred>0)#.float()\n",
    "    return (pred*targs).sum() / ((pred+targs).sum() - (pred*targs).sum())\n",
    "    \n",
    "    #return (pred*targs).sum()/targs.sum()\n",
    "\n",
    "\n",
    "class grad_cam():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialization\n",
    "        self.data_dir = '../Data/CBIS-DDSM_classification_orient/'\n",
    "        self.train_csv = '../CSV/gain_train.csv'\n",
    "        self.num_epochs = 50\n",
    "        self.input_shape = (320,256)#(640,512) #(640,512)#(224,224)#(640,384) (640,512)\n",
    "        self.batch_size = 16\n",
    "        self.img_mean = [0.223, 0.231, 0.243]\n",
    "        self.img_std = [0.266, 0.270, 0.274]\n",
    "        \n",
    "        self.exp_name = 'grad_cam_vgg_16'\n",
    "        \n",
    "        #Define the three models\n",
    "        self.model = build_model()\n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.model = self.model.cuda()\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.input_shape,self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(),lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        #Define the three optimizers one for each model\n",
    "        \n",
    "\t#self.optimizer = optim.Adam([{'params':self.model.gap.parameters()},\n",
    "        #                            {'params':self.model.fc1.parameters()},\n",
    "        #                            {'params':self.model.base[:6].parameters(),'lr':0.0001},\n",
    "        #                            {'params':self.model.base[6:].parameters(),'lr':0.001}], lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        best_epoch_acc = 0.0\n",
    "        best_epoch_f1 = 0.0\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':\n",
    "                    \n",
    "                    #Set the models to training mode\n",
    "                    self.model.train()\n",
    "                \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    self.model.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                #Metrics : predictor auc and selector iou\n",
    "                running_acc = 0\n",
    "                running_f1 = 0\n",
    "                \n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    labels = sampled_batch['category']\n",
    "                    mask = denorm_img(sampled_batch['mask'],self.img_mean,self.img_std)\n",
    "                    bmask = torch.Tensor(denorm_img(sampled_batch['bmask'],self.img_mean,self.img_std)).to(self.device)\n",
    "\n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    labels = labels.long().to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer.zero_grad()\n",
    "                \n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        \n",
    "                        #import pdb;pdb.set_trace()\n",
    "                        \n",
    "                        outputs,_ = self.model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            loss.backward()\n",
    "                            self.optimizer.step()\n",
    "                                    \n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_acc += torch.sum(preds == labels.data)\n",
    "                    running_f1 += f1_score(labels.data,preds)*inputs.size(0)\n",
    "                    \n",
    "\n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "                epoch_loss = running_loss / self.dataset_sizes[phase]\n",
    "                epoch_acc = running_acc.double() / self.dataset_sizes[phase]\n",
    "                epoch_f1 = 1.0*running_f1 / self.dataset_sizes[phase]\n",
    "\n",
    "                print('{} Sel_Loss: {:.4f} Acc: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_acc,  epoch_f1))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and epoch_f1 > best_epoch_f1:\n",
    "                    best_epoch_f1 = epoch_f1\n",
    "                    torch.save(self.model.state_dict(),self.exp_name+'_sel.pt')\n",
    "                    \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best Sel Loss: {:4f}'.format(best_sel_loss))\n",
    "\n",
    "        torch.save(self.model.state_dict(),self.exp_name+'_sel_final.pt')\n",
    "        \n",
    "        print('Training completed finally !!!!!')\n",
    "        \n",
    "        \n",
    "    def get_output(self,input_data):\n",
    "        \n",
    "        return self.selector(input_data).numpy()\n",
    "        \n",
    "    def test_model(self):\n",
    "                \n",
    "        self.selector.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.selector.eval()\n",
    "        \n",
    "        mIoU = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                images = data['image']\n",
    "                mask = data['mask']\n",
    "\n",
    "                images = images.to(self.device)\n",
    "                \n",
    "                sel_prob = make_prob(self.selector(images))\n",
    "                iou = get_IoU(sel_prob,mask)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                mIoU += iou\n",
    "\n",
    "        print(\"mIoU:\", 1.0*mIoU/total)\n",
    "        \n",
    "    def test_model_auc(self):\n",
    "                \n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.model.eval()\n",
    "        \n",
    "        acc = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        predictions = []\n",
    "        ground_truth = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pbar = tqdm(total=self.dataset_sizes[mode])\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                inputs = data['image']\n",
    "                labels = data['category']\n",
    "                \n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                output,_ = F.sigmoid(self.model(inputs))\n",
    "                _,out = torch.max(output,1)\n",
    "                \n",
    "                predictions.append(output.cpu().numpy())\n",
    "                ground_truth.append(labels.cpu().numpy())\n",
    "                #ground_truth.append(labels.cpu())\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                acc += torch.sum(out==labels.data)\n",
    "                pbar.update(inputs.shape[0])\n",
    "            pbar.close()\n",
    "                \n",
    "        pred = predictions[0]\n",
    "        for i in range(len(predictions)-1):\n",
    "            pred = np.concatenate((pred,predictions[i+1]),axis=0)\n",
    "            \n",
    "        gt = ground_truth[0]\n",
    "        for i in range(len(ground_truth)-1):\n",
    "            gt = np.concatenate((gt,ground_truth[i+1]),axis=0)\n",
    "            \n",
    "        #import pdb;pdb.set_trace()\n",
    "        auc = roc_auc_score(gt,pred[:,1],average='weighted')\n",
    "        \n",
    "        print(\"AUC:\", auc)\n",
    "        print(\"ACC:\", acc.double()/total)\n",
    "        \n",
    "\n",
    "    def get_cam(self):\n",
    "                \n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.model.eval()\n",
    "        \n",
    "        acc = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        cm = []\n",
    "        m = []\n",
    "        bm = []\n",
    "        \n",
    "        params = list(self.model.parameters())                        \n",
    "        weight_softmax = torch.squeeze(params[-2].data)\n",
    "        \n",
    "        iou = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pbar = tqdm(total=self.dataset_sizes[mode])\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                inputs = data['image']\n",
    "                labels = data['category']\n",
    "                mask = denorm_img(data['mask'],self.img_mean,self.img_std)\n",
    "                bmask = torch.Tensor(denorm_img(data['bmask'],self.img_mean,self.img_std)).to(self.device)\n",
    "                \n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                output,feat = self.model(inputs)\n",
    "                _,out = torch.max(output,1)      \n",
    "\n",
    "                #Get the CAM which will the prob map\n",
    "                cam = torch.matmul(weight_softmax[out[0]],feat[0].reshape(feat[0].shape[0],feat[0].shape[1]*feat[0].shape[2]))\n",
    "                cam = F.relu(cam.reshape(feat[0].shape[1], feat[0].shape[2]))\n",
    "                cam_img = F.interpolate(cam.unsqueeze(dim=0).unsqueeze(dim=0),(self.input_shape[0],self.input_shape[1]),mode='bilinear')             \n",
    "                \n",
    "                c_mean = cam_img.mean()\n",
    "                c_std = cam_img.std()\n",
    "                c_max = cam_img.max()\n",
    "                \n",
    "                cam_bin = F.relu(cam_img)\n",
    "                cam_bin[cam_bin>0] = 1\n",
    "                #cam_bin[cam_img<0] = 0\n",
    "                \n",
    "                iou += get_IoU(cam_bin,mask,self.device)\n",
    "                #import pdb;pdb.set_trace()\n",
    "                #print(iou)\n",
    "                \n",
    "                m.append(mask.squeeze())\n",
    "                bm.append(bmask.squeeze())\n",
    "                cm.append(cam_img.cpu().numpy().squeeze())\n",
    "                                \n",
    "                base_path = '../Experiments/CAM/'\n",
    "                name = data['name'][0]\n",
    "                \n",
    "                im = name.replace('.j','_1.j')\n",
    "                #import pdb;pdb.set_trace()\n",
    "                cv2.imwrite(base_path+im,inputs.cpu().numpy().squeeze().transpose((1,2,0))*255)\n",
    "                \n",
    "                ma = name.replace('.j','_2.j')\n",
    "                cv2.imwrite(base_path+ma,mask.squeeze()*255)\n",
    "\n",
    "                pr = name.replace('.j','_3.j')\n",
    "                cv2.imwrite(base_path+pr,cam_img.cpu().numpy().squeeze()*255)\n",
    "                \n",
    "                pbar.update(inputs.shape[0])\n",
    "                \n",
    "            pbar.close()\n",
    "\n",
    "        print('mIoU:',iou.double()/self.dataset_sizes[mode])\n",
    "\n",
    "        return m,bm,cm\n",
    "                \n",
    "        \n",
    "    def return_model(self):\n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.model.eval()\n",
    "        mode = 'test'\n",
    "        return self.model,self.dataloaders[mode]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = grad_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1230b9e602d54e5d81347584fc82dc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=645), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mIoU: tensor(0.0120, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a081d0898d8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "m,b,c = gc.get_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f283b9a3ef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = cv2.imread('../Experiments/CAM/Calc-Test_P_00038_LEFT_MLO_3.jpg')\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
