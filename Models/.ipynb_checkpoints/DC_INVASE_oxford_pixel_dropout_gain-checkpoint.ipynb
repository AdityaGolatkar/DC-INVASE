{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "  \n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import augmentations\n",
    "from augmentations import *\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import dataloaders\n",
    "from dataloaders import *\n",
    "\n",
    "## Dataloader\n",
    "\n",
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = self.root_dir.replace('images','masks')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'])\n",
    "        mask = io.imread(mask_name)\n",
    "        mask = np.array([mask,mask,mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']       \n",
    "\n",
    "        if self.transform:\n",
    "            image,mask = self.transform(image,mask)\n",
    "        \n",
    "        mask_final = mask[0,:,:]\n",
    "        mask_final[mask_final<0.5] = 0\n",
    "        mask_final[mask_final>0.5] = 1\n",
    "        \n",
    "        return {'image':image, 'category':label, 'mask':mask_final, 'name':self.data_frame.iloc[idx]['name']}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': Compose([\n",
    "            Resize(image_size),\n",
    "            RandomHorizontallyFlip(0.5),\n",
    "            RandomVerticallyFlip(0.5),\n",
    "            RandomTranslate((0.2,0.2)),\n",
    "            RandomRotate(15),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': Compose([\n",
    "            Resize(image_size),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': Compose([\n",
    "            Resize(image_size),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)        \n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        if x == 'test':\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        elif x == 'valid':\n",
    "            bs = batch_size\n",
    "            sh = False\n",
    "        else:\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=bs,shuffle=sh, num_workers=8)    \n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "# a,_,_,_ = get_dataloader('../Data/oxford_pets/sparse_images/','../CSV/oxford_pet_train.csv',(224,224),[0,0,0],[1,1,1])\n",
    "# b = iter(a['train']).next()\n",
    "\n",
    "# c = b['image'].squeeze().numpy().transpose((1,2,0))\n",
    "# plt.imshow(c)\n",
    "\n",
    "# b['mask'].shape\n",
    "\n",
    "# c = b['mask'].squeeze().numpy()\n",
    "# plt.imshow(c)\n",
    "\n",
    "## Selector network (VGG-UNet)\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return F.dropout2d(self.bn(F.relu(cat_p)),p=0.5) #Using dropout after non-linearity and before the \n",
    "\n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[0][i]) for i in [12,22,32,42]]\n",
    "        self.up1 = UnetBlock(512,512,256)\n",
    "        self.up2 = UnetBlock(256,512,256)\n",
    "        self.up3 = UnetBlock(256,256,256)\n",
    "        self.up4 = UnetBlock(256,128,256)\n",
    "        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x1 = self.up1(x, self.sfs[3].features)\n",
    "        x2 = self.up2(x1, self.sfs[2].features)\n",
    "        x3 = self.up3(x2, self.sfs[1].features)\n",
    "        x4 = self.up4(x3, self.sfs[0].features)\n",
    "        x5 = self.up5(x4)\n",
    "        return x5,x4,x3,x2,x1\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "\n",
    "def build_selector():\n",
    "    v = models.vgg16_bn(pretrained=True)\n",
    "    v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "    m = Unet34(v1)\n",
    "    return m\n",
    "\n",
    "# a = build_selector()\n",
    "# summary(a.cuda(),(3,224,224))\n",
    "\n",
    "## Predictor-Discriminator-Baseline\n",
    "\n",
    "def build_pdb():\n",
    "\n",
    "    class mdl(nn.Module):\n",
    "        def __init__(self,base_model):\n",
    "            super().__init__()\n",
    "            self.base = base_model \n",
    "            self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.fc1 = nn.Linear(512,2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x_base = self.base(x)\n",
    "            x = self.gap(x_base)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            return x\n",
    "\n",
    "    v = models.vgg16_bn(pretrained=True)\n",
    "    v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "    model = mdl(v1[-1][:-1])\n",
    "    \n",
    "    #Lets not load the weights because it may bias the CNN.\n",
    "    #model.load_state_dict(torch.load('Weights/grad_cam_vgg_16_dogcat.pt'))\n",
    "    model.eval()\n",
    "        \n",
    "    return model\n",
    "\n",
    "# a = build_pdb()\n",
    "# summary(a.cuda(),(3,224,224))\n",
    "\n",
    "def get_IoU(pred, targs):\n",
    "    return (pred*targs).sum() / ((pred+targs).sum() - (pred*targs).sum())\n",
    "\n",
    "## Sampler\n",
    "\n",
    "def sampler(gen_prob):\n",
    "\n",
    "    # Sampling\n",
    "    samples = np.random.binomial(1, gen_prob, gen_prob.shape)\n",
    "\n",
    "    return samples\n",
    "\n",
    "def test_samples(gen_prob):\n",
    "    out = torch.zeros(gen_prob.shape)\n",
    "    out[gen_prob>0.5] = 1\n",
    "    return out\n",
    "\n",
    "## DC-INVASE class\n",
    "\n",
    "class dc_invase():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialization\n",
    "        self.beta = 1e-5\n",
    "        \n",
    "        self.data_dir =  '../Data/oxford_pets/sparse_images/'\n",
    "        self.train_csv = '../CSV/oxford_pet_train.csv'\n",
    "        self.num_epochs = 300\n",
    "        self.input_shape = (224,224)#(640,512) #(640,512)#(224,224)#(640,384) (640,512)\n",
    "        self.batch_size = 1\n",
    "        self.img_mean = [0.485, 0.456, 0.406]#[0,0,0]\n",
    "        self.img_std = [0.229, 0.224, 0.225]#[1,1,1]\n",
    "        self.exp_name = 'Weights/dci_oxford_pixel_dropout_gain'\n",
    "        \n",
    "        #Define the three models\n",
    "        self.selector = build_selector()\n",
    "        #self.discriminator = build_pdb()\n",
    "        self.baseline = build_pdb()\n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.selector = self.selector.cuda()\n",
    "        #self.discriminator = self.discriminator.cuda()\n",
    "        self.baseline = self.baseline.cuda()\n",
    "        \n",
    "        self.baseline.load_state_dict(torch.load('Weights/grad_cam_vgg_16_oxford.pt'))\n",
    "#         self.discriminator.load_state_dict(torch.load('Weights/grad_cam_vgg_16_oxford.pt'))\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.input_shape,self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "        #Define the three optimizers one for each model\n",
    "        self.optimizer_sel = optim.Adam(self.selector.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5, amsgrad=False)\n",
    "        #self.optimizer_dis = optim.Adam(self.discriminator.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5, amsgrad=False)\n",
    "        self.optimizer_base = optim.Adam(self.baseline.parameters(), lr=1e-5, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5, amsgrad=False)\n",
    "           \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        \n",
    "        best_iou = 0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train','valid']:\n",
    "                if phase == 'train':\n",
    "                    \n",
    "                    #Set the models to training mode\n",
    "                    #self.discriminator.train()\n",
    "                    self.selector.train()\n",
    "                    self.baseline.train()\n",
    "                \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    #self.discriminator.eval()\n",
    "                    self.selector.eval()\n",
    "                    self.baseline.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_sel_loss = 0.0\n",
    "                #running_dis_loss = 0.0\n",
    "                running_base_loss = 0.0\n",
    "                running_spa = 0.0\n",
    "                running_int_spa = 0.0 #Intermediate sparsity\n",
    "                \n",
    "                #Metrics : accuracy\n",
    "                running_dis_acc = 0\n",
    "                running_base_acc = 0\n",
    "                running_iou = 0\n",
    "                running_bin_mask = 0\n",
    "\n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    labels = sampled_batch['category']\n",
    "                    masks = sampled_batch['mask']\n",
    "                    \n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    labels = labels.long().to(self.device)\n",
    "                    masks = masks.to(self.device)\n",
    "                    \n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer_sel.zero_grad()\n",
    "                    #self.optimizer_dis.zero_grad()\n",
    "                    self.optimizer_base.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        \n",
    "                        #import pdb;pdb.set_trace()\n",
    "                    \n",
    "                        #Generate selection probabilites using selector function. This will be the mask\n",
    "                    \n",
    "                        int_5,int_4,int_3,int_2,int_1 = self.selector(inputs)#Final and intermediate maps\n",
    "                        int_4.detach()\n",
    "                        int_3.detach()\n",
    "                        int_2.detach()\n",
    "                        int_1.detach()\n",
    "                        \n",
    "                        #Sigmoid mask\n",
    "                        sel_prob = F.sigmoid(int_5)\n",
    "                        \n",
    "                        #Linear mask\n",
    "                        #sel_prob = sel_prob - sel_prob.min()\n",
    "                        #sel_prob = sel_prob/sel_prob.max()\n",
    "                        \n",
    "                        #Get the binary sampled mask\n",
    "                        bin_mask = torch.Tensor(sampler(sel_prob.data.cpu().numpy())).to(self.device)\n",
    "                    \n",
    "                        #Compute the Complementary selection probability\n",
    "                        comp_bin_mask = 1 - bin_mask\n",
    "                        \n",
    "                        #Generate X_S_bar the complementary selection probability masked image\n",
    "                        x_s_bar = inputs*comp_bin_mask\n",
    "                        \n",
    "                        #Generate baseline output probabilities\n",
    "                        base_out = self.baseline(inputs)\n",
    "                        _, base_preds = torch.max(base_out, 1)\n",
    "                        \n",
    "                        #Generate discriminator probabilities\n",
    "                        dis_out = self.baseline(x_s_bar)\n",
    "                        dis_probs = F.softmax(dis_out)\n",
    "                        \n",
    "                        #Baseline Cross entropy\n",
    "                        base_ce_loss = nn.CrossEntropyLoss()(base_out,labels)\n",
    "                        base_loss = base_ce_loss - torch.log(dis_probs[0][0]*dis_probs[0][1]) \n",
    "                        \n",
    "                        #Discriminator Loss\n",
    "                        #dis_loss = -torch.log(dis_probs[0][0]*dis_probs[0][1])\n",
    "                        \n",
    "                        #import pdb;pdb.set_trace()\n",
    "                        with torch.no_grad():\n",
    "                            #Discriminator Cross entropy\n",
    "                            dis_ce_loss = F.cross_entropy(dis_out,labels)\n",
    "                            \n",
    "                            #KL divergence term\n",
    "                            kl = 0.5*base_ce_loss - dis_ce_loss\n",
    "                            #print(kl)\n",
    "                        \n",
    "                            #Selector function loss along with penalization on intermediate losses                           \n",
    "\n",
    "                            combined_int_loss = 0.25*(torch.mean(torch.abs(int_4))+torch.mean(torch.abs(int_3))\\\n",
    "                                                          +torch.mean(torch.abs(int_2))+torch.mean(torch.abs(int_1)))\n",
    "                        \n",
    "                        l1_loss = torch.mean(sel_prob)\n",
    "                        \n",
    "                        #Weight all the intermediate terms equally                        \n",
    "                        distribution_loss = torch.mean(bin_mask*torch.log(sel_prob + 1e-8) + (1-bin_mask)*torch.log(1 - sel_prob + 1e-8))\n",
    "                        \n",
    "                        #print(distribution_loss*kl,l1_loss)\n",
    "                        sel_loss = distribution_loss*(kl) + self.beta*l1_loss\n",
    "                        \n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            #The gradients of pred_ce_loss should not update the params of disc or sel\n",
    "                            base_loss.backward()#retain_graph=True)\n",
    "                            self.optimizer_sel.zero_grad()\n",
    "                            #self.optimizer_dis.zero_grad()\n",
    "                            self.optimizer_base.step()\n",
    "                                                        \n",
    "#                             #The gradients of dis_ce_loss should not update the params of pred or sel\n",
    "#                             dis_loss.backward(retain_graph=True)\n",
    "#                             self.optimizer_sel.zero_grad()\n",
    "#                             self.optimizer_base.zero_grad()\n",
    "#                             self.optimizer_dis.step()\n",
    "                            \n",
    "                            #Update sel\n",
    "                            sel_loss.backward()\n",
    "                            #self.optimizer_dis.zero_grad()\n",
    "                            self.optimizer_base.zero_grad()\n",
    "                            self.optimizer_sel.step()\n",
    "                        \n",
    "                    #Metric computation\n",
    "                    out4metric = int_5.view(-1)\n",
    "                    mask4metric = masks.view(-1)\n",
    "                    preds = out4metric\n",
    "                    preds[preds>0] = 1\n",
    "                    preds[preds<=0] = 0\n",
    "\n",
    "                    # statistics\n",
    "                    running_sel_loss += sel_loss.item() * inputs.size(0)\n",
    "                    #running_dis_loss += dis_loss.item() * inputs.size(0)\n",
    "                    running_base_loss += base_ce_loss.item() * inputs.size(0)\n",
    "                    running_spa += l1_loss.item() * inputs.size(0)\n",
    "                    running_int_spa += combined_int_loss.item() * inputs.size(0)\n",
    "                \n",
    "                    running_dis_acc += torch.mean(torch.abs(dis_probs-0.5).float())\n",
    "                    running_base_acc += torch.sum(base_preds == labels.data)\n",
    "                    running_iou += get_IoU(preds,mask4metric) * inputs.size(0)\n",
    "                    running_bin_mask += torch.mean(preds) * inputs.size(0)\n",
    "                    \n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "                epoch_base_loss = running_base_loss / self.dataset_sizes[phase]\n",
    "                epoch_sel_loss = running_sel_loss / self.dataset_sizes[phase]\n",
    "                #epoch_dis_loss = running_dis_loss / self.dataset_sizes[phase]\n",
    "                epoch_spa = running_spa / self.dataset_sizes[phase]\n",
    "                epoch_int_spa = running_int_spa / self.dataset_sizes[phase]\n",
    "                \n",
    "                epoch_base_acc = running_base_acc.double()/ self.dataset_sizes[phase]\n",
    "                epoch_dis_acc = running_dis_acc.double() / self.dataset_sizes[phase]\n",
    "                epoch_iou = running_iou / self.dataset_sizes[phase]\n",
    "                epoch_bin_mask = running_bin_mask / self.dataset_sizes[phase]\n",
    "                \n",
    "                print('{} Base_Loss: {:.4f} Sel_Loss: {:.4f} Spa: {:.4f} Int_Spa: {:.4f} BAC: {:.4f} DAC: {:.4f} IoU: {:.4f} Bin: {:.4f}'.\\\n",
    "                      format(phase, epoch_base_loss, epoch_sel_loss, \\\n",
    "                             epoch_spa, epoch_int_spa, epoch_base_acc, epoch_dis_acc, \\\n",
    "                             epoch_iou, epoch_bin_mask))\n",
    "                \n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and epoch_iou > best_iou:\n",
    "                    \n",
    "                    best_iou = epoch_iou\n",
    "                    torch.save(self.selector.state_dict(),self.exp_name+'_sel.pt')\n",
    "                    torch.save(self.baseline.state_dict(),self.exp_name+'_base.pt')\n",
    "                    #torch.save(self.discriminator.state_dict(),self.exp_name+'_dis.pt')\n",
    "                    #import pdb;pdb.set_trace()\n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best iou: {:4f}'.format(best_iou))\n",
    "\n",
    "        torch.save(self.baseline.state_dict(),self.exp_name+'_base_final.pt')\n",
    "        torch.save(self.selector.state_dict(),self.exp_name+'_sel_final.pt')\n",
    "        torch.save(self.discriminator.state_dict(),self.exp_name+'_dis_final.pt')\n",
    "\n",
    "        print('Training completed finally !!!!!')\n",
    "        \n",
    "    def get_cam(self):\n",
    "                \n",
    "        self.selector.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        #self.selector.load_state_dict(torch.load('Weights/dc_invase_vgg_dogcat_sel.pt'))\n",
    "        self.selector.eval()\n",
    "        \n",
    "        acc = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        cm = []\n",
    "        m = []\n",
    "        bm = []\n",
    "        \n",
    "        params = list(self.selector.parameters())                        \n",
    "        weight_softmax = torch.squeeze(params[-2].data)\n",
    "        \n",
    "        iou = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pbar = tqdm(total=self.dataset_sizes[mode])\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                inputs = data['image']\n",
    "                labels = data['category']\n",
    "\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device) \n",
    "                \n",
    "                sel_prob = self.selector(inputs)\n",
    "                sel_prob = sel_prob - sel_prob.min()\n",
    "                sel_prob = sel_prob/sel_prob.max()\n",
    "                #bin_mask = torch.Tensor(sampler(sel_prob.data.cpu().numpy())).to(self.device)\n",
    "                bin_mask = sel_prob\n",
    "                bin_mask[sel_prob>0.5] = 1\n",
    "                bin_mask[sel_prob<0.5] = 0\n",
    "\n",
    "                base_path = '../Experiments/Sanity_Check/'\n",
    "                name = data['name'][0]\n",
    "\n",
    "                #import pdb;pdb.set_trace()\n",
    "                heatmap = cv2.applyColorMap(np.uint8(255*bin_mask.cpu().numpy().squeeze()), cv2.COLORMAP_JET)\n",
    "                #heatmap = bin_mask.cpu().numpy().squeeze()\n",
    "                #heatmap = np.expand_dims(heatmap,axis=2)\n",
    "                heatmap = np.float32(heatmap) / 255\n",
    "                cam_f = heatmap + np.float32(inputs.cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "                cam_f = cam_f / np.max(cam_f)\n",
    "                #cam_f = heatmap\n",
    "                pr = name.replace('.j','_hm.j')\n",
    "                cv2.imwrite(base_path+pr,bin_mask.cpu().numpy().squeeze()*255)\n",
    "\n",
    "                \n",
    "                pbar.update(inputs.shape[0])\n",
    "                \n",
    "            pbar.close()\n",
    "        \n",
    "\n",
    "    def return_model(self):\n",
    "        self.selector.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.selector.s()\n",
    "        return self.selector,self.dataloaders['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dci = dc_invase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/299\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca60c24a9acf4d5593a8ffd9bb015b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1999), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2481, device='cuda:0')\n",
      "tensor(0.1714, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5047, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1531, device='cuda:0')\n",
      "tensor(0.1055, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5050, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1637, device='cuda:0')\n",
      "tensor(0.1129, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0421, device='cuda:0')\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.6917, device='cuda:0')\n",
      "tensor(0.4767, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5053, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0744, device='cuda:0')\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5050, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3433, device='cuda:0')\n",
      "tensor(0.2361, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5047, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.4041, device='cuda:0')\n",
      "tensor(0.2783, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5045, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0941, device='cuda:0')\n",
      "tensor(0.0648, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5043, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.4545, device='cuda:0')\n",
      "tensor(0.3127, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5041, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3242, device='cuda:0')\n",
      "tensor(0.2229, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5039, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2825, device='cuda:0')\n",
      "tensor(0.1942, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5038, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0033, device='cuda:0')\n",
      "tensor(-0.0023, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5038, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0607, device='cuda:0')\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5037, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3707, device='cuda:0')\n",
      "tensor(0.2543, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5037, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1597, device='cuda:0')\n",
      "tensor(0.1097, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5037, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2359, device='cuda:0')\n",
      "tensor(0.1620, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3939, device='cuda:0')\n",
      "tensor(0.2701, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.6683, device='cuda:0')\n",
      "tensor(0.4586, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1657, device='cuda:0')\n",
      "tensor(0.1135, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5034, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1566, device='cuda:0')\n",
      "tensor(0.1073, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5032, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0963, device='cuda:0')\n",
      "tensor(0.0660, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5033, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2183, device='cuda:0')\n",
      "tensor(0.1497, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0146, device='cuda:0')\n",
      "tensor(-0.0100, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5029, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0828, device='cuda:0')\n",
      "tensor(0.0567, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0246, device='cuda:0')\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.4131, device='cuda:0')\n",
      "tensor(0.2823, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3629, device='cuda:0')\n",
      "tensor(0.2483, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1397, device='cuda:0')\n",
      "tensor(0.0955, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3870, device='cuda:0')\n",
      "tensor(0.2643, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5025, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.6079, device='cuda:0')\n",
      "tensor(0.4153, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5026, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.5828, device='cuda:0')\n",
      "tensor(0.3979, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5029, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1357, device='cuda:0')\n",
      "tensor(0.0926, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5031, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0225, device='cuda:0')\n",
      "tensor(-0.0154, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5032, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1358, device='cuda:0')\n",
      "tensor(0.0927, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1132, device='cuda:0')\n",
      "tensor(0.0772, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5039, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0933, device='cuda:0')\n",
      "tensor(0.0637, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5040, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1997, device='cuda:0')\n",
      "tensor(0.1361, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5043, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2873, device='cuda:0')\n",
      "tensor(0.1954, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5044, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.4285, device='cuda:0')\n",
      "tensor(0.2919, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5048, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1884, device='cuda:0')\n",
      "tensor(0.1281, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5050, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1127, device='cuda:0')\n",
      "tensor(0.0765, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5049, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0579, device='cuda:0')\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3141, device='cuda:0')\n",
      "tensor(0.2135, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5052, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2393, device='cuda:0')\n",
      "tensor(0.1622, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1855, device='cuda:0')\n",
      "tensor(0.1259, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.4307, device='cuda:0')\n",
      "tensor(0.2924, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0850, device='cuda:0')\n",
      "tensor(-0.0576, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1477, device='cuda:0')\n",
      "tensor(0.1001, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5058, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2975, device='cuda:0')\n",
      "tensor(0.2016, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2135, device='cuda:0')\n",
      "tensor(0.1443, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3770, device='cuda:0')\n",
      "tensor(0.2550, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5059, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3833, device='cuda:0')\n",
      "tensor(0.2595, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1418, device='cuda:0')\n",
      "tensor(0.0960, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-1.0509, device='cuda:0')\n",
      "tensor(0.7083, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2811, device='cuda:0')\n",
      "tensor(0.1899, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5059, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.5319, device='cuda:0')\n",
      "tensor(0.3601, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.4773, device='cuda:0')\n",
      "tensor(0.3227, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0780, device='cuda:0')\n",
      "tensor(0.0525, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5064, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.4212, device='cuda:0')\n",
      "tensor(0.2841, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2709, device='cuda:0')\n",
      "tensor(0.1829, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.5006, device='cuda:0')\n",
      "tensor(0.3385, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.7141, device='cuda:0')\n",
      "tensor(0.4833, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5058, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3064, device='cuda:0')\n",
      "tensor(0.2064, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5064, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2139, device='cuda:0')\n",
      "tensor(0.1447, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5058, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2399, device='cuda:0')\n",
      "tensor(0.1621, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0426, device='cuda:0')\n",
      "tensor(0.0288, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5057, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1978, device='cuda:0')\n",
      "tensor(0.1337, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5057, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.8870, device='cuda:0')\n",
      "tensor(0.6011, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5054, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.4663, device='cuda:0')\n",
      "tensor(0.3143, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.7843, device='cuda:0')\n",
      "tensor(0.5287, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5054, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2329, device='cuda:0')\n",
      "tensor(0.1572, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5058, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1788, device='cuda:0')\n",
      "tensor(0.1204, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5057, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0126, device='cuda:0')\n",
      "tensor(0.0085, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3992, device='cuda:0')\n",
      "tensor(0.2686, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5058, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0339, device='cuda:0')\n",
      "tensor(0.0229, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5063, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3016, device='cuda:0')\n",
      "tensor(0.2036, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2117, device='cuda:0')\n",
      "tensor(0.1425, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.0978, device='cuda:0')\n",
      "tensor(0.0658, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5069, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2106, device='cuda:0')\n",
      "tensor(0.1417, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5068, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.2535, device='cuda:0')\n",
      "tensor(0.1706, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5070, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3324, device='cuda:0')\n",
      "tensor(0.2232, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5071, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.1047, device='cuda:0')\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5071, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(-0.3340, device='cuda:0')\n",
      "tensor(0.2249, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5080, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "tensor(0.0286, device='cuda:0')\n",
      "tensor(-0.0192, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5073, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-74:\n",
      "Process Process-79:\n",
      "Process Process-77:\n",
      "Process Process-73:\n",
      "Process Process-75:\n",
      "Process Process-80:\n",
      "Process Process-78:\n",
      "Process Process-76:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.4806, device='cuda:0')\n",
      "tensor(0.3233, device='cuda:0', grad_fn=<ThMulBackward>) tensor(0.5079, device='cuda:0', grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-742f7ce152e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-c4bb9c6690a1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m                             \u001b[0;31m#self.optimizer_dis.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                     \u001b[0;31m#Metric computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "dci.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dci.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dci.get_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[3,3] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1 - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = cv2.applyColorMap(np.uint8(255*a), cv2.COLORMAP_JET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(heatmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
