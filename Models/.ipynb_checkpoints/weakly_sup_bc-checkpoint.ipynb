{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import augmentations\n",
    "from augmentations import *\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import dataloaders\n",
    "from dataloaders import *\n",
    "\n",
    "'''Dataloader'''\n",
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = '../Data/mask_orient_cropped/'\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'].replace('.j','_mask.j'))\n",
    "        mask = io.imread(mask_name)\n",
    "        mask = np.array([mask,mask,mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']       \n",
    "\n",
    "        if self.transform:\n",
    "            image,mask = self.transform(image,mask)\n",
    "        \n",
    "        mask_final = mask[0,:,:]\n",
    "        mask_final[mask_final<0.5] = 0\n",
    "        mask_final[mask_final>0.5] = 1\n",
    "        \n",
    "        return {'image':image, 'category':label, 'mask':mask_final, 'name':self.data_frame.iloc[idx]['name']}\n",
    "    \n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': Compose([\n",
    "            RandomHorizontallyFlip(0.5),\n",
    "            #RandomVerticallyFlip(0.5),\n",
    "            RandomTranslate((0.2,0.2)),\n",
    "            RandomRotate(15),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': Compose([\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': Compose([\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)        \n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        if x == 'train':\n",
    "            bs = batch_size\n",
    "            sh = True\n",
    "        elif x == 'valid':\n",
    "            bs = batch_size\n",
    "            sh = False\n",
    "        else:\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=bs,shuffle=sh, num_workers=8)    \n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "\n",
    "#Selector network\n",
    "\n",
    "#The selector output is 5x5x5. Each patch will have 5 anchor boxes\n",
    "\n",
    "def build_selector():\n",
    "\n",
    "    class mdl(nn.Module):\n",
    "        def __init__(self,base_model):\n",
    "            super().__init__()\n",
    "            self.base = base_model \n",
    "            self.l1 = nn.Conv2d(512,5,3,stride=2)\n",
    "        def forward(self, x):\n",
    "            x = self.base(x)\n",
    "            x = self.l1(x)   \n",
    "            return x\n",
    "\n",
    "    v = models.vgg16_bn(pretrained=True)\n",
    "    v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "\n",
    "    #r = models.resnet101(pretrained=True)\n",
    "    #r1 = nn.Sequential(*list(r.children())[:-2])\n",
    "    \n",
    "    model = mdl(v1[-1])\n",
    "        \n",
    "    return model\n",
    "\n",
    "## Predictor-Discriminator-Baseline\n",
    "def build_baseline_predictor():\n",
    "\n",
    "    class mdl(nn.Module):\n",
    "        def __init__(self,base_model):\n",
    "            super().__init__()\n",
    "            self.base = base_model \n",
    "            self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.fc1 = nn.Linear(512,2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x_base = self.base(x)\n",
    "            x = self.gap(x_base)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            return x,x_base \n",
    "\n",
    "    v = models.vgg16_bn(pretrained=True)\n",
    "    v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "\n",
    "    #r = models.resnet101(pretrained=True)\n",
    "    #r1 = nn.Sequential(*list(r.children())[:-2])\n",
    "    \n",
    "    model = mdl(v1[-1])\n",
    "    model.load_state_dict(torch.load('classification_bc_vgg_16_balanced_mass_sel.pt'))\n",
    "        \n",
    "    return model\n",
    "\n",
    "def get_sample(target):\n",
    "\n",
    "    prob_vector = F.softmax(target.view(-1))\n",
    "    probs = prob_vector.data.cpu().numpy()\n",
    "    \n",
    "    probs = probs.astype('float64')\n",
    "    probs = probs/probs.sum()\n",
    "    \n",
    "    try:\n",
    "        prob_sample = np.random.multinomial(1,probs,1)\n",
    "    except:import pdb;pdb.set_trace()\n",
    "    return prob_sample.reshape(target.shape)\n",
    "\n",
    "def get_anchor_box(m_r,m_c,img_shape,patch_shape):\n",
    "    \n",
    "    r1 = max(0,m_r - patch_shape[0]//2)\n",
    "    r2 = min(img_shape[0],m_r + patch_shape[0]//2)\n",
    "    \n",
    "    c1 = max(0,m_c - patch_shape[1]//2)\n",
    "    c2 = min(img_shape[1],m_c + patch_shape[1]//2)\n",
    "    \n",
    "    if r1 == 0:\n",
    "        r2 = patch_shape[0]\n",
    "        \n",
    "    if r2 == img_shape[0]:\n",
    "        r1 = img_shape[0]-patch_shape[0]\n",
    "        \n",
    "    if c1 == 0:\n",
    "        c2 = patch_shape[1]\n",
    "        \n",
    "    if c2 == img_shape[1]:\n",
    "        c1 = img_shape[1]-patch_shape[1]\n",
    "        \n",
    "    if r2-r1 != patch_shape[0] and c2-c1 != patch_shape[1]:\n",
    "        import pdb;pdb.set_trace()\n",
    "    \n",
    "    return r1,r2,c1,c2\n",
    "\n",
    "def get_patch_center(inp,img_shape):\n",
    "    \n",
    "    grid = inp\n",
    "    _,c,h,w = inp.shape\n",
    "    _,c_l,h_l,w_l = np.where(grid==1)\n",
    "    \n",
    "    c_l = c_l[0]\n",
    "    h_l = h_l[0]\n",
    "    w_l = w_l[0]\n",
    "    \n",
    "    patch_h = img_shape[0]//h\n",
    "    patch_w = img_shape[1]//w\n",
    "    \n",
    "    patch_h_4 = patch_h//4\n",
    "    patch_w_4 = patch_w//4\n",
    "    \n",
    "    r1 = h_l*patch_h\n",
    "    r2 = (h_l+1)*patch_h\n",
    "    \n",
    "    c1 = c_l*patch_w\n",
    "    c2 = (c_l+1)*patch_w\n",
    "    \n",
    "    m_r = (r1+r2)//2\n",
    "    m_c = (c1+c2)//2\n",
    "    \n",
    "    if c_l == 1:\n",
    "        m_r = m_r - patch_h_4\n",
    "        m_c = m_c - patch_w_4\n",
    "        \n",
    "    elif c_l == 2:\n",
    "        m_r = m_r - patch_h_4\n",
    "        m_c = m_c + patch_w_4\n",
    "\n",
    "    elif c_l == 3:\n",
    "        m_r = m_r + patch_h_4\n",
    "        m_c = m_c + patch_w_4\n",
    "\n",
    "    elif c_l == 4:\n",
    "        m_r = m_r + patch_h_4\n",
    "        m_c = m_c - patch_w_4\n",
    "\n",
    "    m_r = int(m_r)\n",
    "    m_c = int(m_c)\n",
    "    \n",
    "    return m_r,m_c\n",
    "\n",
    "def intersection_metric(anchor,mask):\n",
    "    r1,r2,c1,c2 = anchor\n",
    "    return mask[0,r1:r2,c1:c2].sum()/(mask.sum()+1)\n",
    "\n",
    "## DC-INVASE class\n",
    "class dc_invase():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialization\n",
    "        self.data_dir =  '../Data/CBIS-DDSM_classification_orient_cropped/'\n",
    "        self.train_csv = '../CSV/mass_weak_train.csv'\n",
    "        self.num_epochs = 100\n",
    "        self.input_shape = (288,256)\n",
    "        self.patch_shape = (256,256)\n",
    "        self.batch_size = 1\n",
    "        self.img_mean = [0.253, 0.238, 0.234]\n",
    "        self.img_std = [0.272, 0.268, 0.262]\n",
    "        \n",
    "        self.exp_name = './Weights/weak_sup_bc'\n",
    "        \n",
    "        #Define the four models\n",
    "        self.selector = build_selector()\n",
    "        self.baseline = build_baseline_predictor()\n",
    "        self.predictor = build_baseline_predictor()\n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.selector = self.selector.cuda()\n",
    "        self.baseline = self.baseline.cuda()\n",
    "        self.predictor = self.predictor.cuda()\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.input_shape,self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "        #Define optimizers one for each model\n",
    "        self.optimizer_sel = optim.Adam(self.selector.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-6, amsgrad=False)\n",
    "        self.optimizer_pred = optim.Adam(self.predictor.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-6, amsgrad=False)\n",
    "\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        best_iou = 0\n",
    "        best_acc = 0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':                \n",
    "                    #Set the models to training mode\n",
    "                    self.selector.train()\n",
    "                    self.predictor.train()\n",
    "                    self.baseline.eval()\n",
    "        \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    self.selector.eval()\n",
    "                    self.baseline.eval()\n",
    "                    self.predictor.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_sel_loss = 0.0\n",
    "                running_pred_loss = 0.0\n",
    "              \n",
    "                #Metrics : accuracy\n",
    "                running_pred_acc = 0\n",
    "                running_base_acc = 0\n",
    "                running_int = 0\n",
    "                \n",
    "                '''aucroc'''\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                \n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    labels = sampled_batch['category']\n",
    "                    mask = sampled_batch['mask']\n",
    "                    \n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    labels = labels.long().to(self.device)\n",
    "                    mask = mask.to(self.device)\n",
    "                    \n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer_sel.zero_grad()\n",
    "                    self.optimizer_pred.zero_grad()\n",
    "                    \n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        \n",
    "                        #import pdb;pdb.set_trace()\n",
    "                        \n",
    "                        #Generate predictor output probabilities\n",
    "                        base_out,_ = self.baseline(inputs)\n",
    "                        base_prob = F.softmax(base_out)\n",
    "                        _, base_preds = torch.max(base_out, 1)\n",
    "                        \n",
    "                        #=>Baseline Cross entropy\n",
    "                        base_ce_loss = F.cross_entropy(base_out,labels)\n",
    "                                          \n",
    "                        #Generate selection probabilites using selector function.\n",
    "                        sel_prob = self.selector(inputs)\n",
    "                                                \n",
    "                        probs_sample = get_sample(sel_prob)\n",
    "\n",
    "                        m_r,m_c = get_patch_center(probs_sample,self.input_shape)\n",
    "\n",
    "                        r1,r2,c1,c2 = get_anchor_box(m_r,m_c,self.input_shape,self.patch_shape)\n",
    "                        \n",
    "                        #print(r1,r2,c1,c2)\n",
    "                        \n",
    "                        int_met = intersection_metric([r1,r2,c1,c2],mask)\n",
    "                        \n",
    "                        patch = inputs[0,:,r1:r2,c1:c2].unsqueeze(dim=0)\n",
    "\n",
    "                        #Generate predictor output probabilities using the baseline cnn\n",
    "                        pred_out,_ = self.predictor(patch)\n",
    "                        pred_prob = F.softmax(pred_out)\n",
    "                        _, pred_preds = torch.max(pred_out, 1)\n",
    "                                                \n",
    "                        '''aucroc'''\n",
    "                        y_true.append(labels.data)\n",
    "                        y_pred.append(pred_prob.data[0][1])\n",
    "\n",
    "                        #Predictor Cross entropy\n",
    "                        pred_ce_loss = F.cross_entropy(pred_out,labels)\n",
    "\n",
    "                        with torch.no_grad():\n",
    "\n",
    "                            k_l = pred_ce_loss - base_ce_loss                  \n",
    "\n",
    "                        probs_sample = torch.Tensor(probs_sample).to(self.device)\n",
    "                        \n",
    "                        probs_sample = probs_sample.view(-1)\n",
    "                        sel_prob = F.softmax(sel_prob.view(-1))\n",
    "                        \n",
    "                        distribution_loss = torch.mean(probs_sample*torch.log(sel_prob + 1e-8) + (1-probs_sample)*torch.log(1 - sel_prob + 1e-8))\n",
    "                                                \n",
    "                        sel_loss = distribution_loss*(k_l) + c2/self.input_shape[1] + abs((r1+r2)/2-self.input_shape[0]//2)/self.input_shape[0]\n",
    "            \n",
    "                        #print(distribution_loss*kl_diff,self.beta*l1_loss)\n",
    "                                                    \n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            pred_ce_loss.backward(retain_graph=True)\n",
    "                            self.optimizer_sel.zero_grad()\n",
    "                            self.optimizer_pred.step()\n",
    "                            \n",
    "                            #Update sel\n",
    "                            sel_loss.backward()\n",
    "                            self.optimizer_pred.zero_grad()\n",
    "                            self.optimizer_sel.step()\n",
    "                                    \n",
    "                    # statistics\n",
    "                    running_sel_loss += sel_loss.item() * inputs.size(0)\n",
    "                    running_pred_loss += pred_ce_loss.item() * inputs.size(0)\n",
    "                \n",
    "                    running_pred_acc += torch.sum(pred_preds == labels.data)\n",
    "                    running_base_acc += torch.sum(base_preds == labels.data)\n",
    "                    running_int += int_met * inputs.size(0)\n",
    "                    \n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "                epoch_sel_loss = running_sel_loss / self.dataset_sizes[phase]\n",
    "                epoch_pred_loss = running_pred_loss / self.dataset_sizes[phase]\n",
    "                \n",
    "                epoch_base_acc = running_base_acc.double()/ self.dataset_sizes[phase]\n",
    "                epoch_pred_acc = running_pred_acc.double() / self.dataset_sizes[phase]\n",
    "                epoch_int = running_int / self.dataset_sizes[phase]\n",
    "                \n",
    "                epoch_auc_roc = sklearn.metrics.roc_auc_score(y_true,y_pred,average='weighted')\n",
    "                \n",
    "                print('{} Sel_Loss: {:.4f} Pred_Loss: {:.4f} BAC: {:.4f} PAC: {:.4f} Int: {:.4f} Auc: {:4f}'.format(\n",
    "                    phase, epoch_sel_loss, epoch_pred_loss, epoch_base_acc, epoch_pred_acc, epoch_int, epoch_auc_roc))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and epoch_pred_acc > best_acc:\n",
    "                    \n",
    "                    best_acc = epoch_pred_acc\n",
    "                    torch.save(self.selector.state_dict(),self.exp_name+'_sel.pt')\n",
    "                    torch.save(self.baseline.state_dict(),self.exp_name+'_base.pt')\n",
    "                    #import pdb;pdb.set_trace()\n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best iou: {:4f}'.format(best_iou))\n",
    "\n",
    "        torch.save(self.baseline.state_dict(),self.exp_name+'_base_final.pt')\n",
    "        torch.save(self.selector.state_dict(),self.exp_name+'_sel_final.pt')\n",
    "\n",
    "        print('Training completed finally !!!!!')\n",
    "        \n",
    "    def get_cam(self):\n",
    "                \n",
    "        self.selector.load_state_dict(torch.load(self.exp_name+'_sel_final.pt'))\n",
    "        self.selector.eval()\n",
    "        \n",
    "        acc = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        cm = []\n",
    "        m = []\n",
    "        bm = []\n",
    "        \n",
    "        params = list(self.selector.parameters())                        \n",
    "        weight_softmax = torch.squeeze(params[-2].data)\n",
    "        \n",
    "        iou = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pbar = tqdm(total=self.dataset_sizes[mode])\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                inputs = data['image']\n",
    "                labels = data['category']\n",
    "\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device) \n",
    "                \n",
    "                sel_prob = self.selector(inputs)\n",
    "                sel_prob = sel_prob - sel_prob.min()\n",
    "                sel_prob = sel_prob/sel_prob.max()\n",
    "\n",
    "                #Threshold using 0.5\n",
    "                #bin_samples = test_samples(sel_prob.data)\n",
    "                \n",
    "                #Sample using the distribution induced\n",
    "                bin_samples = sampler(sel_prob.data.cpu().numpy())\n",
    "                bin_samples = torch.Tensor(bin_samples).to(self.device)\n",
    "                bin_mask = self.prob_mask(bin_samples).to(self.device) \n",
    "\n",
    "                base_path = '../Experiments/Oxford_pets/'\n",
    "                name = data['name'][0]\n",
    "\n",
    "                #heatmap = cv2.applyColorMap(np.uint8(255*bin_mask.cpu().numpy().squeeze()), cv2.COLORMAP_JET)\n",
    "                heatmap = bin_mask.cpu().numpy().squeeze()\n",
    "                heatmap = np.expand_dims(heatmap,axis=2)\n",
    "                #heatmap = np.float32(heatmap) / 255\n",
    "                cam_f = heatmap*np.float32(inputs.cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "                cam_f = cam_f / np.max(cam_f)\n",
    "                #cam_f = heatmap\n",
    "                pr = name.replace('.j','_bin_8x8_samp_share_1_final.j')\n",
    "                cv2.imwrite(base_path+pr,cam_f*255)\n",
    "\n",
    "                \n",
    "                pbar.update(inputs.shape[0])\n",
    "                \n",
    "            pbar.close()\n",
    "        \n",
    "\n",
    "    def return_model(self):\n",
    "        self.selector.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.selector.eval()\n",
    "        return self.selector,self.dataloaders['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dc = dc_invase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.imread('../Experiments/Oxford_pets/cat_Abyssinian_105_bin_8x8_samp_share_1_final.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
