{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "  \n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import dataloaders\n",
    "from dataloaders import *\n",
    "\n",
    "## Dataloader\n",
    "\n",
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']       \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        return {'image':image,'category':label,'name':self.data_frame.iloc[idx]['name']}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(image_size),#row to column ratio should be 1.69\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomVerticalFlip(0.5),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.RandomAffine(translate=(0,0.2),degrees=15,shear=15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        if x == 'test':\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        else:\n",
    "            bs = batch_size\n",
    "            sh = True\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=bs,shuffle=sh, num_workers=8)    \n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "\n",
    "## Selector network (U-Net)\n",
    "\n",
    "def build_selector():\n",
    "    class unetConv2(nn.Module):\n",
    "        def __init__(self, in_size, out_size, is_batchnorm):\n",
    "            super(unetConv2, self).__init__()\n",
    "\n",
    "            if is_batchnorm:\n",
    "                self.conv1 = nn.Sequential(nn.Conv2d(in_size, out_size, 3, 1, 1),\n",
    "                                           nn.BatchNorm2d(out_size),\n",
    "                                           nn.ReLU(),)\n",
    "                self.conv2 = nn.Sequential(nn.Conv2d(out_size, out_size, 3, 1, 1),\n",
    "                                           nn.BatchNorm2d(out_size),\n",
    "                                           nn.ReLU(),)\n",
    "            else:\n",
    "                self.conv1 = nn.Sequential(nn.Conv2d(in_size, out_size, 3, 1, 1),\n",
    "                                           nn.ReLU(),)\n",
    "                self.conv2 = nn.Sequential(nn.Conv2d(out_size, out_size, 3, 1, 1),\n",
    "                                           nn.ReLU(),)\n",
    "        def forward(self, inputs):\n",
    "            outputs = self.conv1(inputs)\n",
    "            outputs = self.conv2(outputs)\n",
    "            return outputs\n",
    "\n",
    "    class unetUp(nn.Module):\n",
    "        def __init__(self, in_size, out_size, is_deconv):\n",
    "            super(unetUp, self).__init__()\n",
    "            self.conv = unetConv2(in_size, out_size, False)\n",
    "            if is_deconv:\n",
    "                self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "            else:\n",
    "                self.up = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "\n",
    "        def forward(self, inputs1, inputs2):\n",
    "            outputs2 = self.up(inputs2)\n",
    "            offset = outputs2.size()[2] - inputs1.size()[2]\n",
    "            padding = 2 * [offset // 2, offset // 2]\n",
    "            outputs1 = F.pad(inputs1, padding)\n",
    "            return self.conv(torch.cat([outputs1, outputs2], 1))\n",
    "\n",
    "    class unet(nn.Module):\n",
    "\n",
    "        def __init__(self, feature_scale=4, n_classes=1, is_deconv=True, in_channels=3, is_batchnorm=True):\n",
    "            super(unet, self).__init__()\n",
    "            self.is_deconv = is_deconv\n",
    "            self.in_channels = in_channels\n",
    "            self.is_batchnorm = is_batchnorm\n",
    "            self.feature_scale = feature_scale\n",
    "\n",
    "            filters = [32, 64, 128, 256, 512]\n",
    "            filters = [int(x / self.feature_scale) for x in filters]\n",
    "\n",
    "            #downsampling\n",
    "            self.conv1 = unetConv2(self.in_channels, filters[0], self.is_batchnorm)\n",
    "            self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "            self.conv2 = unetConv2(filters[0], filters[1], self.is_batchnorm)\n",
    "            self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "            self.conv3 = unetConv2(filters[1], filters[2], self.is_batchnorm)\n",
    "            self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "            self.conv4 = unetConv2(filters[2], filters[3], self.is_batchnorm)\n",
    "            self.maxpool4 = nn.MaxPool2d(kernel_size=2)\n",
    "                    \n",
    "            self.center = unetConv2(filters[3], filters[4], self.is_batchnorm)\n",
    "\n",
    "            # upsampling\n",
    "            self.up_concat4 = unetUp(filters[4], filters[3], self.is_deconv)\n",
    "            self.up_concat3 = unetUp(filters[3], filters[2], self.is_deconv)\n",
    "            self.up_concat2 = unetUp(filters[2], filters[1], self.is_deconv)\n",
    "            self.up_concat1 = unetUp(filters[1], filters[0], self.is_deconv)\n",
    "\n",
    "            # final conv (without any concat)\n",
    "            self.final = nn.Conv2d(filters[4], n_classes, 1)\n",
    "\n",
    "        def forward(self, inputs):\n",
    "            conv1 = self.conv1(inputs)\n",
    "            maxpool1 = self.maxpool1(conv1)\n",
    "\n",
    "            conv2 = self.conv2(maxpool1)\n",
    "            maxpool2 = self.maxpool2(conv2)\n",
    "\n",
    "            conv3 = self.conv3(maxpool2)\n",
    "            maxpool3 = self.maxpool3(conv3)\n",
    "\n",
    "            conv4 = self.conv4(maxpool3)\n",
    "            maxpool4 = self.maxpool4(conv4)\n",
    "\n",
    "            center = self.center(maxpool4)\n",
    "            #up4 = self.up_concat4(conv4, center)\n",
    "            #up3 = self.up_concat3(conv3, up4)\n",
    "            #up2 = self.up_concat2(conv2, up3)\n",
    "            #up1 = self.up_concat1(conv1, up2)\n",
    "\n",
    "            final = self.final(center)\n",
    "\n",
    "            return final\n",
    "        \n",
    "    model = unet()\n",
    "    return model\n",
    "\n",
    "a = build_selector()\n",
    "\n",
    "#summary(a.cuda(),(3,224,224))\n",
    "\n",
    "## Predictor-Discriminator-Baseline\n",
    "\n",
    "def build_pdb():\n",
    "\n",
    "    class mdl(nn.Module):\n",
    "        def __init__(self,base_model):\n",
    "            super().__init__()\n",
    "            self.base = base_model \n",
    "            self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.fc1 = nn.Linear(512,2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x_base = self.base(x)\n",
    "            x = self.gap(x_base)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc1(x)\n",
    "            return x,x_base \n",
    "\n",
    "    v = models.vgg16_bn(pretrained=True)\n",
    "    v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "\n",
    "    #r = models.resnet101(pretrained=True)\n",
    "    #r1 = nn.Sequential(*list(r.children())[:-2])\n",
    "    \n",
    "    model = mdl(v1[-1][:-1])\n",
    "    model.load_state_dict(torch.load('Weights/grad_cam_vgg_16_dogcat.pt'))\n",
    "        \n",
    "    return model\n",
    "    \n",
    "\n",
    "## Sampler\n",
    "\n",
    "def sampler(gen_prob):\n",
    "\n",
    "    # Sampling\n",
    "    samples = np.random.binomial(1, gen_prob, gen_prob.shape)\n",
    "\n",
    "    return samples\n",
    "\n",
    "def test_samples(gen_prob):\n",
    "    out = torch.zeros(gen_prob.shape)\n",
    "    out[gen_prob>0.5] = 1\n",
    "    return out\n",
    "\n",
    "## Mask generation\n",
    "\n",
    "class get_prob_mask(torch.nn.Module):\n",
    "    def __init__(self,img_size,patch_size):\n",
    "        super(get_prob_mask, self).__init__()\n",
    "        self.i_h = img_size[0]\n",
    "        self.i_w = img_size[1]\n",
    "        self.p_h = patch_size[0]\n",
    "        self.p_w = patch_size[1]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        b,c,h,w = x.size()\n",
    "        mask = torch.zeros((b,c,self.i_h,self.i_w))\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                mask[0][0][i*self.p_h:(i+1)*self.p_h,j*self.p_w:(j+1)*self.p_w] = x[0][0][i,j]\n",
    "                #import pdb;pdb.set_trace()\n",
    "        return mask\n",
    "    \n",
    "\n",
    "## DC-INVASE class\n",
    "\n",
    "class dc_invase():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialization\n",
    "        self.data_dir = '../Data/DogCat/train/'\n",
    "        self.train_csv = '../CSV/dogcat_train_1.csv'\n",
    "        self.num_epochs = 20\n",
    "        self.input_shape = (224,224)\n",
    "        self.patch_shape = (16,16)\n",
    "        self.batch_size = 1\n",
    "        self.img_mean = [0,0,0]#[0.485, 0.456, 0.406]\n",
    "        self.img_std = [1,1,1]#[0.229, 0.224, 0.225]\n",
    "        self.alpha = 0.5\n",
    "        self.beta = 0.01\n",
    "        self.exp_name = 'Weights/dci_dc_pdb_wo_sig'\n",
    "        \n",
    "        #Define the three models\n",
    "        self.selector = build_selector()\n",
    "        self.predictor = build_pdb()\n",
    "        self.discriminator = build_pdb()\n",
    "        self.baseline = build_pdb()\n",
    "        \n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.selector = self.selector.cuda()\n",
    "        self.predictor = self.predictor.cuda()\n",
    "        self.discriminator = self.discriminator.cuda()\n",
    "        self.baseline = self.baseline.cuda()\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.input_shape,self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "        #Define the three optimizers one for each model\n",
    "        self.optimizer_sel = optim.Adam(self.selector.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        self.optimizer_pred = optim.Adam(self.predictor.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        self.optimizer_dis = optim.Adam(self.discriminator.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        self.optimizer_base = optim.Adam(self.baseline.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "        #Loss to ensure sparsity\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        \n",
    "        self.prob_mask = get_prob_mask(self.input_shape,self.patch_shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        best_sel_loss = 0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':\n",
    "                    \n",
    "                    #Set the models to training mode\n",
    "                    self.predictor.train() \n",
    "                    self.discriminator.train()\n",
    "                    self.selector.train()\n",
    "                    self.baseline.train()\n",
    "                \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    self.predictor.eval()\n",
    "                    self.discriminator.eval()\n",
    "                    self.selector.eval()\n",
    "                    self.baseline.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_sel_loss = 0.0\n",
    "                running_pred_loss = 0.0\n",
    "                running_dis_loss = 0.0\n",
    "                running_base_loss = 0.0\n",
    "                running_spa = 0.0\n",
    "\n",
    "                \n",
    "                #Metrics : accuracy\n",
    "                running_pred_acc = 0\n",
    "                running_dis_acc = 0\n",
    "                running_base_acc = 0\n",
    "\n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    labels = sampled_batch['category']\n",
    "                    \n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    labels = labels.long().to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer_sel.zero_grad()\n",
    "                    self.optimizer_pred.zero_grad()\n",
    "                    self.optimizer_dis.zero_grad()\n",
    "                    self.optimizer_base.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        \n",
    "                        #import pdb;pdb.set_trace()\n",
    "                    \n",
    "                        #Generate selection probabilites using selector function. This will be the mask\n",
    "                        #sel_prob = F.sigmoid(self.selector(inputs))\n",
    "                        sel_prob = self.selector(inputs)\n",
    "                        sel_prob = sel_prob - sel_prob.min()\n",
    "                        sel_prob = sel_prob/sel_prob.max()\n",
    "                        \n",
    "                        bin_samples = sampler(sel_prob.data.cpu().numpy())\n",
    "                        bin_samples = torch.Tensor(bin_samples).to(self.device)\n",
    "                        bin_mask = self.prob_mask(bin_samples).to(self.device)\n",
    "                    \n",
    "                        #Compute the Complementary selection probability\n",
    "                        comp_bin_mask = 1 - bin_mask\n",
    "                        \n",
    "                        #Generate X_S the selection probability masked image\n",
    "                        x_s = inputs*bin_mask\n",
    "                        \n",
    "                        #Generate X_S_bar the complementary selection probability masked image\n",
    "                        x_s_bar = inputs*comp_bin_mask\n",
    "                        \n",
    "                        #Generate predictor output probabilities\n",
    "                        base_out,_ = self.baseline(inputs)\n",
    "                        base_prob = F.softmax(base_out)\n",
    "                        _, base_preds = torch.max(base_out, 1)\n",
    "                        \n",
    "                        #Generate predictor output probabilities\n",
    "                        pred_out,_ = self.predictor(x_s)\n",
    "                        pred_prob = F.softmax(pred_out)\n",
    "                        _, pred_preds = torch.max(pred_out, 1)\n",
    "                        \n",
    "                        #Generate discriminator probabilities)\n",
    "                        dis_out,_ = self.discriminator(x_s_bar)\n",
    "                        dis_prob = F.softmax(dis_out)\n",
    "                        _, dis_preds = torch.max(dis_out, 1)\n",
    "                        \n",
    "                        #Baseline Cross entropy\n",
    "                        base_ce_loss = F.cross_entropy(base_out,labels)\n",
    "                        \n",
    "                        #Predictor Cross entropy\n",
    "                        pred_ce_loss = F.cross_entropy(pred_out,labels)\n",
    "                        \n",
    "                        #Discriminator Negative Cross entropy\n",
    "                        #dis_ce_loss = F.cross_entropy(dis_out,1-labels)\n",
    "                        #import pdb;pdb.set_trace()\n",
    "                        dis_ce_loss = dis_prob[0][int(labels[0])]\n",
    "                        \n",
    "                        #first KL divergence term\n",
    "                        kl_1 = -base_ce_loss + pred_ce_loss\n",
    "                        \n",
    "                        #second KL divergence term\n",
    "                        kl_2 = -base_ce_loss + dis_ce_loss\n",
    "                        \n",
    "                        #the difference in the two KL divergence terms\n",
    "                        kl_diff = kl_1 - self.alpha*kl_2\n",
    "                        kl_diff.detach()\n",
    "                        \n",
    "                        #Selector function loss\n",
    "                        l1_loss = self.l1_loss(sel_prob,torch.zeros(sel_prob.shape,requires_grad=False).to(self.device))\n",
    "                        \n",
    "                        #kl_1.requires_grad = False\n",
    "                        #kl_2.requires_grad = False\n",
    "                        #kl_diff.requires_grad = False\n",
    "                        \n",
    "                        distribution_loss = torch.mean(bin_samples*torch.log(sel_prob + 1e-8) + (1-bin_samples)*torch.log(1 - sel_prob + 1e-8))\n",
    "                        \n",
    "                        sel_loss = distribution_loss*kl_diff + self.beta*l1_loss\n",
    "                        \n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            #The gradients of pred_ce_loss should not update the params of disc or sel\n",
    "                            base_ce_loss.backward(retain_graph=True)\n",
    "                            self.optimizer_sel.zero_grad()\n",
    "                            self.optimizer_dis.zero_grad()\n",
    "                            self.optimizer_pred.zero_grad()\n",
    "                            self.optimizer_base.step()\n",
    "                            \n",
    "                            #Update predictor using pred_ce_loss\n",
    "                            #The gradients of pred_ce_loss should not update the params of disc or sel\n",
    "                            pred_ce_loss.backward(retain_graph=True)\n",
    "                            self.optimizer_sel.zero_grad()\n",
    "                            self.optimizer_dis.zero_grad()\n",
    "                            self.optimizer_base.zero_grad()\n",
    "                            self.optimizer_pred.step()\n",
    "                            \n",
    "                            #The gradients of dis_ce_loss should not update the params of pred or sel\n",
    "                            dis_ce_loss.backward(retain_graph=True)\n",
    "                            self.optimizer_sel.zero_grad()\n",
    "                            self.optimizer_pred.zero_grad()\n",
    "                            self.optimizer_base.zero_grad()\n",
    "                            self.optimizer_dis.step()\n",
    "                            \n",
    "                            #Update sel\n",
    "                            sel_loss.backward()\n",
    "                            self.optimizer_pred.zero_grad()\n",
    "                            self.optimizer_dis.zero_grad()\n",
    "                            self.optimizer_base.zero_grad()\n",
    "                            self.optimizer_sel.step()\n",
    "                                    \n",
    "                    # statistics\n",
    "                    running_sel_loss += sel_loss.item() * inputs.size(0)\n",
    "                    running_pred_loss += pred_ce_loss.item() * inputs.size(0)\n",
    "                    running_dis_loss += dis_ce_loss.item() * inputs.size(0)\n",
    "                    running_base_loss += base_ce_loss.item() * inputs.size(0)\n",
    "                    running_spa += l1_loss.item() *inputs.size(0)\n",
    "                \n",
    "                    running_pred_acc += torch.sum(pred_preds == labels.data)\n",
    "                    running_dis_acc += torch.sum(dis_preds == (1-labels.data))\n",
    "                    running_base_acc += torch.sum(base_preds == labels.data)\n",
    "                    \n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "                epoch_base_loss = running_base_loss / self.dataset_sizes[phase]\n",
    "                epoch_sel_loss = running_sel_loss / self.dataset_sizes[phase]\n",
    "                epoch_pred_loss = running_pred_loss / self.dataset_sizes[phase]\n",
    "                epoch_dis_loss = running_dis_loss / self.dataset_sizes[phase]\n",
    "                epoch_spa = running_spa / self.dataset_sizes[phase]\n",
    "                \n",
    "                epoch_base_acc = running_base_acc.double()/ self.dataset_sizes[phase]\n",
    "                epoch_pred_acc = running_pred_acc.double() / self.dataset_sizes[phase]\n",
    "                epoch_dis_acc = running_dis_acc.double() / self.dataset_sizes[phase]\n",
    "\n",
    "                print('{} Base_Loss: {:.4f} Sel_Loss: {:.4f} Pred_Loss: {:.4f} Dis_Loss: {:.4f} Spa: {:.4f} BAC: {:.4f} PAC: {:.4f} DAC: {:.4f}'.format(\n",
    "                    phase, epoch_base_loss, epoch_sel_loss, epoch_pred_loss, epoch_dis_loss, epoch_spa, epoch_base_acc, epoch_pred_acc, epoch_dis_acc))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and epoch_sel_loss < best_sel_loss:\n",
    "                    \n",
    "                    best_sel_loss = epoch_sel_loss\n",
    "                    torch.save(self.selector.state_dict(),self.exp_name+'_sel.pt')\n",
    "                    torch.save(self.baseline.state_dict(),self.exp_name+'_base.pt')\n",
    "                    torch.save(self.predictor.state_dict(),self.exp_name+'_pred.pt')\n",
    "                    torch.save(self.discriminator.state_dict(),self.exp_name+'_dis.pt')\n",
    "                    #import pdb;pdb.set_trace()\n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best Sel Loss: {:4f}'.format(best_sel_loss))\n",
    "\n",
    "        torch.save(self.baseline.state_dict(),self.exp_name+'_base_final.pt')\n",
    "        torch.save(self.selector.state_dict(),self.exp_name+'_sel_final.pt')\n",
    "        torch.save(self.predictor.state_dict(),self.exp_name+'_pred_final.pt')\n",
    "        torch.save(self.discriminator.state_dict(),self.exp_name+'_dis_final.pt')\n",
    "\n",
    "        print('Training completed finally !!!!!')\n",
    "        \n",
    "    def get_cam(self):\n",
    "                \n",
    "        self.selector.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.selector.eval()\n",
    "        \n",
    "        acc = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        cm = []\n",
    "        m = []\n",
    "        bm = []\n",
    "        \n",
    "        params = list(self.selector.parameters())                        \n",
    "        weight_softmax = torch.squeeze(params[-2].data)\n",
    "        \n",
    "        iou = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pbar = tqdm(total=self.dataset_sizes[mode])\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                inputs = data['image']\n",
    "                labels = data['category']\n",
    "\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device) \n",
    "                \n",
    "                sel_prob = self.selector(inputs)\n",
    "                sel_prob = sel_prob - sel_prob.min()\n",
    "                sel_prob = sel_prob/sel_prob.max()\n",
    "\n",
    "                bin_samples = test_samples(sel_prob.data)\n",
    "                bin_samples = torch.Tensor(bin_samples).to(self.device)\n",
    "                bin_mask = self.prob_mask(bin_samples).to(self.device) \n",
    "\n",
    "                base_path = '../Experiments/Sanity_Check/'\n",
    "                name = data['name'][0]\n",
    "\n",
    "                #heatmap = cv2.applyColorMap(np.uint8(255*bin_mask.cpu().numpy().squeeze()), cv2.COLORMAP_JET)\n",
    "                heatmap = bin_mask.cpu().numpy().squeeze()\n",
    "                heatmap = np.expand_dims(heatmap,axis=2)\n",
    "                #heatmap = np.float32(heatmap) / 255\n",
    "                cam_f = heatmap*np.float32(inputs.cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "                cam_f = cam_f / np.max(cam_f)\n",
    "                #cam_f = heatmap\n",
    "                pr = name.replace('.j','_bin_16x16_wo_sof.j')\n",
    "                cv2.imwrite(base_path+pr,cam_f*255)\n",
    "\n",
    "                \n",
    "                pbar.update(inputs.shape[0])\n",
    "                \n",
    "            pbar.close()\n",
    "        \n",
    "\n",
    "    def return_model(self):\n",
    "        self.selector.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.selector.eval()\n",
    "        return self.selector,self.dataloaders['valid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dci = dc_invase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dci.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f285f424421487a9df8fb1f3eddd854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dci.get_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cv2.imread('../Experiments/Sanity_Check/cat.10103_bin_16x16_wo_sof.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcce613a710>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dci.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_ = dci.get_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dci.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dci.test_model_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md,dl = dci.return_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(dl).next()\n",
    "\n",
    "m = denorm_img(a['mask'],[0.223, 0.231, 0.243],[0.266, 0.270, 0.274]).squeeze()\n",
    "bm = denorm_img(a['bmask'],[0.223, 0.231, 0.243],[0.266, 0.270, 0.274]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "p = F.sigmoid(md(a['image'].to(device))).detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m = p*bm\n",
    "p_m[p_m > p_m.mean() + p_m.std()] = 1\n",
    "p_m[p_m < p_m.mean() + p_m.std()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m_t = torch.Tensor(p_m)\n",
    "print(nn.L1Loss()(torch.Tensor(p_m),torch.zeros(p_m_t.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p*bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
