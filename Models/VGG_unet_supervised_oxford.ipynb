{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "  \n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import augmentations\n",
    "from augmentations import *\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## Dataloader\n",
    "\n",
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = self.root_dir.replace('images','masks')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'])\n",
    "        mask = io.imread(mask_name)\n",
    "        mask = np.array([mask,mask,mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']       \n",
    "\n",
    "        if self.transform:\n",
    "            image,mask = self.transform(image,mask)\n",
    "        \n",
    "        mask_final = mask[0,:,:]\n",
    "        mask_final[mask_final<0.5] = 0\n",
    "        mask_final[mask_final>0.5] = 1\n",
    "        \n",
    "        return {'image':image, 'category':label, 'mask':mask_final, 'name':self.data_frame.iloc[idx]['name']}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': Compose([\n",
    "            Resize(image_size),\n",
    "            RandomHorizontallyFlip(0.5),\n",
    "            RandomVerticallyFlip(0.5),\n",
    "            RandomTranslate((0.2,0.2)),\n",
    "            RandomRotate(15),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': Compose([\n",
    "            Resize(image_size),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': Compose([\n",
    "            Resize(image_size),\n",
    "            ToTensor(),\n",
    "            Normalize(img_mean,img_std)        \n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        if x == 'train':\n",
    "            bs = batch_size\n",
    "            sh = True\n",
    "        elif x == 'valid':\n",
    "            bs = batch_size\n",
    "            sh = False\n",
    "        else:\n",
    "            bs = 1\n",
    "            sh = False\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=bs,shuffle=sh, num_workers=8)    \n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "\n",
    "# a,_,_,_ = get_dataloader('../Data/oxford_pets/sparse_images/','../CSV/oxford_pet_train.csv',(224,224),[0,0,0],[1,1,1])\n",
    "# b = iter(a['train']).next()\n",
    "\n",
    "# c = b['image'].squeeze().numpy().transpose((1,2,0))\n",
    "# plt.imshow(c)\n",
    "\n",
    "# b['mask'].shape\n",
    "\n",
    "# c = b['mask'].squeeze().numpy()\n",
    "# plt.imshow(c)\n",
    "\n",
    "## Model\n",
    "\n",
    "# class StdUpsample(nn.Module):\n",
    "#     def __init__(self, nin, nout):\n",
    "#         super().__init__()\n",
    "#         self.conv = nn.ConvTranspose2d(nin, nout, 2, stride=2)\n",
    "#         self.bn = nn.BatchNorm2d(nout)\n",
    "        \n",
    "#     def forward(self, x): return self.bn(F.relu(self.conv(x)))\n",
    "    \n",
    "# class VGG_UNet(nn.Module):\n",
    "#     def __init__(self,base):\n",
    "#         super().__init__()\n",
    "#         self.base = base\n",
    "#         self.conv1 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "#         self.conv2 = nn.ConvTranspose2d(256, 256, 2, stride=2)\n",
    "#         self.conv3 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n",
    "#         self.bn = nn.BatchNorm2d(256)\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = self.base(x)\n",
    "#         x = self.bn(F.relu(self.conv1(x)))\n",
    "#         x = self.bn(F.relu(self.conv2(x)))\n",
    "#         x = self.bn(F.relu(self.conv2(x)))\n",
    "#         x = self.bn(F.relu(self.conv2(x)))\n",
    "#         x = self.conv3(x)\n",
    "#         return x\n",
    "\n",
    "# v = models.vgg16_bn(pretrained=True)\n",
    "# v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "# model = VGG_UNet(v1)\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "\n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[0][i]) for i in [12,22,32,42]]\n",
    "        self.up1 = UnetBlock(512,512,256)\n",
    "        self.up2 = UnetBlock(256,512,256)\n",
    "        self.up3 = UnetBlock(256,256,256)\n",
    "        self.up4 = UnetBlock(256,128,256)\n",
    "        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        return x\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "\n",
    "def build_model():\n",
    "    v = models.vgg16_bn(pretrained=True)\n",
    "    v1 = nn.Sequential(*list(v.children())[:-1])\n",
    "    m = Unet34(v1)\n",
    "    return m\n",
    "\n",
    "def get_IoU(pred, targs):\n",
    "    return 2*(pred*targs).sum() / ((pred+targs).sum())# - (pred*targs).sum())\n",
    "\n",
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        smooth = 1\n",
    "        num = targets.size(0)\n",
    "        probs = F.sigmoid(logits)\n",
    "        m1 = probs.view(num, -1)\n",
    "        m2 = targets.view(num, -1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score\n",
    "    \n",
    "class unet_bc():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialization\n",
    "        self.data_dir =  '../Data/oxford_pets/sparse_images/'\n",
    "        self.train_csv = '../CSV/oxford_pet_train.csv'\n",
    "        self.num_epochs = 100\n",
    "        self.input_shape = (224,224)#(640,512) #(640,512)#(224,224)#(640,384) (640,512)\n",
    "        self.batch_size = 8\n",
    "        self.img_mean = [0,0,0]#[0.485, 0.456, 0.406]#[0,0,0]\n",
    "        self.img_std = [1,1,1]#[0.229, 0.224, 0.225]#[1,1,1]\n",
    "        self.exp_name = 'Weights/unet_oxford'\n",
    "        \n",
    "        #Define the three models\n",
    "        self.model = build_model()\n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.model = self.model.cuda()\n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'.pt'))\n",
    "\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.input_shape,self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(),lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        \n",
    "        self.lr_scheduler = CosineAnnealingLR(self.optimizer,T_max=10)\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        best_epoch_acc = 0.0\n",
    "        best_epoch_iou = 0.0\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':\n",
    "                    \n",
    "                    #Set the models to training mode\n",
    "                    self.lr_scheduler.step()\n",
    "                    self.model.train()\n",
    "                \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    self.model.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                #Metrics : predictor auc and selector iou\n",
    "                running_iou = 0\n",
    "                \n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    labels = sampled_batch['category']\n",
    "                    mask = sampled_batch['mask']\n",
    "                    #import pdb;pdb.set_trace()        \n",
    "                    \n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    labels = labels.long().to(self.device)\n",
    "                    mask = mask.to(self.device)\n",
    "                    \n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer.zero_grad()\n",
    "                \n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        \n",
    "                        outputs = self.model(inputs)\n",
    "                        \n",
    "                        out4loss = outputs.view(-1)\n",
    "                        mask4loss = mask.view(-1)\n",
    "                        \n",
    "                        loss = nn.BCEWithLogitsLoss()(out4loss,mask4loss)\n",
    "                        \n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            loss.backward()\n",
    "                            self.optimizer.step()\n",
    "                                    \n",
    "                    preds = out4loss\n",
    "                    preds[preds>0] = 1\n",
    "                    preds[preds<=0] = 0\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_iou += get_IoU(preds,mask4loss) * inputs.size(0)\n",
    "                    #print(running_iou)\n",
    "                    \n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "                epoch_loss = running_loss / self.dataset_sizes[phase]\n",
    "                epoch_iou = running_iou / self.dataset_sizes[phase]\n",
    "                \n",
    "                print('{} Sel_Loss: {:.4f} IoU: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_iou))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and epoch_iou > best_epoch_iou:\n",
    "                    best_epoch_iou = epoch_iou\n",
    "                    torch.save(self.model.state_dict(),self.exp_name+'.pt')\n",
    "                    \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best IoU: {:4f}'.format(best_epoch_iou))\n",
    "\n",
    "        torch.save(self.model.state_dict(),self.exp_name+'_final.pt')\n",
    "        \n",
    "        print('Training completed finally !!!!!')\n",
    "        \n",
    "        \n",
    "    def test_model(self):\n",
    "                \n",
    "        self.model.load_state_dict(torch.load(self.exp_name+'.pt'))\n",
    "        self.model.eval()\n",
    "        \n",
    "        mIoU = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        image_list = []\n",
    "        mask_list = []\n",
    "        pred_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                images = data['image'].to(self.device)               \n",
    "                preds = self.model(images)\n",
    "                \n",
    "                base_path = '../Experiments/Oxford_pets/'\n",
    "                name = data['name'][0]\n",
    "                \n",
    "                pr = name.replace('.j','_supervised.j')\n",
    "                preds =  preds/preds.max()\n",
    "                \n",
    "                cv2.imwrite(base_path+pr,preds.cpu().numpy().squeeze()*255)\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "#                 image_list.append(images.squeeze().cpu().numpy().transpose((1,2,0)))\n",
    "#                 mask_list.append(mask.transpose((1,2,0)).squeeze())\n",
    "#                 pred_list.append(preds.squeeze().cpu().numpy())\n",
    "                \n",
    "#         return image_list,mask_list,pred_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = unet_bc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = u.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c[1]\n",
    "d[d>0] = 255\n",
    "d[d<=0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_IoU(d/255,b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_ = dci.get_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dci.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dci.test_model_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md,dl = dci.return_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(dl).next()\n",
    "\n",
    "m = denorm_img(a['mask'],[0.223, 0.231, 0.243],[0.266, 0.270, 0.274]).squeeze()\n",
    "bm = denorm_img(a['bmask'],[0.223, 0.231, 0.243],[0.266, 0.270, 0.274]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "p = F.sigmoid(md(a['image'].to(device))).detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m = p*bm\n",
    "p_m[p_m > p_m.mean() + p_m.std()] = 1\n",
    "p_m[p_m < p_m.mean() + p_m.std()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m_t = torch.Tensor(p_m)\n",
    "print(nn.L1Loss()(torch.Tensor(p_m),torch.zeros(p_m_t.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p*bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
