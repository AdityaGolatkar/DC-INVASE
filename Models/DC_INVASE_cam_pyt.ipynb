{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "  \n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def build_selector():\n",
    "    class selector(nn.Module):\n",
    "        def __init__(self,base):\n",
    "            super().__init__()\n",
    "            self.base = base\n",
    "            self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.fc = nn.Linear(1088,2)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.base(x)\n",
    "            x = self.gap(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "\n",
    "    ir2 = pretrainedmodels.__dict__['inceptionresnetv2'](num_classes=1000, pretrained='imagenet')\n",
    "    ir1 = nn.Sequential(*list(ir2.children())[:-6])\n",
    "    model = selector(ir1)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = build_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.base[-1][-1].relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 199, 199]             864\n",
      "       BatchNorm2d-2         [-1, 32, 199, 199]              64\n",
      "              ReLU-3         [-1, 32, 199, 199]               0\n",
      "       BasicConv2d-4         [-1, 32, 199, 199]               0\n",
      "            Conv2d-5         [-1, 32, 197, 197]           9,216\n",
      "       BatchNorm2d-6         [-1, 32, 197, 197]              64\n",
      "              ReLU-7         [-1, 32, 197, 197]               0\n",
      "       BasicConv2d-8         [-1, 32, 197, 197]               0\n",
      "            Conv2d-9         [-1, 64, 197, 197]          18,432\n",
      "      BatchNorm2d-10         [-1, 64, 197, 197]             128\n",
      "             ReLU-11         [-1, 64, 197, 197]               0\n",
      "      BasicConv2d-12         [-1, 64, 197, 197]               0\n",
      "        MaxPool2d-13           [-1, 64, 98, 98]               0\n",
      "           Conv2d-14           [-1, 80, 98, 98]           5,120\n",
      "      BatchNorm2d-15           [-1, 80, 98, 98]             160\n",
      "             ReLU-16           [-1, 80, 98, 98]               0\n",
      "      BasicConv2d-17           [-1, 80, 98, 98]               0\n",
      "           Conv2d-18          [-1, 192, 96, 96]         138,240\n",
      "      BatchNorm2d-19          [-1, 192, 96, 96]             384\n",
      "             ReLU-20          [-1, 192, 96, 96]               0\n",
      "      BasicConv2d-21          [-1, 192, 96, 96]               0\n",
      "        MaxPool2d-22          [-1, 192, 47, 47]               0\n",
      "           Conv2d-23           [-1, 96, 47, 47]          18,432\n",
      "      BatchNorm2d-24           [-1, 96, 47, 47]             192\n",
      "             ReLU-25           [-1, 96, 47, 47]               0\n",
      "      BasicConv2d-26           [-1, 96, 47, 47]               0\n",
      "           Conv2d-27           [-1, 48, 47, 47]           9,216\n",
      "      BatchNorm2d-28           [-1, 48, 47, 47]              96\n",
      "             ReLU-29           [-1, 48, 47, 47]               0\n",
      "      BasicConv2d-30           [-1, 48, 47, 47]               0\n",
      "           Conv2d-31           [-1, 64, 47, 47]          76,800\n",
      "      BatchNorm2d-32           [-1, 64, 47, 47]             128\n",
      "             ReLU-33           [-1, 64, 47, 47]               0\n",
      "      BasicConv2d-34           [-1, 64, 47, 47]               0\n",
      "           Conv2d-35           [-1, 64, 47, 47]          12,288\n",
      "      BatchNorm2d-36           [-1, 64, 47, 47]             128\n",
      "             ReLU-37           [-1, 64, 47, 47]               0\n",
      "      BasicConv2d-38           [-1, 64, 47, 47]               0\n",
      "           Conv2d-39           [-1, 96, 47, 47]          55,296\n",
      "      BatchNorm2d-40           [-1, 96, 47, 47]             192\n",
      "             ReLU-41           [-1, 96, 47, 47]               0\n",
      "      BasicConv2d-42           [-1, 96, 47, 47]               0\n",
      "           Conv2d-43           [-1, 96, 47, 47]          82,944\n",
      "      BatchNorm2d-44           [-1, 96, 47, 47]             192\n",
      "             ReLU-45           [-1, 96, 47, 47]               0\n",
      "      BasicConv2d-46           [-1, 96, 47, 47]               0\n",
      "        AvgPool2d-47          [-1, 192, 47, 47]               0\n",
      "           Conv2d-48           [-1, 64, 47, 47]          12,288\n",
      "      BatchNorm2d-49           [-1, 64, 47, 47]             128\n",
      "             ReLU-50           [-1, 64, 47, 47]               0\n",
      "      BasicConv2d-51           [-1, 64, 47, 47]               0\n",
      "         Mixed_5b-52          [-1, 320, 47, 47]               0\n",
      "           Conv2d-53           [-1, 32, 47, 47]          10,240\n",
      "      BatchNorm2d-54           [-1, 32, 47, 47]              64\n",
      "             ReLU-55           [-1, 32, 47, 47]               0\n",
      "      BasicConv2d-56           [-1, 32, 47, 47]               0\n",
      "           Conv2d-57           [-1, 32, 47, 47]          10,240\n",
      "      BatchNorm2d-58           [-1, 32, 47, 47]              64\n",
      "             ReLU-59           [-1, 32, 47, 47]               0\n",
      "      BasicConv2d-60           [-1, 32, 47, 47]               0\n",
      "           Conv2d-61           [-1, 32, 47, 47]           9,216\n",
      "      BatchNorm2d-62           [-1, 32, 47, 47]              64\n",
      "             ReLU-63           [-1, 32, 47, 47]               0\n",
      "      BasicConv2d-64           [-1, 32, 47, 47]               0\n",
      "           Conv2d-65           [-1, 32, 47, 47]          10,240\n",
      "      BatchNorm2d-66           [-1, 32, 47, 47]              64\n",
      "             ReLU-67           [-1, 32, 47, 47]               0\n",
      "      BasicConv2d-68           [-1, 32, 47, 47]               0\n",
      "           Conv2d-69           [-1, 48, 47, 47]          13,824\n",
      "      BatchNorm2d-70           [-1, 48, 47, 47]              96\n",
      "             ReLU-71           [-1, 48, 47, 47]               0\n",
      "      BasicConv2d-72           [-1, 48, 47, 47]               0\n",
      "           Conv2d-73           [-1, 64, 47, 47]          27,648\n",
      "      BatchNorm2d-74           [-1, 64, 47, 47]             128\n",
      "             ReLU-75           [-1, 64, 47, 47]               0\n",
      "      BasicConv2d-76           [-1, 64, 47, 47]               0\n",
      "           Conv2d-77          [-1, 320, 47, 47]          41,280\n",
      "             ReLU-78          [-1, 320, 47, 47]               0\n",
      "          Block35-79          [-1, 320, 47, 47]               0\n",
      "           Conv2d-80           [-1, 32, 47, 47]          10,240\n",
      "      BatchNorm2d-81           [-1, 32, 47, 47]              64\n",
      "             ReLU-82           [-1, 32, 47, 47]               0\n",
      "      BasicConv2d-83           [-1, 32, 47, 47]               0\n",
      "           Conv2d-84           [-1, 32, 47, 47]          10,240\n",
      "      BatchNorm2d-85           [-1, 32, 47, 47]              64\n",
      "             ReLU-86           [-1, 32, 47, 47]               0\n",
      "      BasicConv2d-87           [-1, 32, 47, 47]               0\n",
      "           Conv2d-88           [-1, 32, 47, 47]           9,216\n",
      "      BatchNorm2d-89           [-1, 32, 47, 47]              64\n",
      "             ReLU-90           [-1, 32, 47, 47]               0\n",
      "      BasicConv2d-91           [-1, 32, 47, 47]               0\n",
      "           Conv2d-92           [-1, 32, 47, 47]          10,240\n",
      "      BatchNorm2d-93           [-1, 32, 47, 47]              64\n",
      "             ReLU-94           [-1, 32, 47, 47]               0\n",
      "      BasicConv2d-95           [-1, 32, 47, 47]               0\n",
      "           Conv2d-96           [-1, 48, 47, 47]          13,824\n",
      "      BatchNorm2d-97           [-1, 48, 47, 47]              96\n",
      "             ReLU-98           [-1, 48, 47, 47]               0\n",
      "      BasicConv2d-99           [-1, 48, 47, 47]               0\n",
      "          Conv2d-100           [-1, 64, 47, 47]          27,648\n",
      "     BatchNorm2d-101           [-1, 64, 47, 47]             128\n",
      "            ReLU-102           [-1, 64, 47, 47]               0\n",
      "     BasicConv2d-103           [-1, 64, 47, 47]               0\n",
      "          Conv2d-104          [-1, 320, 47, 47]          41,280\n",
      "            ReLU-105          [-1, 320, 47, 47]               0\n",
      "         Block35-106          [-1, 320, 47, 47]               0\n",
      "          Conv2d-107           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-108           [-1, 32, 47, 47]              64\n",
      "            ReLU-109           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-110           [-1, 32, 47, 47]               0\n",
      "          Conv2d-111           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-112           [-1, 32, 47, 47]              64\n",
      "            ReLU-113           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-114           [-1, 32, 47, 47]               0\n",
      "          Conv2d-115           [-1, 32, 47, 47]           9,216\n",
      "     BatchNorm2d-116           [-1, 32, 47, 47]              64\n",
      "            ReLU-117           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-118           [-1, 32, 47, 47]               0\n",
      "          Conv2d-119           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-120           [-1, 32, 47, 47]              64\n",
      "            ReLU-121           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-122           [-1, 32, 47, 47]               0\n",
      "          Conv2d-123           [-1, 48, 47, 47]          13,824\n",
      "     BatchNorm2d-124           [-1, 48, 47, 47]              96\n",
      "            ReLU-125           [-1, 48, 47, 47]               0\n",
      "     BasicConv2d-126           [-1, 48, 47, 47]               0\n",
      "          Conv2d-127           [-1, 64, 47, 47]          27,648\n",
      "     BatchNorm2d-128           [-1, 64, 47, 47]             128\n",
      "            ReLU-129           [-1, 64, 47, 47]               0\n",
      "     BasicConv2d-130           [-1, 64, 47, 47]               0\n",
      "          Conv2d-131          [-1, 320, 47, 47]          41,280\n",
      "            ReLU-132          [-1, 320, 47, 47]               0\n",
      "         Block35-133          [-1, 320, 47, 47]               0\n",
      "          Conv2d-134           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-135           [-1, 32, 47, 47]              64\n",
      "            ReLU-136           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-137           [-1, 32, 47, 47]               0\n",
      "          Conv2d-138           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-139           [-1, 32, 47, 47]              64\n",
      "            ReLU-140           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-141           [-1, 32, 47, 47]               0\n",
      "          Conv2d-142           [-1, 32, 47, 47]           9,216\n",
      "     BatchNorm2d-143           [-1, 32, 47, 47]              64\n",
      "            ReLU-144           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-145           [-1, 32, 47, 47]               0\n",
      "          Conv2d-146           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-147           [-1, 32, 47, 47]              64\n",
      "            ReLU-148           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-149           [-1, 32, 47, 47]               0\n",
      "          Conv2d-150           [-1, 48, 47, 47]          13,824\n",
      "     BatchNorm2d-151           [-1, 48, 47, 47]              96\n",
      "            ReLU-152           [-1, 48, 47, 47]               0\n",
      "     BasicConv2d-153           [-1, 48, 47, 47]               0\n",
      "          Conv2d-154           [-1, 64, 47, 47]          27,648\n",
      "     BatchNorm2d-155           [-1, 64, 47, 47]             128\n",
      "            ReLU-156           [-1, 64, 47, 47]               0\n",
      "     BasicConv2d-157           [-1, 64, 47, 47]               0\n",
      "          Conv2d-158          [-1, 320, 47, 47]          41,280\n",
      "            ReLU-159          [-1, 320, 47, 47]               0\n",
      "         Block35-160          [-1, 320, 47, 47]               0\n",
      "          Conv2d-161           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-162           [-1, 32, 47, 47]              64\n",
      "            ReLU-163           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-164           [-1, 32, 47, 47]               0\n",
      "          Conv2d-165           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-166           [-1, 32, 47, 47]              64\n",
      "            ReLU-167           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-168           [-1, 32, 47, 47]               0\n",
      "          Conv2d-169           [-1, 32, 47, 47]           9,216\n",
      "     BatchNorm2d-170           [-1, 32, 47, 47]              64\n",
      "            ReLU-171           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-172           [-1, 32, 47, 47]               0\n",
      "          Conv2d-173           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-174           [-1, 32, 47, 47]              64\n",
      "            ReLU-175           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-176           [-1, 32, 47, 47]               0\n",
      "          Conv2d-177           [-1, 48, 47, 47]          13,824\n",
      "     BatchNorm2d-178           [-1, 48, 47, 47]              96\n",
      "            ReLU-179           [-1, 48, 47, 47]               0\n",
      "     BasicConv2d-180           [-1, 48, 47, 47]               0\n",
      "          Conv2d-181           [-1, 64, 47, 47]          27,648\n",
      "     BatchNorm2d-182           [-1, 64, 47, 47]             128\n",
      "            ReLU-183           [-1, 64, 47, 47]               0\n",
      "     BasicConv2d-184           [-1, 64, 47, 47]               0\n",
      "          Conv2d-185          [-1, 320, 47, 47]          41,280\n",
      "            ReLU-186          [-1, 320, 47, 47]               0\n",
      "         Block35-187          [-1, 320, 47, 47]               0\n",
      "          Conv2d-188           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-189           [-1, 32, 47, 47]              64\n",
      "            ReLU-190           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-191           [-1, 32, 47, 47]               0\n",
      "          Conv2d-192           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-193           [-1, 32, 47, 47]              64\n",
      "            ReLU-194           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-195           [-1, 32, 47, 47]               0\n",
      "          Conv2d-196           [-1, 32, 47, 47]           9,216\n",
      "     BatchNorm2d-197           [-1, 32, 47, 47]              64\n",
      "            ReLU-198           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-199           [-1, 32, 47, 47]               0\n",
      "          Conv2d-200           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-201           [-1, 32, 47, 47]              64\n",
      "            ReLU-202           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-203           [-1, 32, 47, 47]               0\n",
      "          Conv2d-204           [-1, 48, 47, 47]          13,824\n",
      "     BatchNorm2d-205           [-1, 48, 47, 47]              96\n",
      "            ReLU-206           [-1, 48, 47, 47]               0\n",
      "     BasicConv2d-207           [-1, 48, 47, 47]               0\n",
      "          Conv2d-208           [-1, 64, 47, 47]          27,648\n",
      "     BatchNorm2d-209           [-1, 64, 47, 47]             128\n",
      "            ReLU-210           [-1, 64, 47, 47]               0\n",
      "     BasicConv2d-211           [-1, 64, 47, 47]               0\n",
      "          Conv2d-212          [-1, 320, 47, 47]          41,280\n",
      "            ReLU-213          [-1, 320, 47, 47]               0\n",
      "         Block35-214          [-1, 320, 47, 47]               0\n",
      "          Conv2d-215           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-216           [-1, 32, 47, 47]              64\n",
      "            ReLU-217           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-218           [-1, 32, 47, 47]               0\n",
      "          Conv2d-219           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-220           [-1, 32, 47, 47]              64\n",
      "            ReLU-221           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-222           [-1, 32, 47, 47]               0\n",
      "          Conv2d-223           [-1, 32, 47, 47]           9,216\n",
      "     BatchNorm2d-224           [-1, 32, 47, 47]              64\n",
      "            ReLU-225           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-226           [-1, 32, 47, 47]               0\n",
      "          Conv2d-227           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-228           [-1, 32, 47, 47]              64\n",
      "            ReLU-229           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-230           [-1, 32, 47, 47]               0\n",
      "          Conv2d-231           [-1, 48, 47, 47]          13,824\n",
      "     BatchNorm2d-232           [-1, 48, 47, 47]              96\n",
      "            ReLU-233           [-1, 48, 47, 47]               0\n",
      "     BasicConv2d-234           [-1, 48, 47, 47]               0\n",
      "          Conv2d-235           [-1, 64, 47, 47]          27,648\n",
      "     BatchNorm2d-236           [-1, 64, 47, 47]             128\n",
      "            ReLU-237           [-1, 64, 47, 47]               0\n",
      "     BasicConv2d-238           [-1, 64, 47, 47]               0\n",
      "          Conv2d-239          [-1, 320, 47, 47]          41,280\n",
      "            ReLU-240          [-1, 320, 47, 47]               0\n",
      "         Block35-241          [-1, 320, 47, 47]               0\n",
      "          Conv2d-242           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-243           [-1, 32, 47, 47]              64\n",
      "            ReLU-244           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-245           [-1, 32, 47, 47]               0\n",
      "          Conv2d-246           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-247           [-1, 32, 47, 47]              64\n",
      "            ReLU-248           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-249           [-1, 32, 47, 47]               0\n",
      "          Conv2d-250           [-1, 32, 47, 47]           9,216\n",
      "     BatchNorm2d-251           [-1, 32, 47, 47]              64\n",
      "            ReLU-252           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-253           [-1, 32, 47, 47]               0\n",
      "          Conv2d-254           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-255           [-1, 32, 47, 47]              64\n",
      "            ReLU-256           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-257           [-1, 32, 47, 47]               0\n",
      "          Conv2d-258           [-1, 48, 47, 47]          13,824\n",
      "     BatchNorm2d-259           [-1, 48, 47, 47]              96\n",
      "            ReLU-260           [-1, 48, 47, 47]               0\n",
      "     BasicConv2d-261           [-1, 48, 47, 47]               0\n",
      "          Conv2d-262           [-1, 64, 47, 47]          27,648\n",
      "     BatchNorm2d-263           [-1, 64, 47, 47]             128\n",
      "            ReLU-264           [-1, 64, 47, 47]               0\n",
      "     BasicConv2d-265           [-1, 64, 47, 47]               0\n",
      "          Conv2d-266          [-1, 320, 47, 47]          41,280\n",
      "            ReLU-267          [-1, 320, 47, 47]               0\n",
      "         Block35-268          [-1, 320, 47, 47]               0\n",
      "          Conv2d-269           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-270           [-1, 32, 47, 47]              64\n",
      "            ReLU-271           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-272           [-1, 32, 47, 47]               0\n",
      "          Conv2d-273           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-274           [-1, 32, 47, 47]              64\n",
      "            ReLU-275           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-276           [-1, 32, 47, 47]               0\n",
      "          Conv2d-277           [-1, 32, 47, 47]           9,216\n",
      "     BatchNorm2d-278           [-1, 32, 47, 47]              64\n",
      "            ReLU-279           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-280           [-1, 32, 47, 47]               0\n",
      "          Conv2d-281           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-282           [-1, 32, 47, 47]              64\n",
      "            ReLU-283           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-284           [-1, 32, 47, 47]               0\n",
      "          Conv2d-285           [-1, 48, 47, 47]          13,824\n",
      "     BatchNorm2d-286           [-1, 48, 47, 47]              96\n",
      "            ReLU-287           [-1, 48, 47, 47]               0\n",
      "     BasicConv2d-288           [-1, 48, 47, 47]               0\n",
      "          Conv2d-289           [-1, 64, 47, 47]          27,648\n",
      "     BatchNorm2d-290           [-1, 64, 47, 47]             128\n",
      "            ReLU-291           [-1, 64, 47, 47]               0\n",
      "     BasicConv2d-292           [-1, 64, 47, 47]               0\n",
      "          Conv2d-293          [-1, 320, 47, 47]          41,280\n",
      "            ReLU-294          [-1, 320, 47, 47]               0\n",
      "         Block35-295          [-1, 320, 47, 47]               0\n",
      "          Conv2d-296           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-297           [-1, 32, 47, 47]              64\n",
      "            ReLU-298           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-299           [-1, 32, 47, 47]               0\n",
      "          Conv2d-300           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-301           [-1, 32, 47, 47]              64\n",
      "            ReLU-302           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-303           [-1, 32, 47, 47]               0\n",
      "          Conv2d-304           [-1, 32, 47, 47]           9,216\n",
      "     BatchNorm2d-305           [-1, 32, 47, 47]              64\n",
      "            ReLU-306           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-307           [-1, 32, 47, 47]               0\n",
      "          Conv2d-308           [-1, 32, 47, 47]          10,240\n",
      "     BatchNorm2d-309           [-1, 32, 47, 47]              64\n",
      "            ReLU-310           [-1, 32, 47, 47]               0\n",
      "     BasicConv2d-311           [-1, 32, 47, 47]               0\n",
      "          Conv2d-312           [-1, 48, 47, 47]          13,824\n",
      "     BatchNorm2d-313           [-1, 48, 47, 47]              96\n",
      "            ReLU-314           [-1, 48, 47, 47]               0\n",
      "     BasicConv2d-315           [-1, 48, 47, 47]               0\n",
      "          Conv2d-316           [-1, 64, 47, 47]          27,648\n",
      "     BatchNorm2d-317           [-1, 64, 47, 47]             128\n",
      "            ReLU-318           [-1, 64, 47, 47]               0\n",
      "     BasicConv2d-319           [-1, 64, 47, 47]               0\n",
      "          Conv2d-320          [-1, 320, 47, 47]          41,280\n",
      "            ReLU-321          [-1, 320, 47, 47]               0\n",
      "         Block35-322          [-1, 320, 47, 47]               0\n",
      "          Conv2d-323          [-1, 384, 23, 23]       1,105,920\n",
      "     BatchNorm2d-324          [-1, 384, 23, 23]             768\n",
      "            ReLU-325          [-1, 384, 23, 23]               0\n",
      "     BasicConv2d-326          [-1, 384, 23, 23]               0\n",
      "          Conv2d-327          [-1, 256, 47, 47]          81,920\n",
      "     BatchNorm2d-328          [-1, 256, 47, 47]             512\n",
      "            ReLU-329          [-1, 256, 47, 47]               0\n",
      "     BasicConv2d-330          [-1, 256, 47, 47]               0\n",
      "          Conv2d-331          [-1, 256, 47, 47]         589,824\n",
      "     BatchNorm2d-332          [-1, 256, 47, 47]             512\n",
      "            ReLU-333          [-1, 256, 47, 47]               0\n",
      "     BasicConv2d-334          [-1, 256, 47, 47]               0\n",
      "          Conv2d-335          [-1, 384, 23, 23]         884,736\n",
      "     BatchNorm2d-336          [-1, 384, 23, 23]             768\n",
      "            ReLU-337          [-1, 384, 23, 23]               0\n",
      "     BasicConv2d-338          [-1, 384, 23, 23]               0\n",
      "       MaxPool2d-339          [-1, 320, 23, 23]               0\n",
      "        Mixed_6a-340         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-341          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-342          [-1, 192, 23, 23]             384\n",
      "            ReLU-343          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-344          [-1, 192, 23, 23]               0\n",
      "          Conv2d-345          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-346          [-1, 128, 23, 23]             256\n",
      "            ReLU-347          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-348          [-1, 128, 23, 23]               0\n",
      "          Conv2d-349          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-350          [-1, 160, 23, 23]             320\n",
      "            ReLU-351          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-352          [-1, 160, 23, 23]               0\n",
      "          Conv2d-353          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-354          [-1, 192, 23, 23]             384\n",
      "            ReLU-355          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-356          [-1, 192, 23, 23]               0\n",
      "          Conv2d-357         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-358         [-1, 1088, 23, 23]               0\n",
      "         Block17-359         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-360          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-361          [-1, 192, 23, 23]             384\n",
      "            ReLU-362          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-363          [-1, 192, 23, 23]               0\n",
      "          Conv2d-364          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-365          [-1, 128, 23, 23]             256\n",
      "            ReLU-366          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-367          [-1, 128, 23, 23]               0\n",
      "          Conv2d-368          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-369          [-1, 160, 23, 23]             320\n",
      "            ReLU-370          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-371          [-1, 160, 23, 23]               0\n",
      "          Conv2d-372          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-373          [-1, 192, 23, 23]             384\n",
      "            ReLU-374          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-375          [-1, 192, 23, 23]               0\n",
      "          Conv2d-376         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-377         [-1, 1088, 23, 23]               0\n",
      "         Block17-378         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-379          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-380          [-1, 192, 23, 23]             384\n",
      "            ReLU-381          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-382          [-1, 192, 23, 23]               0\n",
      "          Conv2d-383          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-384          [-1, 128, 23, 23]             256\n",
      "            ReLU-385          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-386          [-1, 128, 23, 23]               0\n",
      "          Conv2d-387          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-388          [-1, 160, 23, 23]             320\n",
      "            ReLU-389          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-390          [-1, 160, 23, 23]               0\n",
      "          Conv2d-391          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-392          [-1, 192, 23, 23]             384\n",
      "            ReLU-393          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-394          [-1, 192, 23, 23]               0\n",
      "          Conv2d-395         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-396         [-1, 1088, 23, 23]               0\n",
      "         Block17-397         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-398          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-399          [-1, 192, 23, 23]             384\n",
      "            ReLU-400          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-401          [-1, 192, 23, 23]               0\n",
      "          Conv2d-402          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-403          [-1, 128, 23, 23]             256\n",
      "            ReLU-404          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-405          [-1, 128, 23, 23]               0\n",
      "          Conv2d-406          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-407          [-1, 160, 23, 23]             320\n",
      "            ReLU-408          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-409          [-1, 160, 23, 23]               0\n",
      "          Conv2d-410          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-411          [-1, 192, 23, 23]             384\n",
      "            ReLU-412          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-413          [-1, 192, 23, 23]               0\n",
      "          Conv2d-414         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-415         [-1, 1088, 23, 23]               0\n",
      "         Block17-416         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-417          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-418          [-1, 192, 23, 23]             384\n",
      "            ReLU-419          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-420          [-1, 192, 23, 23]               0\n",
      "          Conv2d-421          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-422          [-1, 128, 23, 23]             256\n",
      "            ReLU-423          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-424          [-1, 128, 23, 23]               0\n",
      "          Conv2d-425          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-426          [-1, 160, 23, 23]             320\n",
      "            ReLU-427          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-428          [-1, 160, 23, 23]               0\n",
      "          Conv2d-429          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-430          [-1, 192, 23, 23]             384\n",
      "            ReLU-431          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-432          [-1, 192, 23, 23]               0\n",
      "          Conv2d-433         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-434         [-1, 1088, 23, 23]               0\n",
      "         Block17-435         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-436          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-437          [-1, 192, 23, 23]             384\n",
      "            ReLU-438          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-439          [-1, 192, 23, 23]               0\n",
      "          Conv2d-440          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-441          [-1, 128, 23, 23]             256\n",
      "            ReLU-442          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-443          [-1, 128, 23, 23]               0\n",
      "          Conv2d-444          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-445          [-1, 160, 23, 23]             320\n",
      "            ReLU-446          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-447          [-1, 160, 23, 23]               0\n",
      "          Conv2d-448          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-449          [-1, 192, 23, 23]             384\n",
      "            ReLU-450          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-451          [-1, 192, 23, 23]               0\n",
      "          Conv2d-452         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-453         [-1, 1088, 23, 23]               0\n",
      "         Block17-454         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-455          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-456          [-1, 192, 23, 23]             384\n",
      "            ReLU-457          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-458          [-1, 192, 23, 23]               0\n",
      "          Conv2d-459          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-460          [-1, 128, 23, 23]             256\n",
      "            ReLU-461          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-462          [-1, 128, 23, 23]               0\n",
      "          Conv2d-463          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-464          [-1, 160, 23, 23]             320\n",
      "            ReLU-465          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-466          [-1, 160, 23, 23]               0\n",
      "          Conv2d-467          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-468          [-1, 192, 23, 23]             384\n",
      "            ReLU-469          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-470          [-1, 192, 23, 23]               0\n",
      "          Conv2d-471         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-472         [-1, 1088, 23, 23]               0\n",
      "         Block17-473         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-474          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-475          [-1, 192, 23, 23]             384\n",
      "            ReLU-476          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-477          [-1, 192, 23, 23]               0\n",
      "          Conv2d-478          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-479          [-1, 128, 23, 23]             256\n",
      "            ReLU-480          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-481          [-1, 128, 23, 23]               0\n",
      "          Conv2d-482          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-483          [-1, 160, 23, 23]             320\n",
      "            ReLU-484          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-485          [-1, 160, 23, 23]               0\n",
      "          Conv2d-486          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-487          [-1, 192, 23, 23]             384\n",
      "            ReLU-488          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-489          [-1, 192, 23, 23]               0\n",
      "          Conv2d-490         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-491         [-1, 1088, 23, 23]               0\n",
      "         Block17-492         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-493          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-494          [-1, 192, 23, 23]             384\n",
      "            ReLU-495          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-496          [-1, 192, 23, 23]               0\n",
      "          Conv2d-497          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-498          [-1, 128, 23, 23]             256\n",
      "            ReLU-499          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-500          [-1, 128, 23, 23]               0\n",
      "          Conv2d-501          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-502          [-1, 160, 23, 23]             320\n",
      "            ReLU-503          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-504          [-1, 160, 23, 23]               0\n",
      "          Conv2d-505          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-506          [-1, 192, 23, 23]             384\n",
      "            ReLU-507          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-508          [-1, 192, 23, 23]               0\n",
      "          Conv2d-509         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-510         [-1, 1088, 23, 23]               0\n",
      "         Block17-511         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-512          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-513          [-1, 192, 23, 23]             384\n",
      "            ReLU-514          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-515          [-1, 192, 23, 23]               0\n",
      "          Conv2d-516          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-517          [-1, 128, 23, 23]             256\n",
      "            ReLU-518          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-519          [-1, 128, 23, 23]               0\n",
      "          Conv2d-520          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-521          [-1, 160, 23, 23]             320\n",
      "            ReLU-522          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-523          [-1, 160, 23, 23]               0\n",
      "          Conv2d-524          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-525          [-1, 192, 23, 23]             384\n",
      "            ReLU-526          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-527          [-1, 192, 23, 23]               0\n",
      "          Conv2d-528         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-529         [-1, 1088, 23, 23]               0\n",
      "         Block17-530         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-531          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-532          [-1, 192, 23, 23]             384\n",
      "            ReLU-533          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-534          [-1, 192, 23, 23]               0\n",
      "          Conv2d-535          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-536          [-1, 128, 23, 23]             256\n",
      "            ReLU-537          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-538          [-1, 128, 23, 23]               0\n",
      "          Conv2d-539          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-540          [-1, 160, 23, 23]             320\n",
      "            ReLU-541          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-542          [-1, 160, 23, 23]               0\n",
      "          Conv2d-543          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-544          [-1, 192, 23, 23]             384\n",
      "            ReLU-545          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-546          [-1, 192, 23, 23]               0\n",
      "          Conv2d-547         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-548         [-1, 1088, 23, 23]               0\n",
      "         Block17-549         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-550          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-551          [-1, 192, 23, 23]             384\n",
      "            ReLU-552          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-553          [-1, 192, 23, 23]               0\n",
      "          Conv2d-554          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-555          [-1, 128, 23, 23]             256\n",
      "            ReLU-556          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-557          [-1, 128, 23, 23]               0\n",
      "          Conv2d-558          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-559          [-1, 160, 23, 23]             320\n",
      "            ReLU-560          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-561          [-1, 160, 23, 23]               0\n",
      "          Conv2d-562          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-563          [-1, 192, 23, 23]             384\n",
      "            ReLU-564          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-565          [-1, 192, 23, 23]               0\n",
      "          Conv2d-566         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-567         [-1, 1088, 23, 23]               0\n",
      "         Block17-568         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-569          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-570          [-1, 192, 23, 23]             384\n",
      "            ReLU-571          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-572          [-1, 192, 23, 23]               0\n",
      "          Conv2d-573          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-574          [-1, 128, 23, 23]             256\n",
      "            ReLU-575          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-576          [-1, 128, 23, 23]               0\n",
      "          Conv2d-577          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-578          [-1, 160, 23, 23]             320\n",
      "            ReLU-579          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-580          [-1, 160, 23, 23]               0\n",
      "          Conv2d-581          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-582          [-1, 192, 23, 23]             384\n",
      "            ReLU-583          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-584          [-1, 192, 23, 23]               0\n",
      "          Conv2d-585         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-586         [-1, 1088, 23, 23]               0\n",
      "         Block17-587         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-588          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-589          [-1, 192, 23, 23]             384\n",
      "            ReLU-590          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-591          [-1, 192, 23, 23]               0\n",
      "          Conv2d-592          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-593          [-1, 128, 23, 23]             256\n",
      "            ReLU-594          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-595          [-1, 128, 23, 23]               0\n",
      "          Conv2d-596          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-597          [-1, 160, 23, 23]             320\n",
      "            ReLU-598          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-599          [-1, 160, 23, 23]               0\n",
      "          Conv2d-600          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-601          [-1, 192, 23, 23]             384\n",
      "            ReLU-602          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-603          [-1, 192, 23, 23]               0\n",
      "          Conv2d-604         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-605         [-1, 1088, 23, 23]               0\n",
      "         Block17-606         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-607          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-608          [-1, 192, 23, 23]             384\n",
      "            ReLU-609          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-610          [-1, 192, 23, 23]               0\n",
      "          Conv2d-611          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-612          [-1, 128, 23, 23]             256\n",
      "            ReLU-613          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-614          [-1, 128, 23, 23]               0\n",
      "          Conv2d-615          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-616          [-1, 160, 23, 23]             320\n",
      "            ReLU-617          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-618          [-1, 160, 23, 23]               0\n",
      "          Conv2d-619          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-620          [-1, 192, 23, 23]             384\n",
      "            ReLU-621          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-622          [-1, 192, 23, 23]               0\n",
      "          Conv2d-623         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-624         [-1, 1088, 23, 23]               0\n",
      "         Block17-625         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-626          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-627          [-1, 192, 23, 23]             384\n",
      "            ReLU-628          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-629          [-1, 192, 23, 23]               0\n",
      "          Conv2d-630          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-631          [-1, 128, 23, 23]             256\n",
      "            ReLU-632          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-633          [-1, 128, 23, 23]               0\n",
      "          Conv2d-634          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-635          [-1, 160, 23, 23]             320\n",
      "            ReLU-636          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-637          [-1, 160, 23, 23]               0\n",
      "          Conv2d-638          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-639          [-1, 192, 23, 23]             384\n",
      "            ReLU-640          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-641          [-1, 192, 23, 23]               0\n",
      "          Conv2d-642         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-643         [-1, 1088, 23, 23]               0\n",
      "         Block17-644         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-645          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-646          [-1, 192, 23, 23]             384\n",
      "            ReLU-647          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-648          [-1, 192, 23, 23]               0\n",
      "          Conv2d-649          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-650          [-1, 128, 23, 23]             256\n",
      "            ReLU-651          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-652          [-1, 128, 23, 23]               0\n",
      "          Conv2d-653          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-654          [-1, 160, 23, 23]             320\n",
      "            ReLU-655          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-656          [-1, 160, 23, 23]               0\n",
      "          Conv2d-657          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-658          [-1, 192, 23, 23]             384\n",
      "            ReLU-659          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-660          [-1, 192, 23, 23]               0\n",
      "          Conv2d-661         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-662         [-1, 1088, 23, 23]               0\n",
      "         Block17-663         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-664          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-665          [-1, 192, 23, 23]             384\n",
      "            ReLU-666          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-667          [-1, 192, 23, 23]               0\n",
      "          Conv2d-668          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-669          [-1, 128, 23, 23]             256\n",
      "            ReLU-670          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-671          [-1, 128, 23, 23]               0\n",
      "          Conv2d-672          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-673          [-1, 160, 23, 23]             320\n",
      "            ReLU-674          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-675          [-1, 160, 23, 23]               0\n",
      "          Conv2d-676          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-677          [-1, 192, 23, 23]             384\n",
      "            ReLU-678          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-679          [-1, 192, 23, 23]               0\n",
      "          Conv2d-680         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-681         [-1, 1088, 23, 23]               0\n",
      "         Block17-682         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-683          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-684          [-1, 192, 23, 23]             384\n",
      "            ReLU-685          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-686          [-1, 192, 23, 23]               0\n",
      "          Conv2d-687          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-688          [-1, 128, 23, 23]             256\n",
      "            ReLU-689          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-690          [-1, 128, 23, 23]               0\n",
      "          Conv2d-691          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-692          [-1, 160, 23, 23]             320\n",
      "            ReLU-693          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-694          [-1, 160, 23, 23]               0\n",
      "          Conv2d-695          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-696          [-1, 192, 23, 23]             384\n",
      "            ReLU-697          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-698          [-1, 192, 23, 23]               0\n",
      "          Conv2d-699         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-700         [-1, 1088, 23, 23]               0\n",
      "         Block17-701         [-1, 1088, 23, 23]               0\n",
      "          Conv2d-702          [-1, 192, 23, 23]         208,896\n",
      "     BatchNorm2d-703          [-1, 192, 23, 23]             384\n",
      "            ReLU-704          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-705          [-1, 192, 23, 23]               0\n",
      "          Conv2d-706          [-1, 128, 23, 23]         139,264\n",
      "     BatchNorm2d-707          [-1, 128, 23, 23]             256\n",
      "            ReLU-708          [-1, 128, 23, 23]               0\n",
      "     BasicConv2d-709          [-1, 128, 23, 23]               0\n",
      "          Conv2d-710          [-1, 160, 23, 23]         143,360\n",
      "     BatchNorm2d-711          [-1, 160, 23, 23]             320\n",
      "            ReLU-712          [-1, 160, 23, 23]               0\n",
      "     BasicConv2d-713          [-1, 160, 23, 23]               0\n",
      "          Conv2d-714          [-1, 192, 23, 23]         215,040\n",
      "     BatchNorm2d-715          [-1, 192, 23, 23]             384\n",
      "            ReLU-716          [-1, 192, 23, 23]               0\n",
      "     BasicConv2d-717          [-1, 192, 23, 23]               0\n",
      "          Conv2d-718         [-1, 1088, 23, 23]         418,880\n",
      "            ReLU-719         [-1, 1088, 23, 23]               0\n",
      "         Block17-720         [-1, 1088, 23, 23]               0\n",
      "AdaptiveAvgPool2d-721           [-1, 1088, 1, 1]               0\n",
      "          Linear-722                    [-1, 2]           2,178\n",
      "================================================================\n",
      "Total params: 26,875,490\n",
      "Trainable params: 26,875,490\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.83\n",
      "Forward/backward pass size (MB): 1138.60\n",
      "Params size (MB): 102.52\n",
      "Estimated Total Size (MB): 1242.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(a.cuda(),(3,400,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = self.root_dir.replace('CBIS-DDSM_classification','masks')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']\n",
    "\n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'].replace('.j','_mask.j'))\n",
    "        mask = io.imread(mask_name)\n",
    "        mask = np.array([mask,mask,mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask) \n",
    "      \n",
    "        return {'image':image,'category':label,'mask':mask, 'name':img_name}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(image_size),#row to column ratio should be 1.69\n",
    "            #transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomVerticalFlip(0.5),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "\n",
    "        if x!= 'test':\n",
    "            dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,shuffle=True, num_workers=4)\n",
    "        else:\n",
    "            dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,shuffle=False, num_workers=4)\n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "\n",
    "def build_spd():\n",
    "    class selector(nn.Module):\n",
    "        def __init__(self,base):\n",
    "            super().__init__()\n",
    "            self.base = base\n",
    "            self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.fc = nn.Linear(1088,2)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.base(x)\n",
    "            x = self.gap(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "\n",
    "    ir2 = pretrainedmodels.__dict__['inceptionresnetv2'](num_classes=1000, pretrained='imagenet')\n",
    "    ir1 = nn.Sequential(*list(ir2.children())[:-6])\n",
    "    model = selector(ir1)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def denorm_img(img_ten,img_mean,img_std):\n",
    "\n",
    "    bz,nc,h,w = img_ten.shape\n",
    "    output = []\n",
    "    img_num = img_ten.numpy()\n",
    "    \n",
    "    for i in range(bz):\n",
    "        \n",
    "        img = img_ten[i].numpy().squeeze()\n",
    "        \n",
    "        img[0,:,:] = img[0,:,:]*img_std[0]\n",
    "        img[1,:,:] = img[1,:,:]*img_std[1]\n",
    "        img[2,:,:] = img[2,:,:]*img_std[2]\n",
    "\n",
    "        img[0,:,:] = img[0,:,:] + img_mean[0]\n",
    "        img[1,:,:] = img[1,:,:] + img_mean[1]\n",
    "        img[2,:,:] = img[2,:,:] + img_mean[2]\n",
    "        \n",
    "        img = img.mean(axis=0)\n",
    "        img[img>=0.2*img.max()] = 1\n",
    "        img[img<0.2*img.max()] = 0\n",
    "        \n",
    "        output.append(img)\n",
    "    \n",
    "    output = np.array(output)\n",
    "    return output\n",
    "    \n",
    "def get_IoU(pred, targs, device):\n",
    "\n",
    "    #pred = pred.numpy()\n",
    "    max_pred = pred.max()\n",
    "    pred[pred>0.5*max_pred] = 1\n",
    "    pred[pred<0.5*max_pred] = 0\n",
    "\n",
    "    targs = torch.Tensor(targs).to(device)\n",
    "    \n",
    "    #targs = torch.Tensor((targs>0)).to(device)#.float()\n",
    "    #pred = (pred>0)#.float()\n",
    "    return (pred*targs).sum() / ((pred+targs).sum() - (pred*targs).sum())\n",
    "\n",
    "def get_auc_roc(pred, targs):\n",
    "    \n",
    "    bz,c = pred.shape\n",
    "    out = np.zeros(targs.shape)\n",
    "    for i in range(bz):\n",
    "        out[i] = pred[i][int(targs[i])]\n",
    "    return roc_auc_score(targs,out)\n",
    "\n",
    "def make_prob(a,device):\n",
    "    b = a.shape[0]\n",
    "    \n",
    "    f1 = a.view(b,-1)\n",
    "    mi = torch.min(f1,-1)\n",
    "    \n",
    "    t1 = torch.ones((b,1,1,1)).to(device)\n",
    "    t1[:,0,0,0] = mi[0]\n",
    "    \n",
    "    d1 = a - t1\n",
    "    \n",
    "    ma = torch.max(d1.view(b,-1),-1)\n",
    "    t2 = torch.ones((b,1,1,1)).to(device)\n",
    "    t2[:,0,0,0] = ma[0]\n",
    "    \n",
    "    return d1/t2\n",
    "\n",
    "class SaveFeatures:\n",
    "    def __init__(self, m):\n",
    "        self.handle = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, m, inp, outp):\n",
    "        self.features = outp\n",
    "    def remove(self):\n",
    "        self.handle.remove()\n",
    "        \n",
    "def returnCAM(feature_conv, weight_softmax, class_idx, output_shape,device):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = output_shape\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for i in range(bz):\n",
    "        #import pdb;pdb.set_trace()\n",
    "        idx = class_idx[0][i]\n",
    "        cam = weight_softmax[idx].dot(feature_conv[i].reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        #cam = cam - np.min(cam)\n",
    "        #cam_img = cam / np.max(cam)\n",
    "        #print('cam img shape',cam_img.shape)\n",
    "        cam_img = cv2.resize(cam,(size_upsample[0],size_upsample[1]))\n",
    "        cam_img[cam_img<0] = 0\n",
    "        output_cam.append(cam_img)\n",
    "    output_cam = torch.Tensor(output_cam)\n",
    "    \n",
    "    final_output_cam = torch.zeros((bz,1,size_upsample[1],size_upsample[0]))\n",
    "    final_output_cam[:,0,:,:] = output_cam\n",
    "    \n",
    "    return final_output_cam\n",
    "\n",
    "class dc_invase():\n",
    "    def __init__(self, alpha=1, beta=0.1):\n",
    "        \n",
    "        #Initialization\n",
    "        self.data_dir = '../Data/CBIS-DDSM_classification_orient/'\n",
    "        self.train_csv = '../CSV/gain_train.csv'\n",
    "        self.num_epochs = 200\n",
    "        self.input_shape = (320,256) #(640,512)#(224,224)#(640,384) (640,512)\n",
    "        self.batch_size = 32\n",
    "        self.img_mean = [0.223, 0.231, 0.243]\n",
    "        self.img_std = [0.266, 0.270, 0.274]\n",
    "        self.alpha = 0.1\n",
    "        self.beta = 0.1\n",
    "        self.exp_name = 'dc_invase_resnet'\n",
    "        \n",
    "        #Define the three models\n",
    "        self.selector = build_spd()\n",
    "        self.predictor = build_spd()\n",
    "        self.discriminator = build_spd()\n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.selector = self.selector.cuda()\n",
    "        self.predictor = self.predictor.cuda()\n",
    "        self.discriminator = self.discriminator.cuda()\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.input_shape,self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "        #Define the three optimizers one for each model\n",
    "        self.optimizer_sel = optim.Adam(self.selector.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        self.optimizer_pred = optim.Adam(self.predictor.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        self.optimizer_dis = optim.Adam(self.discriminator.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        best_sel_loss = 0.0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':\n",
    "                    \n",
    "                    #Set the models to training mode\n",
    "                    self.predictor.train() \n",
    "                    self.discriminator.train()\n",
    "                    self.selector.train()\n",
    "                \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    self.predictor.eval()\n",
    "                    self.discriminator.eval()\n",
    "                    self.selector.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_sel_loss = 0.0\n",
    "                running_pred_loss = 0.0\n",
    "                running_dis_loss = 0.0\n",
    "                \n",
    "                #Metrics : predictor auc and selector iou\n",
    "                running_pred_auc = 0\n",
    "                running_iou = 0\n",
    "                running_corrects = 0\n",
    "\n",
    "\n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    labels = sampled_batch['category']\n",
    "                    mask = denorm_img(sampled_batch['mask'],self.img_mean,self.img_std)\n",
    "\n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    labels = labels.long().to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer_sel.zero_grad()\n",
    "                    self.optimizer_pred.zero_grad()\n",
    "                    self.optimizer_dis.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        \n",
    "                        #import pdb;pdb.set_trace()\n",
    "                        \n",
    "                        #Generate selection probabilites using selector function. This will be the mask\n",
    "                        sfs = SaveFeatures(self.selector.base[-1][-1].relu)\n",
    "                        sel_out = self.selector(inputs)\n",
    "                        sfs.remove()\n",
    "                        sel_pred_prob = F.softmax(sel_out)\n",
    "                        _, preds = torch.max(sel_out, 1)\n",
    "\n",
    "                        params = list(model.parameters())\n",
    "                        weight_softmax = torch.squeeze(params[-2].data)\n",
    "                    \n",
    "                        #Get the CAM\n",
    "                        sel_prob = returnCAM(features,weight_softmax,[preds],(inputs.size(-1),inputs.size(-2)))\n",
    "                        \n",
    "                        #sel_prob = make_prob(self.selector(inputs),self.device)\n",
    "                        \n",
    "                        #Compute the Complementary selection probability\n",
    "                        comp_sel_prob = 1 - sel_prob\n",
    "                        \n",
    "                        #Generate X_S the selection probability masked image\n",
    "                        x_s = inputs*sel_prob\n",
    "                        \n",
    "                        #Generate X_S_bar the complementary selection probability masked image\n",
    "                        x_s_bar = inputs*comp_sel_prob\n",
    "                        \n",
    "                        #Generate predictor output probabilities\n",
    "                        pred_out = self.predictor(x_s)\n",
    "                        pred_prob = F.softmax(pred_out)\n",
    "                        \n",
    "                        #Generate discriminator probabilities\n",
    "                        dis_out = self.discriminator(x_s_bar)\n",
    "                        dis_prob = F.softmax(dis_out)\n",
    "                        \n",
    "                        #Predictor Cross entropy\n",
    "                        pred_ce_loss = F.cross_entropy(pred_out,labels)\n",
    "                        \n",
    "                        #Discriminator Negative Cross entropy\n",
    "                        dis_ce_loss = F.cross_entropy(dis_out,1-labels)\n",
    "                        \n",
    "                        #Selector function loss\n",
    "                        sel_ce_loss = F.cross_entropy(sel_out,labels)\n",
    "                        l2_norm = torch.norm(sel_prob.view((sel_prob.shape[0],-1)),2,-1)/torch.prod(torch.Tensor(self.input_shape).to(self.device))\n",
    "                        norm_loss = torch.mean(l2_norm)\n",
    "                        sel_loss = (self.alpha - 1)*sel_ce_loss + pred_ce_loss + self.alpha*dis_ce_loss + self.beta*norm_loss\n",
    "                        \n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            #Update predictor using pred_ce_loss\n",
    "                            #The gradients of pred_ce_loss should not update the params of disc or sel\n",
    "                            pred_ce_loss.backward(retain_graph=True)\n",
    "                            self.optimizer_sel.zero_grad()\n",
    "                            self.optimizer_dis.zero_grad()\n",
    "                            self.optimizer_pred.step()\n",
    "                            \n",
    "                            #The gradients of dis_ce_loss should not update the params of pred or sel\n",
    "                            dis_ce_loss.backward(retain_graph=True)\n",
    "                            self.optimizer_sel.zero_grad()\n",
    "                            self.optimizer_pred.zero_grad()\n",
    "                            self.optimizer_dis.step()\n",
    "                            \n",
    "                            #Update sel\n",
    "                            sel_loss.backward()\n",
    "                            self.optimizer_pred.zero_grad()\n",
    "                            self.optimizer_dis.zero_grad()\n",
    "                            self.optimizer_sel.step()\n",
    "                                    \n",
    "                    # statistics\n",
    "                    running_sel_loss += sel_loss.item() * inputs.size(0)\n",
    "                    running_pred_loss += pred_ce_loss.item() * inputs.size(0)\n",
    "                    running_dis_loss += dis_ce_loss.item() * inputs.size(0)\n",
    "\n",
    "                    \n",
    "                    running_pred_auc += get_auc_roc(pred_prob.detach().cpu().numpy(),labels.data)\n",
    "                    running_iou += get_IoU(sel_prob,mask,self.device)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "                    \n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "\n",
    "                epoch_sel_loss = running_sel_loss / self.dataset_sizes[phase]\n",
    "                epoch_pred_loss = running_pred_loss / self.dataset_sizes[phase]\n",
    "                epoch_dis_loss = running_dis_loss / self.dataset_sizes[phase]\n",
    "                \n",
    "                epoch_pred_auc = 1.0*running_pred_auc / self.dataset_sizes[phase]\n",
    "                epoch_IoU = 1.0*running_iou / self.dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "\n",
    "                print('{} Sel_Loss: {:.4f} Pred_Loss: {:.4f} Dis_Loss: {:.4f} ACC: {:.4f} AUC: {:.4f} IoU: {:.4f}'.format(\n",
    "                    phase, epoch_sel_loss, epoch_pred_loss, epoch_dis_loss, epoch_acc, epoch_pred_auc, epoch_IoU))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and best_sel_loss > epoch_sel_loss:\n",
    "                    best_sel_loss = epoch_sel_loss\n",
    "                    torch.save(self.selector.state_dict(),self.exp_name+'_sel.pt')\n",
    "                    torch.save(self.predictor.state_dict(),self.exp_name+'_pred.pt')\n",
    "                    torch.save(self.discriminator.state_dict(),self.exp_name+'_dis.pt')\n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best Sel Loss: {:4f}'.format(best_sel_loss))\n",
    "\n",
    "        torch.save(self.selector.state_dict(),self.exp_name+'_sel_final.pt')\n",
    "        torch.save(self.predictor.state_dict(),self.exp_name+'_pred_final.pt')\n",
    "        torch.save(self.discriminator.state_dict(),self.exp_name+'_dis_final.pt')\n",
    "\n",
    "        print('Training completed finally !!!!!')\n",
    "        \n",
    "    def get_output(self,input_data):\n",
    "        \n",
    "        return self.selector(input_data).numpy()\n",
    "        \n",
    "    def test_model(self):\n",
    "                \n",
    "        self.selector.load_state_dict(self.exp_name+'_sel.pt')\n",
    "        self.selector.eval()\n",
    "        \n",
    "        mIoU = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in dataloaders[mode]:\n",
    "\n",
    "                images = data['image']\n",
    "                mask = data['mask']\n",
    "\n",
    "                images = images.to(device)\n",
    "                \n",
    "                sel_prob = make_prob(self.selector(images))\n",
    "                iou = get_IoU(sel_prob,mask)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                mIoU += iou\n",
    "\n",
    "        print(\"mIoU:\", 1.0*mIoU/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
