{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "  \n",
    "#Pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Image Processing\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform, color\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "#Others\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from model_summary import *\n",
    "import pretrainedmodels\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "class dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.mask_dir = self.root_dir.replace('CBIS-DDSM_classification','masks')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.data_frame.iloc[idx]['name'])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        label = self.data_frame.iloc[idx]['category']\n",
    "\n",
    "        mask_name = os.path.join(self.mask_dir,self.data_frame.iloc[idx]['name'].replace('.j','_mask.j'))\n",
    "        mask = io.imread(mask_name)\n",
    "        mask = np.array([mask,mask,mask]).transpose((1,2,0))\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask) \n",
    "      \n",
    "        return {'image':image,'category':label,'mask':mask, 'name':img_name}\n",
    "    \n",
    "\n",
    "def get_dataloader(data_dir, train_csv_path, image_size, img_mean, img_std, batch_size=1):\n",
    "\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(image_size),#row to column ratio should be 1.69\n",
    "            #transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomVerticalFlip(0.5),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.RandomAffine(translate=(0,0.2),degrees=15,shear=15),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'valid': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize([0.223, 0.231, 0.243], [0.266, 0.270, 0.274])\n",
    "            transforms.Normalize(img_mean,img_std)\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "\n",
    "    for x in ['train', 'valid', 'test']:\n",
    "        image_datasets[x] = dataset(train_csv_path.replace('train',x),root_dir=data_dir,transform=data_transforms[x])\n",
    "        dataloaders[x] = torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,shuffle=True, num_workers=8)    \n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    return dataloaders,dataset_sizes,image_datasets,device\n",
    "\n",
    "def build_spd():\n",
    "    \n",
    "    class selector(nn.Module):\n",
    "        def __init__(self,base):\n",
    "            super().__init__()\n",
    "            self.base = base\n",
    "            self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.fc = nn.Linear(1088,2)\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.base(x)\n",
    "            x = self.gap(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "\n",
    "    ir2 = pretrainedmodels.__dict__['inceptionresnetv2'](num_classes=1000, pretrained='imagenet')\n",
    "    ir1 = nn.Sequential(*list(ir2.children())[:-6])\n",
    "    model = selector(ir1)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def denorm_img(img_ten,img_mean,img_std):\n",
    "\n",
    "    bz,nc,h,w = img_ten.shape\n",
    "    output = []\n",
    "    img_num = img_ten.numpy()\n",
    "    \n",
    "    for i in range(bz):\n",
    "        \n",
    "        img = img_ten[i].numpy().squeeze()\n",
    "        \n",
    "        img[0,:,:] = img[0,:,:]*img_std[0]\n",
    "        img[1,:,:] = img[1,:,:]*img_std[1]\n",
    "        img[2,:,:] = img[2,:,:]*img_std[2]\n",
    "\n",
    "        img[0,:,:] = img[0,:,:] + img_mean[0]\n",
    "        img[1,:,:] = img[1,:,:] + img_mean[1]\n",
    "        img[2,:,:] = img[2,:,:] + img_mean[2]\n",
    "        \n",
    "        img = img.mean(axis=0)\n",
    "        img[img>=0.2*img.max()] = 1\n",
    "        img[img<0.2*img.max()] = 0\n",
    "        \n",
    "        output.append(img)\n",
    "    \n",
    "    output = np.array(output)\n",
    "    return output\n",
    "    \n",
    "def get_IoU(pred, targs, device):\n",
    "\n",
    "    pred[pred>0.5] = 1\n",
    "    pred[pred<0.5] = 0\n",
    "\n",
    "    targs = torch.Tensor(targs).to(device)\n",
    "    \n",
    "    #targs = torch.Tensor((targs>0)).to(device)#.float()\n",
    "    #pred = (pred>0)#.float()\n",
    "    #return (pred*targs).sum() / ((pred+targs).sum() - (pred*targs).sum())\n",
    "    return (pred*targs).sum()/targs.sum()\n",
    "\n",
    "def get_auc_roc(pred, targs):\n",
    "    \n",
    "    bz,c = pred.shape\n",
    "    out = np.zeros(targs.shape)\n",
    "    for i in range(bz):\n",
    "        out[i] = pred[i][int(targs[i])]\n",
    "    return roc_auc_score(targs,out)\n",
    "\n",
    "def make_prob(a,device):\n",
    "    b = a.shape[0]\n",
    "    \n",
    "    f1 = a.view(b,-1)\n",
    "    mi = torch.min(f1,-1)\n",
    "    \n",
    "    t1 = torch.ones((b,1,1,1)).to(device)\n",
    "    t1[:,0,0,0] = mi[0]\n",
    "    \n",
    "    d1 = a - t1\n",
    "    \n",
    "    ma = torch.max(d1.view(b,-1),-1)\n",
    "    t2 = torch.ones((b,1,1,1)).to(device)\n",
    "    t2[:,0,0,0] = ma[0]\n",
    "    \n",
    "    return d1/t2\n",
    "\n",
    "class SaveFeatures:\n",
    "    def __init__(self, m):\n",
    "        self.handle = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, m, inp, outp):\n",
    "        self.features = outp\n",
    "    def remove(self):\n",
    "        self.handle.remove()\n",
    "        \n",
    "def returnCAM(feature_conv, weight_softmax, class_idx, output_shape,device):\n",
    "    \n",
    "    size_upsample = output_shape\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for i in range(bz):\n",
    "        #import pdb;pdb.set_trace()\n",
    "        idx = class_idx[0][i]\n",
    "        cam = weight_softmax[idx].dot(feature_conv[i].reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam_img = torch.Tensor(cv2.resize(cam,(size_upsample[0],size_upsample[1]))).to(device)\n",
    "        cam_img[cam_img<0] = 0\n",
    "        output_cam.append(cam_img)\n",
    "    output_cam = torch.Tensor(output_cam).to(device)\n",
    "    \n",
    "    final_output_cam = torch.zeros((bz,1,size_upsample[1],size_upsample[0]))\n",
    "    final_output_cam[:,0,:,:] = output_cam\n",
    "    \n",
    "    return final_output_cam\n",
    "\n",
    "class dc_invase():\n",
    "    def __init__(self, alpha=1, beta=0.1):\n",
    "        \n",
    "        #Initialization\n",
    "        self.data_dir = '../Data/CBIS-DDSM_classification_orient/'\n",
    "        self.train_csv = '../CSV/gain_train.csv'\n",
    "        self.num_epochs = 200\n",
    "        self.input_shape = (640,512) #(640,512)#(224,224)#(640,384) (640,512)\n",
    "        self.batch_size = 1\n",
    "        self.img_mean = [0.223, 0.231, 0.243]\n",
    "        self.img_std = [0.266, 0.270, 0.274]\n",
    "        self.alpha = 1\n",
    "        self.beta = 0.1\n",
    "        self.exp_name = 'dc_invase_irv2_cam'\n",
    "        \n",
    "        #Define the three models\n",
    "        self.selector = build_spd()\n",
    "        self.predictor = build_spd()\n",
    "        self.discriminator = build_spd()\n",
    "        \n",
    "        #Put them on the GPU\n",
    "        self.selector = self.selector.cuda()\n",
    "        self.predictor = self.predictor.cuda()\n",
    "        self.discriminator = self.discriminator.cuda()\n",
    "        \n",
    "        #Get the dataloaders\n",
    "        self.dataloaders,self.dataset_sizes,self.dataset,self.device = get_dataloader(self.data_dir,self.train_csv,\\\n",
    "                                                        self.input_shape,self.img_mean,self.img_std,self.batch_size)\n",
    "        \n",
    "        #Define the three optimizers one for each model\n",
    "        self.optimizer_sel = optim.Adam(self.selector.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        self.optimizer_pred = optim.Adam(self.predictor.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        self.optimizer_dis = optim.Adam(self.discriminator.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        since = time.time()\n",
    "        best_sel_loss = 0.0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.num_epochs - 1),flush=True)\n",
    "            print('-' * 10,flush=True)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':\n",
    "                    \n",
    "                    #Set the models to training mode\n",
    "                    self.predictor.train() \n",
    "                    self.discriminator.train()\n",
    "                    self.selector.train()\n",
    "                \n",
    "                else:\n",
    "                    #Set the models to evaluation mode\n",
    "                    self.predictor.eval()\n",
    "                    self.discriminator.eval()\n",
    "                    self.selector.eval()\n",
    "                    \n",
    "                #Keep a track of all the three loss\n",
    "                running_sel_loss = 0.0\n",
    "                running_pred_loss = 0.0\n",
    "                running_dis_loss = 0.0\n",
    "                \n",
    "                #Metrics : predictor auc and selector iou\n",
    "                #running_pred_auc = 0\n",
    "                running_iou = 0\n",
    "                running_sel_acc = 0\n",
    "                running_pred_acc = 0\n",
    "                running_dis_acc = 0\n",
    "\n",
    "                #tqdm bar\n",
    "                pbar = tqdm(total=self.dataset_sizes[phase])\n",
    "\n",
    "                # Iterate over data.\n",
    "                for sampled_batch in self.dataloaders[phase]:\n",
    "\n",
    "                    inputs = sampled_batch['image']\n",
    "                    labels = sampled_batch['category']\n",
    "                    mask = denorm_img(sampled_batch['mask'],self.img_mean,self.img_std)\n",
    "\n",
    "                    #Input needs to be float and labels long\n",
    "                    inputs = inputs.float().to(self.device)\n",
    "                    labels = labels.long().to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    self.optimizer_sel.zero_grad()\n",
    "                    self.optimizer_pred.zero_grad()\n",
    "                    self.optimizer_dis.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        \n",
    "                        #import pdb;pdb.set_trace()\n",
    "                        \n",
    "                        #Save feature during the forward pass\n",
    "                        sfs = SaveFeatures(self.selector.base[-1][-1].relu)\n",
    "                        \n",
    "                        #Selector cnn predictions for the image\n",
    "                        sel_out = self.selector(inputs)\n",
    "                        \n",
    "                        sfs.remove()\n",
    "                        \n",
    "                        #convert sel_out to probabilities\n",
    "                        sel_pred_prob = F.softmax(sel_out)\n",
    "                        #Find the predictions\n",
    "                        _, sel_preds = torch.max(sel_out, 1)\n",
    "\n",
    "                        #Get the parameters list\n",
    "                        params = list(self.selector.parameters())\n",
    "                        \n",
    "                        #Final layer weights\n",
    "                        weight_softmax = torch.squeeze(params[-2].data)\n",
    "                    \n",
    "                        #Get the CAM which will the prob map\n",
    "                        cam = torch.matmul(weight_softmax[sel_preds[0]],sfs.features[0].view(sfs.features[0].shape[0],-1))\n",
    "                        cam = F.relu(cam.reshape(sfs.features[0].shape[1], sfs.features[0].shape[2]))\n",
    "                        cam_img = torch.Tensor(cv2.resize(cam.data.cpu().numpy(),(self.input_shape[1],self.input_shape[0]))).to(self.device)\n",
    "                        #cam_img = transforms.Resize(self.input_shape)(cam)\n",
    "                        \n",
    "                        sel_prob = F.sigmoid(cam_img)\n",
    "                        \n",
    "                        #sel_prob = F.Relu(returnCAM(features,weight_softmax,[sel_preds],(inputs.size(-1),inputs.size(-2))))\n",
    "                                                \n",
    "                        #Compute the Complementary selection probability\n",
    "                        comp_sel_prob = 1 - sel_prob\n",
    "                        \n",
    "                        #Generate X_S the selection probability masked image\n",
    "                        x_s = inputs*sel_prob\n",
    "                        \n",
    "                        #Generate X_S_bar the complementary selection probability masked image\n",
    "                        x_s_bar = inputs*comp_sel_prob\n",
    "                        \n",
    "                        #Generate predictor output probabilities\n",
    "                        pred_out = self.predictor(x_s)\n",
    "                        pred_prob = F.softmax(pred_out)\n",
    "                        _, pred_preds = torch.max(pred_out, 1)\n",
    "\n",
    "                        \n",
    "                        #Generate discriminator probabilities\n",
    "                        dis_out = self.discriminator(x_s_bar)\n",
    "                        dis_prob = F.softmax(dis_out)\n",
    "                        _, dis_preds = torch.max(dis_out, 1)\n",
    "\n",
    "                        \n",
    "                        #Predictor Cross entropy\n",
    "                        pred_ce_loss = F.cross_entropy(pred_out,labels)\n",
    "                        \n",
    "                        #Discriminator Negative Cross entropy\n",
    "                        dis_ce_loss = F.cross_entropy(dis_out,1-labels)\n",
    "                        \n",
    "                        #Selector function loss\n",
    "                        sel_ce_loss = F.cross_entropy(sel_out,labels)\n",
    "                        \n",
    "                        #KL_1\n",
    "                        kl_1 = pred_ce_loss - sel_ce_loss\n",
    "                        \n",
    "                        #LK_2\n",
    "                        kl_2 = dis_ce_loss - sel_ce_loss\n",
    "                        \n",
    "                        #L2 norm loss\n",
    "                        l2_norm = torch.norm(sel_prob.view((sel_prob.shape[0],-1)),2,-1)/torch.prod(torch.Tensor(self.input_shape).to(self.device))\n",
    "                        norm_loss = torch.mean(l2_norm)\n",
    "                        \n",
    "                        #Total selector loss\n",
    "                        sel_loss = kl_1 - self.alpha*kl_2 + self.beta*norm_loss\n",
    "                        \n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            \n",
    "                            #Update predictor using pred_ce_loss\n",
    "                            #The gradients of pred_ce_loss should not update the params of disc or sel\n",
    "                            pred_ce_loss.backward(retain_graph=True)\n",
    "                            self.optimizer_sel.zero_grad()\n",
    "                            self.optimizer_dis.zero_grad()\n",
    "                            self.optimizer_pred.step()\n",
    "                            \n",
    "                            #The gradients of dis_ce_loss should not update the params of pred or sel\n",
    "                            dis_ce_loss.backward(retain_graph=True)\n",
    "                            self.optimizer_sel.zero_grad()\n",
    "                            self.optimizer_pred.zero_grad()\n",
    "                            self.optimizer_dis.step()\n",
    "                            \n",
    "                            #The gradients of sel_loss should not update the params of pred or dis\n",
    "                            sel_loss.backward()\n",
    "                            self.optimizer_pred.zero_grad()\n",
    "                            self.optimizer_dis.zero_grad()\n",
    "                            self.optimizer_sel.step()\n",
    "                                    \n",
    "                    # statistics\n",
    "                    running_sel_loss += sel_loss.item() * inputs.size(0)\n",
    "                    running_pred_loss += pred_ce_loss.item() * inputs.size(0)\n",
    "                    running_dis_loss += dis_ce_loss.item() * inputs.size(0)\n",
    "\n",
    "                    \n",
    "                    #running_pred_auc += get_auc_roc(pred_prob.detach().cpu().numpy(),labels.data)\n",
    "                    running_iou += get_IoU(sel_prob,mask,self.device)\n",
    "                    running_sel_acc += torch.sum(sel_preds == labels.data)\n",
    "                    running_pred_acc += torch.sum(pred_preds == labels.data)\n",
    "                    running_dis_acc += torch.sum(dis_preds == (1-labels.data))\n",
    "                    \n",
    "                    \n",
    "                    pbar.update(inputs.shape[0])\n",
    "                pbar.close()\n",
    "\n",
    "\n",
    "                epoch_sel_loss = running_sel_loss / self.dataset_sizes[phase]\n",
    "                epoch_pred_loss = running_pred_loss / self.dataset_sizes[phase]\n",
    "                epoch_dis_loss = running_dis_loss / self.dataset_sizes[phase]\n",
    "                \n",
    "                #epoch_pred_auc = 1.0*running_pred_auc / self.dataset_sizes[phase]\n",
    "                epoch_IoU = running_iou.double() / self.dataset_sizes[phase]\n",
    "                epoch_pred_acc = running_pred_acc.double() / self.dataset_sizes[phase]\n",
    "                epoch_dis_acc = running_dis_acc.double() / self.dataset_sizes[phase]\n",
    "\n",
    "                print('{} Sel_Loss: {:.4f} Pred_Loss: {:.4f} Dis_Loss: {:.4f} ACC: {:.4f} AUC: {:.4f} IoU: {:.4f}'.format(\n",
    "                    phase, epoch_sel_loss, epoch_pred_loss, epoch_dis_loss, epoch_acc, epoch_pred_auc, epoch_IoU))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'valid' and best_sel_loss > epoch_sel_loss:\n",
    "                    best_sel_loss = epoch_sel_loss\n",
    "                    torch.save(self.selector.state_dict(),self.exp_name+'_sel.pt')\n",
    "                    torch.save(self.predictor.state_dict(),self.exp_name+'_pred.pt')\n",
    "                    torch.save(self.discriminator.state_dict(),self.exp_name+'_dis.pt')\n",
    "\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best Sel Loss: {:4f}'.format(best_sel_loss))\n",
    "\n",
    "        torch.save(self.selector.state_dict(),self.exp_name+'_sel_final.pt')\n",
    "        torch.save(self.predictor.state_dict(),self.exp_name+'_pred_final.pt')\n",
    "        torch.save(self.discriminator.state_dict(),self.exp_name+'_dis_final.pt')\n",
    "\n",
    "        print('Training completed finally !!!!!')\n",
    "        \n",
    "    def get_output(self,input_data):\n",
    "        \n",
    "        return self.selector(input_data).numpy()\n",
    "        \n",
    "    def test_model(self):\n",
    "                \n",
    "        self.selector.load_state_dict(self.exp_name+'_sel.pt')\n",
    "        self.selector.eval()\n",
    "        \n",
    "        mIoU = 0\n",
    "        total = 0\n",
    "        mode = 'test'\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in self.dataloaders[mode]:\n",
    "\n",
    "                images = data['image']\n",
    "                mask = data['mask']\n",
    "\n",
    "                images = images.to(self.device)\n",
    "                \n",
    "                sel_prob = make_prob(self.selector(images))\n",
    "                iou = get_IoU(sel_prob,mask)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                mIoU += iou\n",
    "\n",
    "        print(\"mIoU:\", 1.0*mIoU/total)\n",
    "\n",
    "    def return_model(self):\n",
    "        self.selector.load_state_dict(torch.load(self.exp_name+'_sel.pt'))\n",
    "        self.selector.eval()\n",
    "        return self.selector,self.dataloaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dci = dc_invase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1967 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/1967 [00:01<47:28,  1.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 2/1967 [00:02<38:58,  1.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 3/1967 [00:02<32:17,  1.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 4/1967 [00:03<27:28,  1.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 5/1967 [00:03<24:09,  1.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 6/1967 [00:04<21:51,  1.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 7/1967 [00:04<20:09,  1.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 8/1967 [00:05<18:56,  1.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 9/1967 [00:05<18:06,  1.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AProcess Process-99:\n",
      "Process Process-101:\n",
      "Process Process-102:\n",
      "Process Process-100:\n",
      "Process Process-103:\n",
      "Process Process-104:\n",
      "Process Process-97:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process Process-98:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-49-783ee30eae84>\", line 63, in __getitem__\n",
      "    image = self.transform(image)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 175, in __call__\n",
      "    return F.resize(img, self.size, self.interpolation)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/torchvision/transforms/functional.py\", line 206, in resize\n",
      "    return img.resize(size[::-1], interpolation)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 1747, in resize\n",
      "    self.load()\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/vdslab/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 23244) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-783ee30eae84>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m                             \u001b[0;31m#The gradients of sel_loss should not update the params of pred or dis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                             \u001b[0msel_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-742f7ce152e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-783ee30eae84>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                             \u001b[0;31m#The gradients of sel_loss should not update the params of pred or dis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                             \u001b[0msel_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_dis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 23244) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace."
     ]
    }
   ],
   "source": [
    "dci.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4164, 0.6840, 0.0629, 0.3559, 0.0743, 0.0962, 0.3630, 0.6852, 0.6563])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4164, 0.6840, 0.0629],\n",
       "        [0.3559, 0.0743, 0.0962],\n",
       "        [0.3630, 0.6852, 0.6563]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/(1+torch.exp(-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cam_img.npy\t\t dc_invase_resnet_pred.pt\r\n",
      "cam_mob_exp.py\t\t dc_invase_resnet_segnet_dis.pt\r\n",
      "cam.npy\t\t\t dc_invase_resnet_segnet_pred.pt\r\n",
      "DC_INVASE_cam_pyt.ipynb  dc_invase_resnet_segnet_sel.pt\r\n",
      "DC_INVASE_cam_pyt.py\t dc_invase_resnet_sel.pt\r\n",
      "DC_INVASE_keras.ipynb\t gain_exp_mult.py\r\n",
      "dc_invase.py\t\t GAIN_pyt.ipynb\r\n",
      "DC_INVASE_pyt.ipynb\t model_summary.py\r\n",
      "DC_INVASE_pyt.py\t __pycache__\r\n",
      "dc_invase_resnet_dis.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('cam_img.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.load('cam.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
